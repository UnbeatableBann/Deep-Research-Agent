{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "f4169bfb-769a-4db3-833e-c827f19024b2",
      "metadata": {
        "id": "f4169bfb-769a-4db3-833e-c827f19024b2"
      },
      "source": [
        "# Build a Planning Agent for Deep Research & Structured Report Generation with LangGraph\n",
        "\n",
        "### IMPORTANT: Be Careful this Agent will do a lot of searches so if you run it too many times you can easily exhaust your API limits for Tavily Search if you are on the free tier\n",
        "\n",
        "In this project we will be building a Planning Agent for Deep Research and Structured Report Generation in the form of Wiki-style Reports (structured with key sections and section headings)\n",
        "\n",
        "\n",
        "![](https://i.imgur.com/STSC73k.png)\n",
        "\n",
        "\n",
        "### Planning Agent for Deep Research and Structured Report Generation\n",
        "\n",
        "This project focuses on building a **Planning Agent for Deep Research and Structured Report Generation**. The agent automates the process of analyzing a user-defined topic, performing web research, and generating a well-structured report. The workflow includes the following components:\n",
        "\n",
        "1. **Report Planning**:\n",
        "   - The agent analyzes the user-provided **topic** and **default report template** to create a custom plan for the report.\n",
        "   - Sections such as **Introduction**, **Key Sections**, and **Conclusion** are defined based on the topic.\n",
        "   - A **web search tool** is used to collect information required before deciding the main sections.\n",
        "\n",
        "2. **Parallel Execution for Research and Writing**:\n",
        "   - The agent uses **parallel execution** to efficiently perform:\n",
        "     - **Web Research**: Queries are generated for each section and executed via the web search tool to retrieve up-to-date information.\n",
        "     - **Section Writing**: The retrieved data is used to write content for each section, with the following process:\n",
        "       - The **Researcher** gathers relevant data from the web.\n",
        "       - The **Section Writer** uses the data to generate structured content for the assigned section.\n",
        "\n",
        "3. **Formatting Completed Sections**:\n",
        "   - Once all sections are written, they are formatted to ensure consistency and adherence to the report structure.\n",
        "\n",
        "4. **Introduction and Conclusion Writing**:\n",
        "   - After the main sections are completed and formatted:\n",
        "     - The **Introduction** and **Conclusion** are written based on the content of the remaining sections (in parallel)\n",
        "     - This process ensures that these sections align with the overall flow and insights of the report.\n",
        "\n",
        "5. **Final Compilation**:\n",
        "   - All completed sections are compiled together to generate the **final report**.\n",
        "   - The final output is a comprehensive and structured document in the style of wiki docs.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9hEI3WL328vZ",
      "metadata": {
        "id": "9hEI3WL328vZ"
      },
      "source": [
        "## Install Gemini, LangGraph and LangChain dependencies"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "H9c37cLnSrbg",
      "metadata": {
        "id": "H9c37cLnSrbg"
      },
      "source": [
        "## Enter Gemini API Key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "cv3JzCEx_PAd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cv3JzCEx_PAd",
        "outputId": "fb2a7058-9c1a-4ae2-ceda-5b12d193b2f5"
      },
      "outputs": [],
      "source": [
        "from getpass import getpass\n",
        "\n",
        "GEMINI_API_KEY = getpass('Enter Gemini API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ucWRRI3QztL2",
      "metadata": {
        "id": "ucWRRI3QztL2"
      },
      "source": [
        "## Enter Tavily Search API Key\n",
        "\n",
        "Get a free API key from [here](https://tavily.com/#api)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "mK-1WLzOrJdb",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK-1WLzOrJdb",
        "outputId": "8b103693-f7d9-45c4-9728-47ae91763132"
      },
      "outputs": [],
      "source": [
        "TAVILY_API_KEY = getpass('Enter Tavily Search API Key: ')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1T0s0um5Svfa",
      "metadata": {
        "id": "1T0s0um5Svfa"
      },
      "source": [
        "## Setup Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "x1YSuHNF_lbh",
      "metadata": {
        "id": "x1YSuHNF_lbh"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "\n",
        "#os.environ['OPENAI_API_KEY'] = OPENAI_KEY\n",
        "os.environ['GEMINI_API_KEY'] = GEMINI_API_KEY\n",
        "os.environ['TAVILY_API_KEY'] = TAVILY_API_KEY"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1Anj_VT7b4Rt",
      "metadata": {
        "id": "1Anj_VT7b4Rt"
      },
      "source": [
        "## Define Agent State Schema\n",
        "\n",
        "Each specific set of operations (nodes) will have their own schema as defined below. You can customize this further based on your own style of report generation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "o7EnucYkRb6f",
      "metadata": {
        "id": "o7EnucYkRb6f"
      },
      "outputs": [],
      "source": [
        "from typing_extensions import TypedDict, Dict, Union, Any\n",
        "from pydantic import BaseModel, Field\n",
        "import operator\n",
        "from typing import  Annotated, List, Optional, Literal\n",
        "\n",
        "class Section(BaseModel):\n",
        "    name: str = Field(\n",
        "        description=\"Name for a particular section of the report.\",\n",
        "    )\n",
        "    description: str = Field(\n",
        "        description=\"Brief overview of the main topics and concepts to be covered in this section.\",\n",
        "    )\n",
        "    research: bool = Field(\n",
        "        description=\"Whether to perform web search for this section of the report.\"\n",
        "    )\n",
        "    content: str = Field(\n",
        "        description=\"The content for this section.\"\n",
        "    )\n",
        "\n",
        "class Sections(BaseModel):\n",
        "    sections: List[Section] = Field(\n",
        "        description=\"All the Sections of the overall report.\",\n",
        "    )\n",
        "\n",
        "class SearchQuery(BaseModel):\n",
        "    search_query: str = Field(None, description=\"Query for web search.\")\n",
        "\n",
        "class Queries(BaseModel):\n",
        "    queries: List[SearchQuery] = Field(\n",
        "        description=\"List of web search queries.\",\n",
        "    )\n",
        "\n",
        "class ReportStateInput(TypedDict):\n",
        "    topic: str # Report topic\n",
        "\n",
        "class ReportStateOutput(TypedDict):\n",
        "    final_report: str # Final report\n",
        "\n",
        "class ReportState(TypedDict):\n",
        "    topic: str # Report topic\n",
        "    sections: list[Section] # List of report sections\n",
        "    completed_sections: Annotated[list, operator.add] # Send() API\n",
        "    report_sections_from_research: str # String of any completed sections from research to write final sections\n",
        "    final_report: str # Final report\n",
        "\n",
        "class SectionState(TypedDict):\n",
        "    section: Section # Report section\n",
        "    search_queries: list[SearchQuery] # List of search queries\n",
        "    source_str: str # String of formatted source content from web search\n",
        "    report_sections_from_research: str # String of any completed sections from research to write final sections\n",
        "    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API\n",
        "\n",
        "class SectionOutputState(TypedDict):\n",
        "    completed_sections: list[Section] # Final key we duplicate in outer state for Send() API\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "J8gh0PeLnoD8",
      "metadata": {
        "id": "J8gh0PeLnoD8"
      },
      "source": [
        "## Utility Functions\n",
        "\n",
        "- __`run_search_queries(...)`__ : This will asynchronously run tavily search queries for specific list of queries and return back the search results. This is async so it is non blocking and can be executed in parallel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "x90h-0URszgf",
      "metadata": {
        "id": "x90h-0URszgf"
      },
      "outputs": [],
      "source": [
        "from langchain_community.utilities.tavily_search import TavilySearchAPIWrapper\n",
        "import asyncio\n",
        "from dataclasses import asdict, dataclass\n",
        "\n",
        "\n",
        "# just to handle objects created from LLM reponses\n",
        "@dataclass\n",
        "class SearchQuery:\n",
        "    search_query: str\n",
        "\n",
        "    def to_dict(self) -> Dict[str, Any]:\n",
        "        return asdict(self)\n",
        "\n",
        "\n",
        "tavily_search = TavilySearchAPIWrapper()\n",
        "\n",
        "\n",
        "async def run_search_queries(\n",
        "    search_queries: List[Union[str, SearchQuery]],\n",
        "    num_results: int = 5,\n",
        "    include_raw_content: bool = False\n",
        ") -> List[Dict]:\n",
        "\n",
        "    search_tasks = []\n",
        "\n",
        "    for query in search_queries:\n",
        "        # Handle both string and SearchQuery objects\n",
        "        # Just in case LLM fails to generate queries as:\n",
        "        # class SearchQuery(BaseModel):\n",
        "        #     search_query: str\n",
        "        query_str = query.search_query if isinstance(query, SearchQuery) else str(query) # text query\n",
        "\n",
        "        try:\n",
        "            # get results from tavily asynchronously (in parallel) for each search query\n",
        "            search_tasks.append(\n",
        "                tavily_search.raw_results_async(\n",
        "                    query=query_str,\n",
        "                    max_results=num_results,\n",
        "                    search_depth='advanced',\n",
        "                    include_answer=False,\n",
        "                    include_raw_content=include_raw_content\n",
        "                )\n",
        "            )\n",
        "        except Exception as e:\n",
        "            print(f\"Error creating search task for query '{query_str}': {e}\")\n",
        "            continue\n",
        "\n",
        "    # Execute all searches concurrently and await results\n",
        "    try:\n",
        "        if not search_tasks:\n",
        "            return []\n",
        "        search_docs = await asyncio.gather(*search_tasks, return_exceptions=True)\n",
        "        # Filter out any exceptions from the results\n",
        "        valid_results = [\n",
        "            doc for doc in search_docs\n",
        "            if not isinstance(doc, Exception)\n",
        "        ]\n",
        "        return valid_results\n",
        "    except Exception as e:\n",
        "        print(f\"Error during search queries: {e}\")\n",
        "        return []"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Db-RKn5MCi47",
      "metadata": {
        "id": "Db-RKn5MCi47"
      },
      "source": [
        "- __`format_search_query_results(...)`__ : This will extract the context from tavily search results, make sure content is not duplicated from same urls and format it to show the Source, URL, relevant content (and optionally raw content which can be truncated based on number of tokens)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "E9YSh5pAxW5r",
      "metadata": {
        "id": "E9YSh5pAxW5r"
      },
      "outputs": [],
      "source": [
        "import tiktoken\n",
        "from typing import List, Dict, Union, Any\n",
        "\n",
        "def format_search_query_results(\n",
        "    search_response: Union[Dict[str, Any], List[Any]],\n",
        "    max_tokens: int = 2000,\n",
        "    include_raw_content: bool = False\n",
        ") -> str:\n",
        "    encoding = tiktoken.encoding_for_model(\"gpt-4\")\n",
        "    sources_list = []\n",
        "\n",
        "    # Handle different response formats\n",
        "    # if search results is a dict\n",
        "    if isinstance(search_response, dict):\n",
        "        if 'results' in search_response:\n",
        "            sources_list.extend(search_response['results'])\n",
        "        else:\n",
        "            sources_list.append(search_response)\n",
        "    # if search results is a list\n",
        "    elif isinstance(search_response, list):\n",
        "        for response in search_response:\n",
        "            if isinstance(response, dict):\n",
        "                if 'results' in response:\n",
        "                    sources_list.extend(response['results'])\n",
        "                else:\n",
        "                    sources_list.append(response)\n",
        "            elif isinstance(response, list):\n",
        "                sources_list.extend(response)\n",
        "\n",
        "    if not sources_list:\n",
        "        return \"No search results found.\"\n",
        "\n",
        "    # Deduplicate by URL and keep unique sources (website urls)\n",
        "    unique_sources = {}\n",
        "    for source in sources_list:\n",
        "        if isinstance(source, dict) and 'url' in source:\n",
        "            if source['url'] not in unique_sources:\n",
        "                unique_sources[source['url']] = source\n",
        "\n",
        "    # Format output\n",
        "    formatted_text = \"Content from web search:\\n\\n\"\n",
        "    for i, source in enumerate(unique_sources.values(), 1):\n",
        "        formatted_text += f\"Source {source.get('title', 'Untitled')}:\\n===\\n\"\n",
        "        formatted_text += f\"URL: {source['url']}\\n===\\n\"\n",
        "        formatted_text += f\"Most relevant content from source: {source.get('content', 'No content available')}\\n===\\n\"\n",
        "\n",
        "        if include_raw_content:\n",
        "            # truncate raw webpage content to a certain number of tokens to prevent exceeding LLM max token window\n",
        "            raw_content = source.get(\"raw_content\", \"\")\n",
        "            if raw_content:\n",
        "                tokens = encoding.encode(raw_content)\n",
        "                truncated_tokens = tokens[:max_tokens]\n",
        "                truncated_content = encoding.decode(truncated_tokens)\n",
        "                formatted_text += f\"Raw Content: {truncated_content}\\n\\n\"\n",
        "\n",
        "    return formatted_text.strip()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "lM0iTr7iC-17",
      "metadata": {
        "id": "lM0iTr7iC-17"
      },
      "source": [
        "## Test Sample Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "60GtL630zXH4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60GtL630zXH4",
        "outputId": "829b617b-c306-4fe5-9cb8-db67c56ab497"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'query': 'langgraph',\n",
              "  'follow_up_questions': None,\n",
              "  'answer': None,\n",
              "  'images': [],\n",
              "  'results': [{'title': 'What is LangGraph and How to Use It for Building AI Agents',\n",
              "    'url': 'https://jstoppa.com/posts/artificial-intelligence/fundamentals/what-is-langgraph-and-how-to-use-it-for-building-ai-agents/post/',\n",
              "    'content': 'What is LangGraph?#\\nLangGraph is a framework that brings state machines to Large Language Model (LLM) applications. It‚Äôs particularly useful when you need to build complex, stateful applications with LLMs. The framework allows you to structure your application as a graph, where each node represents a specific task or state, and edges represent transitions between states.\\nBasic LangGraph Example#',\n",
              "    'score': 0.9284155,\n",
              "    'raw_content': 'Published Time: 2025-02-16T00:00:00Z\\nWhat is LangGraph and How to Use It for Building AI Agents | Juan Stoppa\\nJuan Stoppa\\n\\nArchives\\nSearch\\nTags\\n\\nWhat is LangGraph and How to Use It for Building AI Agents\\nA practical guide to LangGraph and AI agents. This covers the basics, real examples, and deployment. I wrote it to simplify LangChain\\'s complex docs and help people build stateful AI agents.\\nFebruary 16, 2025\\xa0¬∑\\xa012 min\\xa0¬∑\\xa0Juan Stoppa\\nI keep finding myself going back to the LangChain documentation to figure out how to use LangGraph. While the documentation is comprehensive, it can be overwhelming to navigate, especially when you‚Äôre trying to build advanced AI agents.\\nThis guide is my attempt to consolidate the key concepts and practical implementations of LangGraph in one place. Whether you‚Äôre building a conversational agent that needs to remember context, a multi-step reasoning agent, or a complex workflow that coordinates multiple AI components, LangGraph provides the framework to make it happen. I created this reference for myself but I hope it helps others who want a more straightforward explanation of how to use LangGraph effectively.\\nWhat is LangGraph?#\\nLangGraph is a framework that brings state machines to Large Language Model (LLM) applications. It‚Äôs particularly useful when you need to build complex, stateful applications with LLMs. The framework allows you to structure your application as a graph, where each node represents a specific task or state, and edges represent transitions between states.\\nBasic LangGraph Example#\\nLet‚Äôs start with a simple example to understand the core concepts: we are developing a simple agent that collects information and processes it, the actions of collecting and processing information are just fixed actions but they can be replaced with more complex actions.\\n\\n```python\\nfrom langgraph.graph import StateGraph\\nfrom typing import TypedDict, Annotated\\nfrom langgraph.graph.message import add_messages\\nfrom langchain_core.runnables.graph import MermaidDrawMethod\\nclass State(TypedDict):\\n    messages: Annotated[list[str], add_messages]\\n    current_step: str\\ndef collect_info(state: State) -> dict:\\n    print(\"\\\\n--> In collect_info\")\\n    print(f\"Messages before: {state[\\'messages\\']}\")\\nmessages = state[\"messages\"] + [\"Information collected\"]\\nprint(f\"Messages after: {messages}\")\\n\\nreturn {\\n    \"messages\": messages,\\n    \"current_step\": \"process\"\\n}\\n\\ndef process_info(state: State) -> dict:\\n    print(\"\\\\n--> In process_info\")\\n    print(f\"Messages before: {state[\\'messages\\']}\")\\nmessages = state[\"messages\"] + [\"Information processed\"]\\nprint(f\"Messages after: {messages}\")\\n\\nreturn {\\n    \"messages\": messages,\\n    \"current_step\": \"end\"\\n}\\n\\nCreate and setup graph\\nworkflow = StateGraph(State)\\nAdd nodes\\nworkflow.add_node(\"collect\", collect_info)\\nworkflow.add_node(\"process\", process_info)\\nAdd edges\\nworkflow.add_edge(\"collect\", \"process\")\\nSet entry and finish points\\nworkflow.set_entry_point(\"collect\")\\nworkflow.set_finish_point(\"process\")\\napp = workflow.compile()\\nRun workflow\\nprint(\"\\\\nStarting workflow...\")\\ninitial_state = State(messages=[\"Starting\"], current_step=\"collect\")\\nfinal_state = app.invoke(initial_state)\\nprint(f\"\\\\nFinal messages: {final_state[\\'messages\\']}\")\\nSave the graph visualization as PNG\\npng_data = app.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API)\\nwith open(\"workflow_graph.png\", \"wb\") as f:\\n    f.write(png_data)\\nprint(\"\\\\nGraph visualization saved as \\'workflow_graph.png\\'\")\\n```\\nThis example shows the basic structure of a LangGraph application:\\n\\nDefine your state using TypedDict, it contains the information that the workflow will need to keep track of.\\nCreate functions for each state, these functions are the actions that the workflow will perform.\\nBuild a graph with nodes and edges, the nodes are the states and the edges are the transitions between them.\\nCompile the graph into a runnable application, this will create a callable object that can be invoked with an initial state.\\nI also added a simple way to save the graph visualization as a PNG file, this will work if you are running this example locally and should save a file that will show the graph structure like below.\\n\\nThe graph is a good way to understand the workflow, it shows the nodes and the edges between them, the entry and finish points and the state of the workflow.\\n\\nThis particular example is not very useful but it shows the core concepts of LangGraph, you can simply replace the fixed actions with more complex ones and build a useful agent.\\nServing LangGraph as a Web Service#\\nWhile LangGraph itself doesn‚Äôt include built-in server capabilities, you can easily create a web service using FastAPI to serve your LangGraph workflows. Below I have modified the previous example to add a simple FastAPI server that allows you to run the workflow from a web interface.\\n\\n```python\\nfrom fastapi import FastAPI\\nfrom langgraph.graph import StateGraph\\nfrom typing import TypedDict, Annotated, List\\nfrom langgraph.graph.message import add_messages\\nfrom pydantic import BaseModel\\nInitialize FastAPI app\\napp = FastAPI(title=\"LangGraph Agent API\")\\nclass State(TypedDict):\\n    messages: Annotated[list[str], add_messages]\\n    current_step: str\\nclass AgentInput(BaseModel):\\n    messages: List[str]\\ndef collect_info(state: State) -> dict:\\n    print(\"\\\\n--> In collect_info\")\\n    print(f\"Messages before: {state[\\'messages\\']}\")\\nmessages = state[\"messages\"] + [\"Information collected\"]\\nprint(f\"Messages after: {messages}\")\\n\\nreturn {\\n    \"messages\": messages,\\n    \"current_step\": \"process\"\\n}\\n\\ndef process_info(state: State) -> dict:\\n    print(\"\\\\n--> In process_info\")\\n    print(f\"Messages before: {state[\\'messages\\']}\")\\nmessages = state[\"messages\"] + [\"Information processed\"]\\nprint(f\"Messages after: {messages}\")\\n\\nreturn {\\n    \"messages\": messages,\\n    \"current_step\": \"end\"\\n}\\n\\nCreate and setup graph\\nworkflow = StateGraph(State)\\nAdd nodes\\nworkflow.add_node(\"collect\", collect_info)\\nworkflow.add_node(\"process\", process_info)\\nAdd edges\\nworkflow.add_edge(\"collect\", \"process\")\\nSet entry and finish points\\nworkflow.set_entry_point(\"collect\")\\nworkflow.set_finish_point(\"process\")\\nCompile the workflow\\nagent = workflow.compile()\\n@app.post(\"/run-agent\")\\nasync def run_agent(input_data: AgentInput):\\n    \"\"\"\\n    Run the agent with the provided input messages.\\n    \"\"\"\\n    initial_state = State(messages=input_data.messages, current_step=\"collect\")\\n    final_state = agent.invoke(initial_state)\\n    return {\"messages\": final_state[\"messages\"]}\\n@app.get(\"/\")\\nasync def root():\\n    \"\"\"\\n    Root endpoint that returns basic API information.\\n    \"\"\"\\n    return {\"message\": \"LangGraph Agent API is running\", \"endpoints\": [\"Navigate to https://jstoppa-langgraph-basic-example-api.hf.space/docs#/default/run_agent_run_agent_post to run the example\"]}\\nif name == \"main\":\\n    import uvicorn\\n    uvicorn.run(app, host=\"0.0.0.0\", port=7860)\\n```\\nYou can run this locally or using the Hugging Face space below, this is the URL to access the swagger API for this example https://jstoppa-langgraph-basic-example-api.hf.space/docs, the API has an end point to run the agent and it returns the messages we‚Äôve seen in our previous example (see below the results). In simple words, the API has an end point to run the agent and it returns the messages we‚Äôve seen in our previous example.\\n\\nMaking it all work with a more interesting example#\\nWe are now going to create a more interesting example, an AI agent that does code reviews, this is far from a production-ready agent but it will give us a better understanding of how to use LangGraph.\\nThe screenshot below shows the interface for the code review agent, the user can enter a code and the agent will return a report with the code analysis. This interface uses the Gradio library to create a simple web interface, this saves a lot of time compared to building a full web app.\\n\\nThe full code is provided after this but the most impportant part of the example is the graph, it shows the nodes and the edges between them, the entry and finish points and the state of the workflow, this is how the graph will look through the code and analyse the code with different agents that are especialised on different aspects. This is a very similar apporach we‚Äôve seen in the previous example but it contains more actions and the actions do use LLMs to analyse the code.\\n```python\\nCreate and setup graph\\nworkflow = StateGraph(State)\\nAdd nodes\\nworkflow.add_node(\"style\", analyze_code_style)\\nworkflow.add_node(\"security\", analyze_security)\\nworkflow.add_node(\"performance\", analyze_performance)\\nworkflow.add_node(\"architecture\", analyze_architecture)\\nworkflow.add_node(\"recommendations\", generate_final_recommendations)\\nAdd edges\\nworkflow.add_edge(\"style\", \"security\")\\nworkflow.add_edge(\"security\", \"performance\")\\nworkflow.add_edge(\"performance\", \"architecture\")\\nworkflow.add_edge(\"architecture\", \"recommendations\")\\nSet entry and finish points\\nworkflow.set_entry_point(\"style\")\\nworkflow.set_finish_point(\"recommendations\")\\nCompile the workflow\\nagent = workflow.compile()\\n```\\nthe full code for the agent is below and it can also be found in Hugging Face below. \\n```python\\nimport gradio as gr\\nfrom langgraph.graph import StateGraph\\nfrom typing import TypedDict, Annotated, List, Dict\\nfrom langgraph.graph.message import add_messages\\nfrom langchain_core.messages import SystemMessage, HumanMessage, AIMessage\\nimport json\\nimport requests\\nimport os\\nfrom dotenv import load_dotenv\\nimport time\\nLoad environment variables\\nload_dotenv()\\nDefine the state structure\\nclass State(TypedDict):\\n    messages: Annotated[list[SystemMessage | HumanMessage | AIMessage], add_messages]\\n    current_step: str\\n    code: str\\n    style_analysis: Dict\\n    security_analysis: Dict\\n    performance_analysis: Dict\\n    architecture_analysis: Dict\\n    final_recommendations: Dict\\ndef call_huggingface_api(prompt: str, max_retries=3) -> Dict:\\n    \"\"\"Call Hugging Face API with retry logic and proper error handling.\"\"\"\\n    api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\\n    if not api_key:\\n        raise ValueError(\"HUGGINGFACE_API_KEY not found in environment variables\")\\n# You can change this to any model you prefer\\nAPI_URL = \"https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1\"\\nheaders = {\"Authorization\": f\"Bearer {api_key}\"}\\n\\nfor attempt in range(max_retries):\\n    try:\\n        response = requests.post(\\n            API_URL,\\n            headers=headers,\\n            json={\\n                \"inputs\": prompt,\\n                \"parameters\": {\\n                    \"max_new_tokens\": 1000,\\n                    \"temperature\": 0.7,\\n                    \"top_p\": 0.95,\\n                    \"return_full_text\": False\\n                }\\n            }\\n        )\\n\\n        if response.status_code == 200:\\n            result = response.json()\\n            if isinstance(result, list) and len(result) > 0:\\n                # Extract the generated text\\n                text = result[0].get(\\'generated_text\\', \\'\\')\\n                # Try to parse as JSON if it contains JSON\\n                try:\\n                    # Find JSON content between triple backticks if present\\n                    if \"```json\" in text:\\n                        json_str = text.split(\"```json\")[1].split(\"```\")[0].strip()\\n                    else:\\n                        json_str = text.strip()\\n                    return json.loads(json_str)\\n                except json.JSONDecodeError:\\n                    return {\"error\": \"Failed to parse JSON from response\", \"raw_text\": text}\\n\\n        # If model is loading, wait and retry\\n        if response.status_code == 503:\\n            wait_time = 2 ** attempt\\n            time.sleep(wait_time)\\n            continue\\n\\n    except Exception as e:\\n        if attempt == max_retries - 1:\\n            return {\"error\": f\"API call failed: {str(e)}\"}\\n        time.sleep(2 ** attempt)\\n\\nreturn {\"error\": \"Maximum retries reached\"}\\n\\ndef analyze_code_style(state: State) -> dict:\\n    \"\"\"Analyze code style and best practices.\"\"\"\\n    code = state[\"code\"]\\n    prompt = f\"\"\"You are a senior code reviewer focused on code style and best practices. Analyze this code:\\n{code}\\nFocus on:\\n1. Code readability and clarity\\n2. Adherence to common style guides\\n3. Variable/function naming\\n4. Code organization\\n5. Documentation quality\\nProvide your response in JSON format with these exact keys:\\n{{\\n    \"issues\": [\"list of identified style issues\"],\\n    \"suggestions\": [\"list of improvement suggestions\"],\\n    \"overall_rating\": \"1-10 score as a number\",\\n    \"primary_concerns\": [\"list of main style concerns\"]\\n}}\"\"\"\\nanalysis = call_huggingface_api(prompt)\\nif \"error\" in analysis:\\n    analysis = {\\n        \"issues\": [\"Error analyzing code style\"],\\n        \"suggestions\": [\"Try again later\"],\\n        \"overall_rating\": 0,\\n        \"primary_concerns\": [\"Analysis failed\"]\\n    }\\n\\nmessages = state[\"messages\"] + [AIMessage(content=\"Completed code style analysis\")]\\nreturn {**state, \"messages\": messages, \"style_analysis\": analysis, \"current_step\": \"security\"}\\n\\ndef analyze_security(state: State) -> dict:\\n    \"\"\"Analyze security vulnerabilities.\"\"\"\\n    code = state[\"code\"]\\n    prompt = f\"\"\"You are a security expert. Analyze this code for security vulnerabilities:\\n{code}\\nFocus on:\\n1. Input validation\\n2. Authentication/Authorization\\n3. Data exposure\\n4. Common vulnerabilities\\n5. Security best practices\\nProvide your response in JSON format with these exact keys:\\n{{\\n    \"vulnerabilities\": [\"list of potential security issues\"],\\n    \"risk_levels\": {{\"vulnerability\": \"risk level\"}},\\n    \"recommendations\": [\"list of security improvements\"],\\n    \"overall_security_score\": \"1-10 score as a number\"\\n}}\"\"\"\\nanalysis = call_huggingface_api(prompt)\\nif \"error\" in analysis:\\n    analysis = {\\n        \"vulnerabilities\": [\"Error analyzing security\"],\\n        \"risk_levels\": {\"Error\": \"High\"},\\n        \"recommendations\": [\"Try again later\"],\\n        \"overall_security_score\": 0\\n    }\\n\\nmessages = state[\"messages\"] + [AIMessage(content=\"Completed security analysis\")]\\nreturn {**state, \"messages\": messages, \"security_analysis\": analysis, \"current_step\": \"performance\"}\\n\\ndef analyze_performance(state: State) -> dict:\\n    \"\"\"Analyze code performance.\"\"\"\\n    code = state[\"code\"]\\n    prompt = f\"\"\"You are a performance optimization expert. Analyze this code for performance issues:\\n{code}\\nFocus on:\\n1. Time complexity\\n2. Space complexity\\n3. Resource usage\\n4. Bottlenecks\\n5. Optimization opportunities\\nProvide your response in JSON format with these exact keys:\\n{{\\n    \"bottlenecks\": [\"list of identified performance bottlenecks\"],\\n    \"complexity_analysis\": {{\\n        \"time_complexity\": \"Big O notation\",\\n        \"space_complexity\": \"Big O notation\",\\n        \"critical_sections\": [\"list of critical sections\"]\\n    }},\\n    \"optimization_suggestions\": [\"list of performance improvements\"],\\n    \"performance_score\": \"1-10 score as a number\"\\n}}\"\"\"\\nanalysis = call_huggingface_api(prompt)\\nif \"error\" in analysis:\\n    analysis = {\\n        \"bottlenecks\": [\"Error analyzing performance\"],\\n        \"complexity_analysis\": {\\n            \"time_complexity\": \"Unknown\",\\n            \"space_complexity\": \"Unknown\",\\n            \"critical_sections\": []\\n        },\\n        \"optimization_suggestions\": [\"Try again later\"],\\n        \"performance_score\": 0\\n    }\\n\\nmessages = state[\"messages\"] + [AIMessage(content=\"Completed performance analysis\")]\\nreturn {**state, \"messages\": messages, \"performance_analysis\": analysis, \"current_step\": \"architecture\"}\\n\\ndef analyze_architecture(state: State) -> dict:\\n    \"\"\"Analyze code architecture patterns.\"\"\"\\n    code = state[\"code\"]\\n    prompt = f\"\"\"You are a software architect. Analyze this code\\'s architectural patterns:\\n{code}\\nFocus on:\\n1. Design patterns used\\n2. Code modularity\\n3. Component relationships\\n4. Architectural anti-patterns\\n5. System design principles\\nProvide your response in JSON format with these exact keys:\\n{{\\n    \"patterns_identified\": [\"list of design patterns found\"],\\n    \"architectural_issues\": [\"list of architectural concerns\"],\\n    \"improvement_suggestions\": [\"list of architectural improvements\"],\\n    \"architecture_score\": \"1-10 score as a number\"\\n}}\"\"\"\\nanalysis = call_huggingface_api(prompt)\\nif \"error\" in analysis:\\n    analysis = {\\n        \"patterns_identified\": [\"Error analyzing architecture\"],\\n        \"architectural_issues\": [\"Analysis failed\"],\\n        \"improvement_suggestions\": [\"Try again later\"],\\n        \"architecture_score\": 0\\n    }\\n\\nmessages = state[\"messages\"] + [AIMessage(content=\"Completed architecture analysis\")]\\nreturn {**state, \"messages\": messages, \"architecture_analysis\": analysis, \"current_step\": \"recommendations\"}\\n\\ndef generate_final_recommendations(state: State) -> dict:\\n    \"\"\"Generate final recommendations based on all analyses.\"\"\"\\n    code = state[\"code\"]\\n    prompt = f\"\"\"Analyze all previous results and provide final recommendations for this code:\\nStyle Analysis: {json.dumps(state.get(\\'style_analysis\\', {}))}\\nSecurity Analysis: {json.dumps(state.get(\\'security_analysis\\', {}))}\\nPerformance Analysis: {json.dumps(state.get(\\'performance_analysis\\', {}))}\\nArchitecture Analysis: {json.dumps(state.get(\\'architecture_analysis\\', {}))}\\nProvide your response in JSON format with these exact keys:\\n{{\\n    \"critical_issues\": [\"list of most critical issues\"],\\n    \"priority_improvements\": [\"list of high-priority improvements\"],\\n    \"quick_wins\": [\"list of easy-to-implement improvements\"],\\n    \"long_term_suggestions\": [\"list of long-term improvements\"],\\n    \"overall_health_score\": \"1-10 score as a number\"\\n}}\"\"\"\\nrecommendations = call_huggingface_api(prompt)\\nif \"error\" in recommendations:\\n    recommendations = {\\n        \"critical_issues\": [\"Error generating recommendations\"],\\n        \"priority_improvements\": [\"Try again later\"],\\n        \"quick_wins\": [],\\n        \"long_term_suggestions\": [],\\n        \"overall_health_score\": 0\\n    }\\n\\nmessages = state[\"messages\"] + [AIMessage(content=\"Generated final recommendations\")]\\nreturn {**state, \"messages\": messages, \"final_recommendations\": recommendations, \"current_step\": \"end\"}\\n\\ndef format_output(state: State) -> str:\\n    \"\"\"Format the analysis results into a readable output.\"\"\"\\n    output = \"\"\"üîç Code Analysis Report\\nüé® Style & Best Practices\\n\"\"\"\\n    style = state.get(\"style_analysis\", {})\\n    output += f\"Rating: {style.get(\\'overall_rating\\', \\'N/A\\')}/10\\\\n\"\\n    output += \"Issues:\\\\n\" + \"\\\\n\".join([f\"‚Ä¢ {issue}\" for issue in style.get(\"issues\", [])]) + \"\\\\n\\\\n\"\\noutput += \"\"\"üîí Security Analysis\\n\\n\"\"\"\\n    security = state.get(\"security_analysis\", {})\\n    output += f\"Score: {security.get(\\'overall_security_score\\', \\'N/A\\')}/10\\\\n\"\\n    vulnerabilities = security.get(\"vulnerabilities\", [])\\n    risk_levels = security.get(\"risk_levels\", {})\\n    output += \"Vulnerabilities:\\\\n\" + \"\\\\n\".join([f\"‚Ä¢ {v} ({risk_levels.get(v, \\'Unknown\\')})\" for v in vulnerabilities]) + \"\\\\n\\\\n\"\\noutput += \"\"\"‚ö° Performance Analysis\\n\\n\"\"\"\\n    perf = state.get(\"performance_analysis\", {})\\n    output += f\"Score: {perf.get(\\'performance_score\\', \\'N/A\\')}/10\\\\n\"\\n    output += \"Bottlenecks:\\\\n\" + \"\\\\n\".join([f\"‚Ä¢ {b}\" for b in perf.get(\"bottlenecks\", [])]) + \"\\\\n\\\\n\"\\noutput += \"\"\"üèóÔ∏è Architecture Analysis\\n\\n\"\"\"\\n    arch = state.get(\"architecture_analysis\", {})\\n    output += f\"Score: {arch.get(\\'architecture_score\\', \\'N/A\\')}/10\\\\n\"\\n    output += \"Patterns:\\\\n\" + \"\\\\n\".join([f\"‚Ä¢ {p}\" for p in arch.get(\"patterns_identified\", [])]) + \"\\\\n\\\\n\"\\noutput += \"\"\"üìã Final Recommendations\\n\\n\"\"\"\\n    final = state.get(\"final_recommendations\", {})\\n    output += f\"Overall Health Score: {final.get(\\'overall_health_score\\', \\'N/A\\')}/10\\\\n\\\\n\"\\n    output += \"Critical Issues:\\\\n\" + \"\\\\n\".join([f\"‚Ä¢ {i}\" for i in final.get(\"critical_issues\", [])]) + \"\\\\n\\\\n\"\\n    output += \"Priority Improvements:\\\\n\" + \"\\\\n\".join([f\"‚Ä¢ {i}\" for i in final.get(\"priority_improvements\", [])])\\nreturn output\\n\\nCreate and setup graph\\nworkflow = StateGraph(State)\\nAdd nodes\\nworkflow.add_node(\"style\", analyze_code_style)\\nworkflow.add_node(\"security\", analyze_security)\\nworkflow.add_node(\"performance\", analyze_performance)\\nworkflow.add_node(\"architecture\", analyze_architecture)\\nworkflow.add_node(\"recommendations\", generate_final_recommendations)\\nAdd edges\\nworkflow.add_edge(\"style\", \"security\")\\nworkflow.add_edge(\"security\", \"performance\")\\nworkflow.add_edge(\"performance\", \"architecture\")\\nworkflow.add_edge(\"architecture\", \"recommendations\")\\nSet entry and finish points\\nworkflow.set_entry_point(\"style\")\\nworkflow.set_finish_point(\"recommendations\")\\nCompile the workflow\\nagent = workflow.compile()\\ndef analyze_code(code: str) -> str:\\n    \"\"\"Analyze the provided code using multiple perspectives.\"\"\"\\n    initial_state = State(\\n        messages=[SystemMessage(content=\"Starting code analysis...\")],\\n        current_step=\"style\",\\n        code=code,\\n        style_analysis={},\\n        security_analysis={},\\n        performance_analysis={},\\n        architecture_analysis={},\\n        final_recommendations={}\\n    )\\nfinal_state = agent.invoke(initial_state)\\nreturn format_output(final_state)\\n\\nCreate Gradio interface\\niface = gr.Interface(\\n    fn=analyze_code,\\n    inputs=gr.Code(\\n        label=\"Enter your code for analysis\",\\n        language=\"python\",\\n        lines=20\\n    ),\\n    outputs=gr.Textbox(\\n        label=\"Analysis Results\",\\n        lines=25\\n    ),\\n    title=\"üîç Code Architecture Critic\",\\n    description=\"Paste your code to get a comprehensive analysis of style, security, performance, and architecture.\",\\n    examples=[\\n        [\\'\\'\\'def process_data(data):\\n    result = []\\n    for i in range(len(data)):\\n        for j in range(len(data)):\\n            if data[i] + data[j] == 10:\\n                result.append((data[i], data[j]))\\n    return result\\ndef save_to_db(user_input):\\n    query = \"INSERT INTO users VALUES (\\'\" + user_input + \"\\')\"\\n    db.execute(query)\\nAPI_KEY = \"sk_test_123456789\"\\'\\'\\']\\n    ],\\n    theme=gr.themes.Soft()\\n)\\nif name == \"main\":\\n    iface.launch() \\n```\\nConclusion#\\nLangGraph makes it easier to build AI agents that need to manage complex workflows. The graph-based approach keeps things organised and flexible, especially when dealing with multi-step processes or memory.\\nEven though LangGraph doesn‚Äôt come with built-in server features, it works well with FastAPI and other frameworks to serve agents as APIs. Whether you‚Äôre building a chatbot, a code reviewer, or something else entirely, it gives you a solid foundation to work with.\\nI‚Äôm still experimenting and learning, so I‚Äôll keep updating this post as I find better ways to use LangGraph. If you‚Äôve built something cool with it or have any questions, let me know‚Äîhappy to chat!\\nResources#\\n\\nLangGraph Documentation\\nFastAPI Documentation\\nLangChain (LangGraph is part of the LangChain ecosystem)\\n\\nI hope you like this article, if you want to hear more follow me on X at @juanstoppa where I regularly post about AI\\n\\nLanggraph\\nAi-Agents\\nLangchain\\nPython\\n\\n¬´ Prev How to Create a Model Context Protocol (MCP) to give context to an LLM Next ¬ª Initial look at ChatGPT with Canvas\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n¬© 2025 Juan Stoppa ¬∑ Powered by Hugo & PaperMod\\n'},\n",
              "   {'title': 'LangGraph Basics: Understanding State, Schema, Nodes, and Edges',\n",
              "    'url': 'https://medium.com/@vivekvjnk/langgraph-basics-understanding-state-schema-nodes-and-edges-77f2fd17cae5',\n",
              "    'content': 'Listen\\nShare\\nLangGraph is a message-passing framework for building modular, graph-based systems. At its core, it focuses on communication between nodes via structured states and logical edges, enabling a flexible and efficient workflow. Let‚Äôs break down the core concepts:\\n1. What is a State?\\nIn LangGraph, the state is the central mechanism for communication between nodes. It acts as a structured message that encapsulates the current snapshot of the system at any given moment. [...] The schema helps nodes interpret the state correctly, ensuring smooth execution across the graph.\\nLangGraph Basics: Understanding State, Schema, Nodes, and Edges\\nLangGraph is a message-passing framework for building modular, graph-based systems. At its core, it focuses on communication between nodes via structured states and logical edges, enabling a flexible and efficient workflow. Let‚Äôs break down the core concepts:\\n1. What is a State?',\n",
              "    'score': 0.9154545,\n",
              "    'raw_content': 'Published Time: 2024-12-15T15:58:51.867Z\\nLangGraph Basics: Understanding State, Schema, Nodes, and Edges | by Story_Teller | Medium\\nOpen in app\\nSign up\\nSign in\\n\\nWrite\\n\\nSign up\\nSign in\\n\\nLangGraph Basics: Understanding State, Schema, Nodes, and Edges\\n\\nStory_Teller\\n¬∑Follow\\n5 min read\\n¬∑\\nDec 15, 2024\\n\\n16\\n\\nListen\\nShare\\nLangGraph is a message-passing framework for building modular, graph-based systems. At its core, it focuses on communication between nodes via structured states and logical edges, enabling a flexible and efficient workflow. Let‚Äôs break down the core concepts:\\n1. What is a State?\\nIn LangGraph, the state is the central mechanism for communication between nodes. It acts as a structured message that encapsulates the current snapshot of the system at any given moment.\\nAccording to the LangGraph documentation:\\n\\n‚ÄúA state is a shared data structure that represents the current snapshot of your application.‚Äù\\n\\nStates are passed along edges between nodes, carrying the output of one node to the next as input. This makes the state the backbone of any message-passing graph.\\n2. What is a Schema in LangGraph?\\nA schema defines the structure of the state. It ensures the data being passed between nodes follows a consistent format.\\n\\nIn Python terms, a schema can be any data type.\\nHowever, it is typically represented using TypedDict or a Pydantic BaseModel.\\n\\nThe schema helps nodes interpret the state correctly, ensuring smooth execution across the graph.\\nLangGraph Basics: Understanding State, Schema, Nodes, and Edges\\nLangGraph is a message-passing framework for building modular, graph-based systems. At its core, it focuses on communication between nodes via structured states and logical edges, enabling a flexible and efficient workflow. Let‚Äôs break down the core concepts:\\n1. What is a State?\\nIn LangGraph, the state is the central mechanism for communication between nodes. It acts as a structured message that encapsulates the current snapshot of the system at any given moment.\\nAccording to the LangGraph documentation:\\n\\n‚ÄúA state is a shared data structure that represents the current snapshot of your application.‚Äù\\n\\nStates are passed along edges between nodes, carrying the output of one node to the next as input. This makes the state the backbone of any message-passing graph.\\n2. What is a Schema in LangGraph?\\nA schema defines the structure of the state. It ensures the data being passed between nodes follows a consistent format.\\n\\nIn Python terms, a schema can be any data type.\\nHowever, it is typically represented using TypedDict or a Pydantic BaseModel.\\n\\nThe schema helps nodes interpret the state correctly, ensuring smooth execution across the graph.\\n3. Nodes vs. Edges: What‚Äôs the Difference?\\nLangGraph can be visualized as a program of programs. It consists of:\\n\\nNodes: Perform the actual work. Nodes contain Python code that can execute any logic, from simple computations to LLM calls or integrations.\\nEdges: Define what happens next. Edges determine the flow of the state between nodes.\\n\\nNodes&Edges: A Messaging App Analogy\\nTo understand the role of edges in LangGraph, let‚Äôs use a relatable analogy: a messaging application on our smartphones.\\nIn this metaphor:\\n\\nWe (humans) represent the nodes.\\nThe edges are the connections or chat threads we create to communicate with others.\\n\\nHere‚Äôs how this analogy maps to LangGraph:\\n\\nDrawing the Edge:\\n    When we want to communicate with someone, we open the messaging app and select the correct chatbox. This action of choosing the chat creates an edge ‚Äî it establishes a connection between two nodes (you and the recipient).\\n\\nInteracting Through the App:\\n    Once the connection (edge) is established, we interact with the app in various ways:\\n\\n\\nHolding the mic button to send a voice message.\\n\\nTyping a text message of any length.\\nCapturing and sending a video using the camera feature.\\n\\nEach of these interactions follows a well-structured sequence of events specific to the messaging app. For example:\\n\\nA text message has a specific format (sender, recipient, message content).\\nA voice message includes data like audio duration and file size.\\nA video message involves capturing, compressing, and attaching a media file.\\n\\nThese predefined structures in the messaging app are synonymous with the schema of the state in LangGraph. Just as a messaging app ensures all interactions (messages) follow a consistent format, the schema in LangGraph ensures the state passed along edges is structured and interpretable.\\nLangGraph‚Äôs Simplicity:\\nThe key difference lies in complexity. In a messaging app, interactions are event-driven and dynamic (e.g., pressing buttons, recording audio, typing text). However, in LangGraph, the schema of the state is much simpler and defined at static time ‚Äî meaning it is established before execution rather than evolving during runtime.\\nThis static schema allows nodes to rely on a consistent state format, ensuring seamless communication along edges throughout the graph.\\nSimple Graph for Structured parsing with fallback\\nFollowing illustrations represents a simple and structured parser workflow with an integrated retry mechanism to handle errors during the parsing process.\\nThrough this illustration let‚Äôs try to understand modular nature of nodes and relevance of edges in the graph. Each node takes state input and yields updated state as output. Sometimes nodes do nothing to the input state and spits out the same state as output.\\nIf we provide proper input state to each individual nodes, they would provide the expected output. ie They are completely modular code sections on their own. Thus with sufficient interface engineering we can implement any graph built using LangGraph without any framework.\\n\\nGraph without edges connecting nodes\\nFollowing image shows the proper graph structure of the Structured Ouptut Parser with Fallback\\nMajor difference is the directed edges connecting different blocks in a logical fashion. These logical connections themselves become some sort of a program. LangGraph framework provides large verity of methods and mechanism to implement such such graphs while still maintaining the modularity.\\n\\nSame graph with directed edges\\nConclusion\\nIn this article, we explored the foundational concepts of graph-based systems, drawing parallels to familiar messaging applications to illustrate how edges, nodes, and state transitions function seamlessly in dynamic workflows. We then delved into a structured parser graph with an integrated retry mechanism, showcasing how LangGraph-like frameworks manage complex processes efficiently.\\nReference : https://langchain-ai.github.io/langgraph/concepts/low_level/\\n\\nSign up to discover human stories that deepen your understanding of the world.\\nFree\\nDistraction-free reading. No ads.\\nOrganize your knowledge with lists and highlights.\\nTell your story. Find your audience.\\nSign up for free\\nMembership\\nRead member-only stories\\nSupport writers you read most\\nEarn money for your writing\\nListen to audio narrations\\nRead offline with the Medium app\\nTry for $5/month\\nLanggraph\\nGraph Theory\\nAgentic\\nAgentic Ai\\nAgentic Workflow\\n\\n16\\n\\n16\\n\\n\\n\\nFollow\\n\\nWritten by Story_Teller ------------------------\\n24 Followers\\n¬∑5 Following\\nAlways a curious student\\nFollow\\n\\nNo responses yet\\n\\n\\nWrite a response\\nWhat are your thoughts?\\nCancel\\nRespond\\nMore from Story_Teller\\n\\n\\nStory_Teller\\nIntroduction to Tool Use with LangGraph‚Äôs ToolNode -------------------------------------------------- ### Modern AI applications often require seamless integration of external tools to enhance their capabilities. Tools are external utilities or‚Ä¶\\nDec 14, 2024\\n11 4\\n\\n\\n\\nStory_Teller\\nThe Command Object in Langgraph ------------------------------- ### What is the Command Object in Langgraph?\\nDec 24, 2024\\n9\\n\\n\\n\\nStory_Teller\\nUnderstanding Leiden vs Louvain Clustering: Hierarchy and Subset Properties --------------------------------------------------------------------------- ### 1. Hierarchical Nature of Clustering\\nJan 12\\n1\\n\\n\\n\\nStory_Teller\\nInterrupt Function: Overcoming BSP Limitations to Enable Human-in-the-Loop Workflows in LangGraph ------------------------------------------------------------------------------------------------- ### Why Is the Implementation of Human-In-The-Loop (HIL) Interactions So Difficult In Frameworks Like LangGraph?\\nDec 26, 2024\\n\\n\\nSee all from Story_Teller\\nRecommended from Medium\\n\\n\\nMinyang Chen\\nBuilding Code Agent from scratch using Langgraph ------------------------------------------------ ### Motivation\\nMar 5\\n8\\n\\n\\n\\nKamal Dhungana\\nGetting Started with Local and Remote MCP Servers in LangChain: A Hands-On Beginner‚Äôs Guide ------------------------------------------------------------------------------------------- ### Model Context Protocol (MCP) is an emerging standard designed to bridge the gap between Large Language Models (LLMs) and external tools or‚Ä¶\\nApr 9\\n138 1\\n\\n\\n\\nIn\\nAlgoMart\\nby\\nYash Jain\\nCreate Your First Multi-Agent Assistant Using LangChain & LangGraph ------------------------------------------------------------------- ### If you have recently been building AI applications using large language models (LLM), you are likely to have used LangChain ü¶ú. LangChain‚Ä¶\\nMar 31\\n37 1\\n\\n\\n\\nAreeba Ayub\\nUsing LangGraph Memory for Persistent Chat Conversations -------------------------------------------------------- ### I‚Äôm currently working on a chatbot and exploring memory systems in LangGraph. During my research, I found the information to be quite‚Ä¶\\nApr 1\\n5\\n\\n\\n\\nMinyang Chen\\nEmulate the investment strategies of today‚Äôs famous hedge fund managers with Agentic AI. ---------------------------------------------------------------------------------------- ### The stock market involves numerous statistics and patterns. Stock trading is grounded in research and data-driven decision-making. The use‚Ä¶\\nMar 25\\n50\\n\\n\\n\\nIn\\nAI Agents\\nby\\nSantosh Rout\\nLangGraph for Beginners, Part 3: Conditional Edges -------------------------------------------------- ### In this article, we will create a simple graph that explains conditional edges in LangGraph.\\nOct 24, 2024\\n41 1\\n\\nSee more recommendations\\nHelp\\nStatus\\nAbout\\nCareers\\nPress\\nBlog\\nPrivacy\\nRules\\nTerms\\nText to speech'},\n",
              "   {'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
              "    'title': 'What Is LangGraph and How to Use It? - DataCamp',\n",
              "    'content': 'LangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner.\\nIt simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing agent runtimes. With LangGraph, we can easily build robust, scalable, and flexible multi-agent systems. [...] Home\\nTutorials\\nArtificial Intelligence\\n\\nLangGraph Tutorial: What Is LangGraph and How to Use It?\\nLangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.\\nContents\\nJun 26, 2024 \\xa0¬∑ 12 min read\\nContents\\n\\nWhat Is LangGraph?\\nGraph structure\\nState management\\n\\nCoordination\\n\\n\\nWhy LangGraph?\\n\\nSimplified development\\nFlexibility\\nScalability\\n\\nFault tolerance [...] If you want to learn more about the LangChain ecosystem, I recommend this introduction to LangChain.\\nWhat Is LangGraph?\\nLangGraph enables us to create stateful, multi-actor applications utilizing LLMs as easily as possible. It extends the capabilities of LangChain, introducing the ability to create and manage cyclical graphs, which are pivotal for developing sophisticated agent runtimes. The core concepts of LangGraph include: graph structure, state management, and coordination.\\nGraph structure',\n",
              "    'score': 0.914176,\n",
              "    'raw_content': 'Published Time: 2024-06-26T21:00:00.000Z\\nLangGraph Tutorial: What Is LangGraph and How to Use It? | DataCamp\\n ##### Get 50% off unlimited learning Buy Now\\nSkip to main content\\nWrite for us\\nEN\\nEnglishEspa√±olBetaPortugu√™sBetaDeutschBetaFran√ßaisBeta\\n\\nFound an Error?\\nLog InGet Started\\nTutorials\\nBlogs\\nTutorials\\ndocs\\nPodcasts\\nCheat Sheets\\ncode-alongs\\nCategory\\nCategory\\nTechnologies\\nDiscover content by tools and technology\\nArtificial IntelligenceAWSAzureBusiness IntelligenceChatGPTDatabricksdbtDockerExcelGenerative AIGitGoogle Cloud PlatformHugging FaceJavaJuliaKubernetesLarge Language ModelsOpenAIPostgreSQLPower BIPythonRScalaSnowflakeSpreadsheetsSQLSQLiteTableau\\nCategory\\nTopics\\nDiscover content by data science topics\\nAI for BusinessBig DataCareer ServicesCloudData AnalysisData EngineeringData LiteracyData ScienceData VisualizationDataLabDeep LearningMachine LearningMLOpsNatural Language Processing\\nRequest a Demo\\ncategory\\n\\nHome\\nTutorials\\nArtificial Intelligence\\n\\nLangGraph Tutorial: What Is LangGraph and How to Use It?\\nLangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.\\nContents\\nJun 26, 2024 \\xa0¬∑ 12 min read\\nContents\\n\\nWhat Is LangGraph?\\nGraph structure\\nState management\\n\\nCoordination\\n\\n\\nWhy LangGraph?\\n\\nSimplified development\\nFlexibility\\nScalability\\n\\nFault tolerance\\n\\n\\nGetting Started With LangGraph\\n\\nInstallation\\n\\nBasic Concepts\\n\\n\\nBuilding a Simple LangGraph Application\\n\\nStep 1: Define the StateGraph\\nStep 2: Initialize an LLM and add it as a Chatbot node\\nStep 3: Set edges\\n\\nStep 5: Run the chatbot\\n\\n\\nAdvanced LangGraph Features\\n\\nCustom node types\\nEdge types\\n\\nError handling\\n\\n\\nReal-World Applications of LangGraph\\n\\nChatbots\\nAutonomous agents\\nMulti-Agent systems\\nWorkflow automation tools\\nRecommendation systems\\n\\nPersonalized learning environments\\n\\n\\nConclusion\\n\\n\\nTraining more people?\\nGet your team access to the full DataCamp for business platform.\\nFor BusinessFor a bespoke solution book a demo.\\nImagine you\\'re building a complex, multi-agent large language model (LLM) application. It\\'s exciting, but it comes with challenges: managing the state of various agents, coordinating their interactions, and handling errors effectively. This is where LangGraph can help.\\nLangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner.\\nIt simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing agent runtimes. With LangGraph, we can easily build robust, scalable, and flexible multi-agent systems.\\nIf you want to learn more about the LangChain ecosystem, I recommend this introduction to LangChain.\\nWhat Is LangGraph?\\nLangGraph enables us to create stateful, multi-actor applications utilizing LLMs as easily as possible. It extends the capabilities of LangChain, introducing the ability to create and manage cyclical graphs, which are pivotal for developing sophisticated agent runtimes. The core concepts of LangGraph include: graph structure, state management, and coordination.\\nGraph structure\\nImagine your application as a directed graph. In LangGraph, each node represents an LLM agent, and the edges are the communication channels between these agents. This structure allows for clear and manageable workflows, where each agent performs specific tasks and passes information to other agents as needed.\\nState management\\nOne of LangGraph\\'s standout features is its automatic state management. This feature enables us to track and persist information across multiple interactions. As agents perform their tasks, the state is dynamically updated, ensuring the system maintains context and responds appropriately to new inputs.\\nCoordination\\nLangGraph ensures agents execute in the correct order and that necessary information is exchanged seamlessly. This coordination is vital for complex applications where multiple agents need to work together to achieve a common goal. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination.\\nWhy LangGraph?\\nAs I mentioned above, LangGraph offers several significant advantages for developers working with complex LLM applications. Here are some of the real-world benefits LangGraph offers.\\nSimplified development\\nLangGraph abstracts away the complexities associated with state management and agent coordination. This means developers can define their workflows and logic without worrying about the underlying mechanisms that ensure data consistency and proper execution order. This simplification accelerates the development process and reduces the likelihood of errors. It‚Äôs a game-changer!\\nFlexibility\\nWith LangGraph, developers have the flexibility to define their own agent logic and communication protocols. This allows for highly customized applications tailored to specific use cases. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. It‚Äôs all about giving you the power to create.\\nScalability\\nLangGraph is built to support the execution of large-scale multi-agent applications. Its robust architecture can handle a high volume of interactions and complex workflows, enabling the development of scalable systems that can grow with your needs. This makes it suitable for enterprise-level applications and scenarios where performance and reliability are critical.\\nFault tolerance\\nReliability is a core consideration in the design of LangGraph. The library includes mechanisms for gracefully handling errors, ensuring that your application can continue to operate even when individual agents encounter issues. This fault tolerance is essential for maintaining the stability and robustness of complex multi-agent systems. Peace of mind is just a feature away.\\nGetting Started With LangGraph\\nLet‚Äôs see how we can set up LangGraph and what the basic concepts are.\\nInstallation\\nTo install LangGraph, you can use pip:\\npip install -U langgraph\\nPowered By \\nWas this helpful? Yes No\\nBasic Concepts\\nNodes: Nodes represent units of work within your LangGraph. They are typically Python functions that perform a specific task, such as:\\n\\nInteracting with an LLM\\nCalling a tool or API\\nPerforming some data manipulation\\nReceiving user input\\nExecuting business logic\\n\\nIn LangGraph, you can add nodes using the graph.add_node(name, value) syntax.\\nEdges: Edges are communication channels between nodes. They define the flow of information and the order of execution. You can add edges using the graph.add_edge(node1, node2) syntax.\\nState: The state is a central object updated over time by the nodes in the graph. It manages the internal state of your application and can be overridden or added to, depending on the application\\'s requirements. This state can hold things such as:\\n\\nConversation history: A list of messages between the agent and the user.\\nContextual data: Information relevant to the current task or interaction.\\nInternal variables: Flags, counters, or other variables to track the agent\\'s progress and behavior.\\n\\nBuilding a Simple LangGraph Application\\nHere‚Äôs a step-by-step example of creating a basic chatbot application using LangGraph.\\nStep 1: Define the StateGraph\\nDefine a StateGraph object to structure the chatbot as a state machine. The State is a class object defined with a single key messages of type List and uses the add_messages() function to append new messages rather than overwrite them.\\nfrom typing import Annotated\\nfrom typing_extensions import TypedDict\\nfrom langgraph.graph import StateGraph\\nfrom langgraph.graph.message import add_messages\\nclass State(TypedDict):\\n    # messages have the type \"list\".\\n    # The add_messages function appends messages to the list, rather than overwriting them\\n    messages: Annotated[list, add_messages]\\ngraph_builder = StateGraph(State)\\nPowered By \\nWas this helpful? Yes No\\nStep 2: Initialize an LLM and add it as a Chatbot node\\nHere, we initialize the AzureChatOpenAI model and create a simple chatbot function that takes in the state messages as input and generates a message response (which is subsequently appended to the state).\\nThis chatbot function is added as a node named ‚Äúchatbot‚Äù to the graph.\\n```\\nfrom langchain_openai import AzureChatOpenAI\\nllm = AzureChatOpenAI(\\n    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\\n    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\\n)\\ndef chatbot(state: State):\\n    return {\"messages\": [llm.invoke(state[\"messages\"])]}\\n‚Äò‚Äô‚ÄôThe first argument is the unique node name\\nThe second argument is the function or object that will be called whenever the node is used.‚Äô‚Äô‚Äô\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n```\\nPowered By \\nStep 3: Set edges\\nSince we are building a simple chatbot, we set the chatbot node as both the entry and finish points of the graph to indicate where to start and end the process.\\n```\\nSet entry and finish points\\ngraph_builder.set_entry_point(\"chatbot\")\\ngraph_builder.set_finish_point(\"chatbot\")\\n```\\nPowered By \\nWas this helpful? Yes No\\nStep 4: Compile and Visualize the Graph\\nCompile the graph to create a CompiledGraph object, and optionally, we can visualize the graph structure using the code below:\\ngraph = graph_builder.compile()\\nfrom IPython.display import Image, display\\ntry:\\n    display(Image(graph.get_graph().draw_mermaid_png()))\\nexcept Exception:\\n    pass\\nPowered By \\nWas this helpful? Yes No\\n\\nStep 5: Run the chatbot\\nFinally, we implement a loop to continuously prompt the user for input, process it through the graph, and print the assistant\\'s response. The loop exits when the user types \"quit\", \"exit\", or \"q\".\\n```\\nRun the chatbot\\nwhile True:\\n    user_input = input(\"User: \")\\n    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\\n        print(\"Goodbye!\")\\n        break\\n    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\\n        for value in event.values():\\n            print(\"Assistant:\", value[\"messages\"][-1].content)\\n```\\nPowered By \\nWas this helpful? Yes No\\nAdvanced LangGraph Features\\nNow that we covered the basics, let‚Äôs take a look at some advanced features.\\nCustom node types\\nLangGraph allows you to create custom node types to implement complex agent logic. This provides flexibility and control over your application\\'s behavior.\\nfrom typing import Annotated\\nfrom langchain_anthropic import ChatAnthropic\\nfrom langgraph.graph import StateGraph\\nfrom langgraph.graph.message import add_messages\\nclass MyCustomNode:\\n    def __init__(self, llm):\\n        self.llm = llm\\n    def __call__(self, state):\\n        # Implement your custom logic here\\n        # Access the state and perform actions\\n        messages = state[\"messages\"]\\n        response = self.llm.invoke(messages)\\n        return {\"messages\": [response]}\\ngraph_builder = StateGraph(State)\\nllm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\\ncustom_node = MyCustomNode(llm)\\ngraph_builder.add_node(\"custom_node\", custom_node)\\nPowered By \\nWas this helpful? Yes No\\nHere, we define a class MyCustomNode that encapsulates custom logic and interacts with the LLM. This provides a more structured and maintainable way to implement complex node behaviors.\\nEdge types\\nLangGraph supports different edge types to handle various communication patterns between nodes. One useful type is the conditional edge, which allows for decision-making based on a node\\'s output.\\nTo create a conditional edge, you need three components:\\n\\nThe upstream node: The node\\'s output decides the next step.\\nA function: This function evaluates the upstream node\\'s output and determines the next node to execute, returning a string that represents the decision.\\nA mapping: This mapping links the possible outcomes of the function to the corresponding nodes to be executed.\\n\\nHere\\'s an example in pseudocode:\\ngraph.add_conditional_edge(\\n    \"model\",\\n    should_continue,\\n    {\\n        \"end\": END,\\n        \"continue\": \"tools\"\\n    }\\n)\\nPowered By \\nWas this helpful? Yes No\\nHere, after the ‚Äúmodel‚Äù node is called, we can either exit the graph (‚Äùend‚Äù) and return to the user, or we can continue (‚Äùcontinue‚Äù) and call a tool‚Äîdepending on what the user decides!\\nState management\\nLangGraph offers powerful state management techniques, which include using external databases like SQLite, PostgreSQL, and MongoDB, or cloud storage solutions like Amazon S3, Google Cloud Storage, and Azure Blob Storage to store and retrieve your agent\\'s state, enabling reliability and scalability.\\nHere\\'s an example of using a SQLite database for state management:\\n```\\nfrom langgraph.checkpoint.sqlite import SqliteSaver\\nConnect to the SQLite database\\nmemory = SqliteSaver.from_conn_string(\":memory:\")\\nCompile the graph with the checkpointer\\ngraph = graph_builder.compile(checkpointer=memory)\\n```\\nPowered By \\nWas this helpful? Yes No\\nError handling\\nLangGraph also provides mechanisms for error handling:\\n\\nExceptions: Node functions can raise exceptions to signal errors during execution. You can catch and handle these exceptions to prevent your graph from crashing.\\nRetry mechanisms: You can implement retry logic within your nodes to handle transient errors, such as network issues or API timeouts.\\nLogging: Use logging to record errors and track the execution of your graph.\\n\\nReal-World Applications of LangGraph\\nLangGraph can be used to build a wide range of applications.\\nChatbots\\nLangGraph is ideal for developing sophisticated chatbots that can handle a wide array of user requests. By leveraging multiple LLM agents, these chatbots can process natural language queries, provide accurate responses, and seamlessly switch between different conversation topics. The ability to manage state and coordinate interactions ensures that the chatbot maintains context and delivers a coherent user experience.\\nAutonomous agents\\nFor applications requiring autonomous decision-making, LangGraph enables the creation of agents that can perform tasks independently based on user inputs and predefined logic.\\nThese agents can execute complex workflows, interact with other systems, and adapt to new information dynamically. LangGraph\\'s structured framework ensures that each agent operates efficiently and effectively, making it suitable for tasks like automated customer support, data processing, and system monitoring.\\nMulti-Agent systems\\nLangGraph excels in building applications where multiple agents collaborate to achieve a common goal. For example, different agents can manage inventory, process orders, and coordinate deliveries in a supply chain management system. LangGraph\\'s coordination capabilities ensure that each agent communicates effectively, sharing information and making decisions in a synchronized manner. This leads to more efficient operations and better overall system performance.\\nWorkflow automation tools\\nWith LangGraph, automating business processes and workflows becomes straightforward. Intelligent agents can be designed to handle tasks such as document processing, approval workflows, and data analysis. By defining clear workflows and leveraging LangGraph\\'s state management, these tools can execute complex sequences of actions without human intervention, reducing errors and increasing productivity.\\nRecommendation systems\\nPersonalized recommendation systems can greatly benefit from LangGraph\\'s capabilities. By employing multiple agents to analyze user behavior, preferences, and contextual data, these systems can deliver tailored suggestions for products, content, or services. LangGraph\\'s flexibility allows for integrating various data sources and algorithms, enhancing the accuracy and relevance of recommendations.\\nPersonalized learning environments\\nIn educational platforms, LangGraph can be used to create adaptive learning environments that cater to individual learning styles and needs. Multiple agents can assess a student\\'s progress, provide customized exercises, and offer real-time feedback. The stateful nature of LangGraph ensures that the system retains information about each learner\\'s performance and preferences, enabling a more personalized and effective educational experience.\\nConclusion\\nLangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.\\nPotential developments for LangGraph include integration with other LangChain components, support for new LLM models, and the introduction of more advanced agent runtimes from academia.\\nIf you want to learn more about developing applications within the LangChain ecosystem, I recommend this course on developing LLM applications with LangChain.\\n\\n\\nAuthor\\nRyan Ong\\n\\nRyan is a lead data scientist specialising in building AI applications using LLMs. He is a PhD candidate in Natural Language Processing and Knowledge Graphs at Imperial College London, where he also completed his Master‚Äôs degree in Computer Science. Outside of data science, he writes a weekly Substack newsletter,\\xa0The Limitless Playbook, where he shares one actionable idea from the world\\'s top thinkers and occasionally writes about core AI concepts.\\nTopics\\nArtificial IntelligencePython\\n\\n\\nRyan OngI write about AI research, entrepreneurship, and self-development.\\n\\nTopics\\nArtificial IntelligencePython\\n### LangGraph Studio Guide: Installation, Set Up, Use Cases\\n### Introduction to LangChain for Data Engineering & Data Applications\\n### How to Build LLM Applications with LangChain Tutorial\\n### Building LangChain Agents to Automate Tasks in Python\\n### Building Context-Aware Chatbots: Leveraging LangChain Framework for ChatGPT\\n### Building AI Applications with LangChain and GPT\\nLearn AI with these courses!\\nCourse\\nDeveloping LLM Applications with LangChain\\n3 hr\\n12.7K\\nDiscover how to build AI-powered applications using LLMs, prompts, chains, and agents in LangChain.\\nSee DetailsStart Course\\nCourse\\nDeveloping LLM Applications with LangChain\\n3 hr\\n12.7K\\nDiscover how to build AI-powered applications using LLMs, prompts, chains, and agents in LangChain.\\nSee DetailsStart Course\\nTrack\\nAI Business Fundamentals\\n11hrs hr\\nAccelerate your AI journey, conquer ChatGPT, and develop a comprehensive Artificial Intelligence strategy.\\nSee DetailsStart Course\\nSee More\\nRelated\\nTutorial ### LangGraph Studio Guide: Installation, Set Up, Use Cases\\nLangGraph Studio is a visual development environment for LangChain‚Äôs LangGraph framework, simplifying the development of complex agentic applications built with LangChain components.\\n\\nDr Ana Rojo-Echebur√∫a\\n8 min\\nTutorial ### Introduction to LangChain for Data Engineering & Data Applications\\nLangChain is a framework for including AI from large language models inside data pipelines and applications. This tutorial provides an overview of what you can do with LangChain, including the problems that LangChain solves and examples of data use cases.\\n\\nRichie Cotton\\n11 min\\nTutorial ### How to Build LLM Applications with LangChain Tutorial\\nExplore the untapped potential of Large Language Models with LangChain, an open-source Python framework for building advanced AI applications.\\n\\nMoez Ali\\n12 min\\nTutorial ### Building LangChain Agents to Automate Tasks in Python\\nA comprehensive tutorial on building multi-tool LangChain agents to automate tasks in Python using LLMs and chat models using OpenAI.\\n\\nBex Tuychiev\\n14 min\\nTutorial ### Building Context-Aware Chatbots: Leveraging LangChain Framework for ChatGPT\\nExplore how to build context-aware chatbots using the ChatGPT and LangChain framework.\\n\\nAndrea Valenzuela\\n15 min\\ncode-along ### Building AI Applications with LangChain and GPT\\nIn the live training, you\\'ll use LangChain to build a simple AI application, including preparing and indexing data, prompting the AI, and generating responses.\\n\\nEmmanuel Pire\\nSee MoreSee More\\nGrow your data skills with DataCamp for Mobile\\nMake progress on the go with our mobile courses and daily 5-minute coding challenges.\\nDownload on the App StoreGet it on Google Play\\nLearn\\nLearn PythonLearn AILearn Power BILearn Data EngineeringAssessmentsCareer TracksSkill TracksCoursesData Science Roadmap\\nData Courses\\nPython CoursesR CoursesSQL CoursesPower BI CoursesTableau CoursesAlteryx CoursesAzure CoursesAWS CoursesGoogle Sheets CoursesExcel CoursesAI CoursesData Analysis CoursesData Visualization CoursesMachine Learning CoursesData Engineering CoursesProbability & Statistics Courses\\nDataLab\\nGet StartedPricingSecurityDocumentation\\nCertification\\nCertificationsData ScientistData AnalystData EngineerSQL AssociatePower BI Data AnalystTableau Certified Data AnalystAzure FundamentalsAI Fundamentals\\nResources\\nResource CenterUpcoming EventsBlogCode-AlongsTutorialsDocsOpen SourceRDocumentationBook a Demo with DataCamp for BusinessData Portfolio\\nPlans\\nPricingFor StudentsFor BusinessFor UniversitiesDiscounts, Promos & SalesDataCamp Donates\\nFor Business\\nBusiness PricingTeams PlanData & AI Unlimited PlanCustomer StoriesPartner Program\\nAbout\\nAbout UsLearner StoriesCareersBecome an InstructorPressLeadershipContact UsDataCamp Espa√±olDataCamp Portugu√™sDataCamp DeutschDataCamp Fran√ßais\\nSupport\\nHelp CenterBecome an Affiliate\\nFacebookTwitterLinkedInYouTubeInstagram\\nPrivacy PolicyCookie NoticeDo Not Sell My Personal InformationAccessibilitySecurityTerms of Use\\n¬© 2025 DataCamp, Inc. All Rights Reserved.\\n\\n\\n\\nEnroll Enroll Learn the\\nfundamentals of AI Check Out All AI Courses ‚úï Perfect thank you! X \"\" has been copied to the clipboardShake To Reaveal Voucher [close] X Click me for great offers... Thanks... your code is: X'},\n",
              "   {'url': 'https://langchain-ai.github.io/langgraph/',\n",
              "    'title': 'LangGraph - GitHub Pages',\n",
              "    'content': 'Note\\nLooking for the JS version? See the JS repo and the JS docs.\\nLangGraph ‚Äî used by Replit, Uber, LinkedIn, GitLab and more ‚Äî is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration ‚Äî offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.',\n",
              "    'score': 0.914176,\n",
              "    'raw_content': 'LangGraph\\nSkip to content\\nJoin us at Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!\\n \\nLangGraph\\n\\nInitializing search\\nGitHub\\n\\nHome\\nAPI reference\\n\\n \\nGitHub\\n\\n\\n[ ] \\nHome\\nHome\\n\\n\\n[ ]  Get started\\nGet started\\n\\nLearn the basics\\nDeployment\\n\\n\\n\\n[ ]  Guides\\nGuides\\n\\nHow-to Guides\\nConcepts\\nTutorials\\n\\n\\n\\n[ ]  Resources\\nResources\\n\\nPrebuilt Agents\\nCompanies using LangGraph\\nLLMS-txt\\nFAQ\\nTroubleshooting\\nLangGraph Academy Course\\n\\n\\n\\n\\n\\nAPI reference\\n\\n\\nTable of contents\\n\\nWhy use LangGraph?\\nLangGraph‚Äôs ecosystem\\nPairing with LangGraph Platform\\nAdditional resources\\nAcknowledgements\\n\\n\\nLangGraph\\n \\n\\n   \\nNote\\nLooking for the JS version? See the JS repo and the JS docs.\\nLangGraph ‚Äî used by Replit, Uber, LinkedIn, GitLab and more ‚Äî is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration ‚Äî offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-0-1)pipinstall-Ulanggraph\\nTo learn more about how to use LangGraph, check out the docs. We show a simple example below of how to create a ReAct agent.\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-1)# This code depends on pip install langchain[anthropic]\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-2)fromlanggraph.prebuiltimport create_react_agent\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-3)\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-4)defsearch(query: str):\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-5)\"\"\"Call to surf the web.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-6)    if \"sf\" in query.lower() or \"san francisco\" in query.lower():\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-7)        return \"It\\'s 60 degrees and foggy.\"\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-8)    return \"It\\'s 90 degrees and sunny.\"\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-9)\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-10)agent = create_react_agent(\"anthropic:claude-3-7-sonnet-latest\", tools=[search])\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-11)agent.invoke(\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-12)    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-13))\\nTip\\nCheck out this guide that walks through implementing common patterns (workflows and agents) in LangGraph.\\nWhy use LangGraph?¬∂\\nLangGraph is built for developers who want to build powerful, adaptable AI agents. Developers choose LangGraph for:\\n\\nReliability and controllability. Steer agent actions with moderation checks and human-in-the-loop approvals. LangGraph persists context for long-running workflows, keeping your agents on course.\\nLow-level and extensible. Build custom agents with fully descriptive, low-level primitives ‚Äì free from rigid abstractions that limit customization. Design scalable multi-agent systems, with each agent serving a specific role tailored to your use case.\\nFirst-class streaming support. With token-by-token streaming and streaming of intermediate steps, LangGraph gives users clear visibility into agent reasoning and actions as they unfold in real time.\\n\\nLangGraph is trusted in production and powering agents for companies like:\\n\\nKlarna: Customer support bot for 85 million active users\\nElastic: Security AI assistant for threat detection\\nUber: Automated unit test generation\\nReplit: Code generation\\nAnd many more (see list here)\\n\\nLangGraph‚Äôs ecosystem¬∂\\nWhile LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents. To improve your LLM application development, pair LangGraph with:\\n\\nLangSmith ‚Äî Helpful for agent evals and observability. Debug poor-performing LLM app runs, evaluate agent trajectories, gain visibility in production, and improve performance over time.\\nLangGraph Platform ‚Äî Deploy and scale agents effortlessly with a purpose-built deployment platform for long running, stateful workflows. Discover, reuse, configure, and share agents across teams ‚Äî and iterate quickly with visual prototyping in LangGraph Studio.\\n\\nPairing with LangGraph Platform¬∂\\nWhile LangGraph is our open-source agent orchestration framework, enterprises that need scalable agent deployment can benefit from LangGraph Platform.\\nLangGraph Platform can help engineering teams:\\n\\nAccelerate agent development: Quickly create agent UXs with configurable templates and LangGraph Studio for visualizing and debugging agent interactions.\\nDeploy seamlessly: We handle the complexity of deploying your agent. LangGraph Platform includes robust APIs for memory, threads, and cron jobs plus auto-scaling task queues & servers.\\nCentralize agent management & reusability: Discover, reuse, and manage agents across the organization. Business users can also modify agents without coding.\\n\\nAdditional resources¬∂\\n\\nLangChain Academy: Learn the basics of LangGraph in our free, structured course.\\nTutorials: Simple walkthroughs with guided examples on getting started with LangGraph.\\nTemplates: Pre-built reference apps for common agentic workflows (e.g. ReAct agent, memory, retrieval etc.) that can be cloned and adapted.\\nHow-to Guides: Quick, actionable code snippets for topics such as streaming, adding memory & persistence, and design patterns (e.g. branching, subgraphs, etc.).\\nAPI Reference: Detailed reference on core classes, methods, how to use the graph and checkpointing APIs, and higher-level prebuilt components.\\nBuilt with LangGraph: Hear how industry leaders use LangGraph to ship powerful, production-ready AI applications.\\n\\nAcknowledgements¬∂\\nLangGraph is inspired by Pregel and Apache Beam. The public interface draws inspiration from NetworkX. LangGraph is built by LangChain Inc, the creators of LangChain, but can be used without LangChain.\\nWas this page helpful?\\nThanks for your feedback!\\nThanks for your feedback! Please help us improve this page by adding to the discussion below.\\nBack to top\\nNext Learn the basics\\nCopyright ¬© 2025 LangChain, Inc | Consent Preferences\\nMade with Material for MkDocs Insiders\\n\\nCookie consent\\nWe use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they\\'re searching for. Clicking \"Accept\" makes our documentation better. Thank you! ‚ù§Ô∏è\\n\\nGoogle Analytics\\nGitHub\\n\\nAccept Reject'},\n",
              "   {'title': 'LangGraph: Definition, Purpose & Benefits',\n",
              "    'url': 'https://zencoder.ai/glossary/lang-graph',\n",
              "    'content': 'LangGraph is an essential tool for developers working on language-intensive software projects. By offering visual insights into language resources and fostering effective management, LangGraph contributes to the quality and functionality of language-enabled applications.',\n",
              "    'score': 0.90791017,\n",
              "    'raw_content': None}],\n",
              "  'response_time': 1.44}]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs = await run_search_queries(['langgraph'], include_raw_content=True)\n",
        "docs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "zFNI1k9bKmBP",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zFNI1k9bKmBP",
        "outputId": "8b59c514-2c61-436e-bd71-54d5d06ae8fc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[{'title': 'What is LangGraph and How to Use It for Building AI Agents',\n",
              "  'url': 'https://jstoppa.com/posts/artificial-intelligence/fundamentals/what-is-langgraph-and-how-to-use-it-for-building-ai-agents/post/',\n",
              "  'content': 'What is LangGraph?#\\nLangGraph is a framework that brings state machines to Large Language Model (LLM) applications. It‚Äôs particularly useful when you need to build complex, stateful applications with LLMs. The framework allows you to structure your application as a graph, where each node represents a specific task or state, and edges represent transitions between states.\\nBasic LangGraph Example#',\n",
              "  'score': 0.9284155,\n",
              "  'raw_content': 'Published Time: 2025-02-16T00:00:00Z\\nWhat is LangGraph and How to Use It for Building AI Agents | Juan Stoppa\\nJuan Stoppa\\n\\nArchives\\nSearch\\nTags\\n\\nWhat is LangGraph and How to Use It for Building AI Agents\\nA practical guide to LangGraph and AI agents. This covers the basics, real examples, and deployment. I wrote it to simplify LangChain\\'s complex docs and help people build stateful AI agents.\\nFebruary 16, 2025\\xa0¬∑\\xa012 min\\xa0¬∑\\xa0Juan Stoppa\\nI keep finding myself going back to the LangChain documentation to figure out how to use LangGraph. While the documentation is comprehensive, it can be overwhelming to navigate, especially when you‚Äôre trying to build advanced AI agents.\\nThis guide is my attempt to consolidate the key concepts and practical implementations of LangGraph in one place. Whether you‚Äôre building a conversational agent that needs to remember context, a multi-step reasoning agent, or a complex workflow that coordinates multiple AI components, LangGraph provides the framework to make it happen. I created this reference for myself but I hope it helps others who want a more straightforward explanation of how to use LangGraph effectively.\\nWhat is LangGraph?#\\nLangGraph is a framework that brings state machines to Large Language Model (LLM) applications. It‚Äôs particularly useful when you need to build complex, stateful applications with LLMs. The framework allows you to structure your application as a graph, where each node represents a specific task or state, and edges represent transitions between states.\\nBasic LangGraph Example#\\nLet‚Äôs start with a simple example to understand the core concepts: we are developing a simple agent that collects information and processes it, the actions of collecting and processing information are just fixed actions but they can be replaced with more complex actions.\\n\\n```python\\nfrom langgraph.graph import StateGraph\\nfrom typing import TypedDict, Annotated\\nfrom langgraph.graph.message import add_messages\\nfrom langchain_core.runnables.graph import MermaidDrawMethod\\nclass State(TypedDict):\\n    messages: Annotated[list[str], add_messages]\\n    current_step: str\\ndef collect_info(state: State) -> dict:\\n    print(\"\\\\n--> In collect_info\")\\n    print(f\"Messages before: {state[\\'messages\\']}\")\\nmessages = state[\"messages\"] + [\"Information collected\"]\\nprint(f\"Messages after: {messages}\")\\n\\nreturn {\\n    \"messages\": messages,\\n    \"current_step\": \"process\"\\n}\\n\\ndef process_info(state: State) -> dict:\\n    print(\"\\\\n--> In process_info\")\\n    print(f\"Messages before: {state[\\'messages\\']}\")\\nmessages = state[\"messages\"] + [\"Information processed\"]\\nprint(f\"Messages after: {messages}\")\\n\\nreturn {\\n    \"messages\": messages,\\n    \"current_step\": \"end\"\\n}\\n\\nCreate and setup graph\\nworkflow = StateGraph(State)\\nAdd nodes\\nworkflow.add_node(\"collect\", collect_info)\\nworkflow.add_node(\"process\", process_info)\\nAdd edges\\nworkflow.add_edge(\"collect\", \"process\")\\nSet entry and finish points\\nworkflow.set_entry_point(\"collect\")\\nworkflow.set_finish_point(\"process\")\\napp = workflow.compile()\\nRun workflow\\nprint(\"\\\\nStarting workflow...\")\\ninitial_state = State(messages=[\"Starting\"], current_step=\"collect\")\\nfinal_state = app.invoke(initial_state)\\nprint(f\"\\\\nFinal messages: {final_state[\\'messages\\']}\")\\nSave the graph visualization as PNG\\npng_data = app.get_graph().draw_mermaid_png(draw_method=MermaidDrawMethod.API)\\nwith open(\"workflow_graph.png\", \"wb\") as f:\\n    f.write(png_data)\\nprint(\"\\\\nGraph visualization saved as \\'workflow_graph.png\\'\")\\n```\\nThis example shows the basic structure of a LangGraph application:\\n\\nDefine your state using TypedDict, it contains the information that the workflow will need to keep track of.\\nCreate functions for each state, these functions are the actions that the workflow will perform.\\nBuild a graph with nodes and edges, the nodes are the states and the edges are the transitions between them.\\nCompile the graph into a runnable application, this will create a callable object that can be invoked with an initial state.\\nI also added a simple way to save the graph visualization as a PNG file, this will work if you are running this example locally and should save a file that will show the graph structure like below.\\n\\nThe graph is a good way to understand the workflow, it shows the nodes and the edges between them, the entry and finish points and the state of the workflow.\\n\\nThis particular example is not very useful but it shows the core concepts of LangGraph, you can simply replace the fixed actions with more complex ones and build a useful agent.\\nServing LangGraph as a Web Service#\\nWhile LangGraph itself doesn‚Äôt include built-in server capabilities, you can easily create a web service using FastAPI to serve your LangGraph workflows. Below I have modified the previous example to add a simple FastAPI server that allows you to run the workflow from a web interface.\\n\\n```python\\nfrom fastapi import FastAPI\\nfrom langgraph.graph import StateGraph\\nfrom typing import TypedDict, Annotated, List\\nfrom langgraph.graph.message import add_messages\\nfrom pydantic import BaseModel\\nInitialize FastAPI app\\napp = FastAPI(title=\"LangGraph Agent API\")\\nclass State(TypedDict):\\n    messages: Annotated[list[str], add_messages]\\n    current_step: str\\nclass AgentInput(BaseModel):\\n    messages: List[str]\\ndef collect_info(state: State) -> dict:\\n    print(\"\\\\n--> In collect_info\")\\n    print(f\"Messages before: {state[\\'messages\\']}\")\\nmessages = state[\"messages\"] + [\"Information collected\"]\\nprint(f\"Messages after: {messages}\")\\n\\nreturn {\\n    \"messages\": messages,\\n    \"current_step\": \"process\"\\n}\\n\\ndef process_info(state: State) -> dict:\\n    print(\"\\\\n--> In process_info\")\\n    print(f\"Messages before: {state[\\'messages\\']}\")\\nmessages = state[\"messages\"] + [\"Information processed\"]\\nprint(f\"Messages after: {messages}\")\\n\\nreturn {\\n    \"messages\": messages,\\n    \"current_step\": \"end\"\\n}\\n\\nCreate and setup graph\\nworkflow = StateGraph(State)\\nAdd nodes\\nworkflow.add_node(\"collect\", collect_info)\\nworkflow.add_node(\"process\", process_info)\\nAdd edges\\nworkflow.add_edge(\"collect\", \"process\")\\nSet entry and finish points\\nworkflow.set_entry_point(\"collect\")\\nworkflow.set_finish_point(\"process\")\\nCompile the workflow\\nagent = workflow.compile()\\n@app.post(\"/run-agent\")\\nasync def run_agent(input_data: AgentInput):\\n    \"\"\"\\n    Run the agent with the provided input messages.\\n    \"\"\"\\n    initial_state = State(messages=input_data.messages, current_step=\"collect\")\\n    final_state = agent.invoke(initial_state)\\n    return {\"messages\": final_state[\"messages\"]}\\n@app.get(\"/\")\\nasync def root():\\n    \"\"\"\\n    Root endpoint that returns basic API information.\\n    \"\"\"\\n    return {\"message\": \"LangGraph Agent API is running\", \"endpoints\": [\"Navigate to https://jstoppa-langgraph-basic-example-api.hf.space/docs#/default/run_agent_run_agent_post to run the example\"]}\\nif name == \"main\":\\n    import uvicorn\\n    uvicorn.run(app, host=\"0.0.0.0\", port=7860)\\n```\\nYou can run this locally or using the Hugging Face space below, this is the URL to access the swagger API for this example https://jstoppa-langgraph-basic-example-api.hf.space/docs, the API has an end point to run the agent and it returns the messages we‚Äôve seen in our previous example (see below the results). In simple words, the API has an end point to run the agent and it returns the messages we‚Äôve seen in our previous example.\\n\\nMaking it all work with a more interesting example#\\nWe are now going to create a more interesting example, an AI agent that does code reviews, this is far from a production-ready agent but it will give us a better understanding of how to use LangGraph.\\nThe screenshot below shows the interface for the code review agent, the user can enter a code and the agent will return a report with the code analysis. This interface uses the Gradio library to create a simple web interface, this saves a lot of time compared to building a full web app.\\n\\nThe full code is provided after this but the most impportant part of the example is the graph, it shows the nodes and the edges between them, the entry and finish points and the state of the workflow, this is how the graph will look through the code and analyse the code with different agents that are especialised on different aspects. This is a very similar apporach we‚Äôve seen in the previous example but it contains more actions and the actions do use LLMs to analyse the code.\\n```python\\nCreate and setup graph\\nworkflow = StateGraph(State)\\nAdd nodes\\nworkflow.add_node(\"style\", analyze_code_style)\\nworkflow.add_node(\"security\", analyze_security)\\nworkflow.add_node(\"performance\", analyze_performance)\\nworkflow.add_node(\"architecture\", analyze_architecture)\\nworkflow.add_node(\"recommendations\", generate_final_recommendations)\\nAdd edges\\nworkflow.add_edge(\"style\", \"security\")\\nworkflow.add_edge(\"security\", \"performance\")\\nworkflow.add_edge(\"performance\", \"architecture\")\\nworkflow.add_edge(\"architecture\", \"recommendations\")\\nSet entry and finish points\\nworkflow.set_entry_point(\"style\")\\nworkflow.set_finish_point(\"recommendations\")\\nCompile the workflow\\nagent = workflow.compile()\\n```\\nthe full code for the agent is below and it can also be found in Hugging Face below. \\n```python\\nimport gradio as gr\\nfrom langgraph.graph import StateGraph\\nfrom typing import TypedDict, Annotated, List, Dict\\nfrom langgraph.graph.message import add_messages\\nfrom langchain_core.messages import SystemMessage, HumanMessage, AIMessage\\nimport json\\nimport requests\\nimport os\\nfrom dotenv import load_dotenv\\nimport time\\nLoad environment variables\\nload_dotenv()\\nDefine the state structure\\nclass State(TypedDict):\\n    messages: Annotated[list[SystemMessage | HumanMessage | AIMessage], add_messages]\\n    current_step: str\\n    code: str\\n    style_analysis: Dict\\n    security_analysis: Dict\\n    performance_analysis: Dict\\n    architecture_analysis: Dict\\n    final_recommendations: Dict\\ndef call_huggingface_api(prompt: str, max_retries=3) -> Dict:\\n    \"\"\"Call Hugging Face API with retry logic and proper error handling.\"\"\"\\n    api_key = os.getenv(\"HUGGINGFACE_API_KEY\")\\n    if not api_key:\\n        raise ValueError(\"HUGGINGFACE_API_KEY not found in environment variables\")\\n# You can change this to any model you prefer\\nAPI_URL = \"https://api-inference.huggingface.co/models/mistralai/Mixtral-8x7B-Instruct-v0.1\"\\nheaders = {\"Authorization\": f\"Bearer {api_key}\"}\\n\\nfor attempt in range(max_retries):\\n    try:\\n        response = requests.post(\\n            API_URL,\\n            headers=headers,\\n            json={\\n                \"inputs\": prompt,\\n                \"parameters\": {\\n                    \"max_new_tokens\": 1000,\\n                    \"temperature\": 0.7,\\n                    \"top_p\": 0.95,\\n                    \"return_full_text\": False\\n                }\\n            }\\n        )\\n\\n        if response.status_code == 200:\\n            result = response.json()\\n            if isinstance(result, list) and len(result) > 0:\\n                # Extract the generated text\\n                text = result[0].get(\\'generated_text\\', \\'\\')\\n                # Try to parse as JSON if it contains JSON\\n                try:\\n                    # Find JSON content between triple backticks if present\\n                    if \"```json\" in text:\\n                        json_str = text.split(\"```json\")[1].split(\"```\")[0].strip()\\n                    else:\\n                        json_str = text.strip()\\n                    return json.loads(json_str)\\n                except json.JSONDecodeError:\\n                    return {\"error\": \"Failed to parse JSON from response\", \"raw_text\": text}\\n\\n        # If model is loading, wait and retry\\n        if response.status_code == 503:\\n            wait_time = 2 ** attempt\\n            time.sleep(wait_time)\\n            continue\\n\\n    except Exception as e:\\n        if attempt == max_retries - 1:\\n            return {\"error\": f\"API call failed: {str(e)}\"}\\n        time.sleep(2 ** attempt)\\n\\nreturn {\"error\": \"Maximum retries reached\"}\\n\\ndef analyze_code_style(state: State) -> dict:\\n    \"\"\"Analyze code style and best practices.\"\"\"\\n    code = state[\"code\"]\\n    prompt = f\"\"\"You are a senior code reviewer focused on code style and best practices. Analyze this code:\\n{code}\\nFocus on:\\n1. Code readability and clarity\\n2. Adherence to common style guides\\n3. Variable/function naming\\n4. Code organization\\n5. Documentation quality\\nProvide your response in JSON format with these exact keys:\\n{{\\n    \"issues\": [\"list of identified style issues\"],\\n    \"suggestions\": [\"list of improvement suggestions\"],\\n    \"overall_rating\": \"1-10 score as a number\",\\n    \"primary_concerns\": [\"list of main style concerns\"]\\n}}\"\"\"\\nanalysis = call_huggingface_api(prompt)\\nif \"error\" in analysis:\\n    analysis = {\\n        \"issues\": [\"Error analyzing code style\"],\\n        \"suggestions\": [\"Try again later\"],\\n        \"overall_rating\": 0,\\n        \"primary_concerns\": [\"Analysis failed\"]\\n    }\\n\\nmessages = state[\"messages\"] + [AIMessage(content=\"Completed code style analysis\")]\\nreturn {**state, \"messages\": messages, \"style_analysis\": analysis, \"current_step\": \"security\"}\\n\\ndef analyze_security(state: State) -> dict:\\n    \"\"\"Analyze security vulnerabilities.\"\"\"\\n    code = state[\"code\"]\\n    prompt = f\"\"\"You are a security expert. Analyze this code for security vulnerabilities:\\n{code}\\nFocus on:\\n1. Input validation\\n2. Authentication/Authorization\\n3. Data exposure\\n4. Common vulnerabilities\\n5. Security best practices\\nProvide your response in JSON format with these exact keys:\\n{{\\n    \"vulnerabilities\": [\"list of potential security issues\"],\\n    \"risk_levels\": {{\"vulnerability\": \"risk level\"}},\\n    \"recommendations\": [\"list of security improvements\"],\\n    \"overall_security_score\": \"1-10 score as a number\"\\n}}\"\"\"\\nanalysis = call_huggingface_api(prompt)\\nif \"error\" in analysis:\\n    analysis = {\\n        \"vulnerabilities\": [\"Error analyzing security\"],\\n        \"risk_levels\": {\"Error\": \"High\"},\\n        \"recommendations\": [\"Try again later\"],\\n        \"overall_security_score\": 0\\n    }\\n\\nmessages = state[\"messages\"] + [AIMessage(content=\"Completed security analysis\")]\\nreturn {**state, \"messages\": messages, \"security_analysis\": analysis, \"current_step\": \"performance\"}\\n\\ndef analyze_performance(state: State) -> dict:\\n    \"\"\"Analyze code performance.\"\"\"\\n    code = state[\"code\"]\\n    prompt = f\"\"\"You are a performance optimization expert. Analyze this code for performance issues:\\n{code}\\nFocus on:\\n1. Time complexity\\n2. Space complexity\\n3. Resource usage\\n4. Bottlenecks\\n5. Optimization opportunities\\nProvide your response in JSON format with these exact keys:\\n{{\\n    \"bottlenecks\": [\"list of identified performance bottlenecks\"],\\n    \"complexity_analysis\": {{\\n        \"time_complexity\": \"Big O notation\",\\n        \"space_complexity\": \"Big O notation\",\\n        \"critical_sections\": [\"list of critical sections\"]\\n    }},\\n    \"optimization_suggestions\": [\"list of performance improvements\"],\\n    \"performance_score\": \"1-10 score as a number\"\\n}}\"\"\"\\nanalysis = call_huggingface_api(prompt)\\nif \"error\" in analysis:\\n    analysis = {\\n        \"bottlenecks\": [\"Error analyzing performance\"],\\n        \"complexity_analysis\": {\\n            \"time_complexity\": \"Unknown\",\\n            \"space_complexity\": \"Unknown\",\\n            \"critical_sections\": []\\n        },\\n        \"optimization_suggestions\": [\"Try again later\"],\\n        \"performance_score\": 0\\n    }\\n\\nmessages = state[\"messages\"] + [AIMessage(content=\"Completed performance analysis\")]\\nreturn {**state, \"messages\": messages, \"performance_analysis\": analysis, \"current_step\": \"architecture\"}\\n\\ndef analyze_architecture(state: State) -> dict:\\n    \"\"\"Analyze code architecture patterns.\"\"\"\\n    code = state[\"code\"]\\n    prompt = f\"\"\"You are a software architect. Analyze this code\\'s architectural patterns:\\n{code}\\nFocus on:\\n1. Design patterns used\\n2. Code modularity\\n3. Component relationships\\n4. Architectural anti-patterns\\n5. System design principles\\nProvide your response in JSON format with these exact keys:\\n{{\\n    \"patterns_identified\": [\"list of design patterns found\"],\\n    \"architectural_issues\": [\"list of architectural concerns\"],\\n    \"improvement_suggestions\": [\"list of architectural improvements\"],\\n    \"architecture_score\": \"1-10 score as a number\"\\n}}\"\"\"\\nanalysis = call_huggingface_api(prompt)\\nif \"error\" in analysis:\\n    analysis = {\\n        \"patterns_identified\": [\"Error analyzing architecture\"],\\n        \"architectural_issues\": [\"Analysis failed\"],\\n        \"improvement_suggestions\": [\"Try again later\"],\\n        \"architecture_score\": 0\\n    }\\n\\nmessages = state[\"messages\"] + [AIMessage(content=\"Completed architecture analysis\")]\\nreturn {**state, \"messages\": messages, \"architecture_analysis\": analysis, \"current_step\": \"recommendations\"}\\n\\ndef generate_final_recommendations(state: State) -> dict:\\n    \"\"\"Generate final recommendations based on all analyses.\"\"\"\\n    code = state[\"code\"]\\n    prompt = f\"\"\"Analyze all previous results and provide final recommendations for this code:\\nStyle Analysis: {json.dumps(state.get(\\'style_analysis\\', {}))}\\nSecurity Analysis: {json.dumps(state.get(\\'security_analysis\\', {}))}\\nPerformance Analysis: {json.dumps(state.get(\\'performance_analysis\\', {}))}\\nArchitecture Analysis: {json.dumps(state.get(\\'architecture_analysis\\', {}))}\\nProvide your response in JSON format with these exact keys:\\n{{\\n    \"critical_issues\": [\"list of most critical issues\"],\\n    \"priority_improvements\": [\"list of high-priority improvements\"],\\n    \"quick_wins\": [\"list of easy-to-implement improvements\"],\\n    \"long_term_suggestions\": [\"list of long-term improvements\"],\\n    \"overall_health_score\": \"1-10 score as a number\"\\n}}\"\"\"\\nrecommendations = call_huggingface_api(prompt)\\nif \"error\" in recommendations:\\n    recommendations = {\\n        \"critical_issues\": [\"Error generating recommendations\"],\\n        \"priority_improvements\": [\"Try again later\"],\\n        \"quick_wins\": [],\\n        \"long_term_suggestions\": [],\\n        \"overall_health_score\": 0\\n    }\\n\\nmessages = state[\"messages\"] + [AIMessage(content=\"Generated final recommendations\")]\\nreturn {**state, \"messages\": messages, \"final_recommendations\": recommendations, \"current_step\": \"end\"}\\n\\ndef format_output(state: State) -> str:\\n    \"\"\"Format the analysis results into a readable output.\"\"\"\\n    output = \"\"\"üîç Code Analysis Report\\nüé® Style & Best Practices\\n\"\"\"\\n    style = state.get(\"style_analysis\", {})\\n    output += f\"Rating: {style.get(\\'overall_rating\\', \\'N/A\\')}/10\\\\n\"\\n    output += \"Issues:\\\\n\" + \"\\\\n\".join([f\"‚Ä¢ {issue}\" for issue in style.get(\"issues\", [])]) + \"\\\\n\\\\n\"\\noutput += \"\"\"üîí Security Analysis\\n\\n\"\"\"\\n    security = state.get(\"security_analysis\", {})\\n    output += f\"Score: {security.get(\\'overall_security_score\\', \\'N/A\\')}/10\\\\n\"\\n    vulnerabilities = security.get(\"vulnerabilities\", [])\\n    risk_levels = security.get(\"risk_levels\", {})\\n    output += \"Vulnerabilities:\\\\n\" + \"\\\\n\".join([f\"‚Ä¢ {v} ({risk_levels.get(v, \\'Unknown\\')})\" for v in vulnerabilities]) + \"\\\\n\\\\n\"\\noutput += \"\"\"‚ö° Performance Analysis\\n\\n\"\"\"\\n    perf = state.get(\"performance_analysis\", {})\\n    output += f\"Score: {perf.get(\\'performance_score\\', \\'N/A\\')}/10\\\\n\"\\n    output += \"Bottlenecks:\\\\n\" + \"\\\\n\".join([f\"‚Ä¢ {b}\" for b in perf.get(\"bottlenecks\", [])]) + \"\\\\n\\\\n\"\\noutput += \"\"\"üèóÔ∏è Architecture Analysis\\n\\n\"\"\"\\n    arch = state.get(\"architecture_analysis\", {})\\n    output += f\"Score: {arch.get(\\'architecture_score\\', \\'N/A\\')}/10\\\\n\"\\n    output += \"Patterns:\\\\n\" + \"\\\\n\".join([f\"‚Ä¢ {p}\" for p in arch.get(\"patterns_identified\", [])]) + \"\\\\n\\\\n\"\\noutput += \"\"\"üìã Final Recommendations\\n\\n\"\"\"\\n    final = state.get(\"final_recommendations\", {})\\n    output += f\"Overall Health Score: {final.get(\\'overall_health_score\\', \\'N/A\\')}/10\\\\n\\\\n\"\\n    output += \"Critical Issues:\\\\n\" + \"\\\\n\".join([f\"‚Ä¢ {i}\" for i in final.get(\"critical_issues\", [])]) + \"\\\\n\\\\n\"\\n    output += \"Priority Improvements:\\\\n\" + \"\\\\n\".join([f\"‚Ä¢ {i}\" for i in final.get(\"priority_improvements\", [])])\\nreturn output\\n\\nCreate and setup graph\\nworkflow = StateGraph(State)\\nAdd nodes\\nworkflow.add_node(\"style\", analyze_code_style)\\nworkflow.add_node(\"security\", analyze_security)\\nworkflow.add_node(\"performance\", analyze_performance)\\nworkflow.add_node(\"architecture\", analyze_architecture)\\nworkflow.add_node(\"recommendations\", generate_final_recommendations)\\nAdd edges\\nworkflow.add_edge(\"style\", \"security\")\\nworkflow.add_edge(\"security\", \"performance\")\\nworkflow.add_edge(\"performance\", \"architecture\")\\nworkflow.add_edge(\"architecture\", \"recommendations\")\\nSet entry and finish points\\nworkflow.set_entry_point(\"style\")\\nworkflow.set_finish_point(\"recommendations\")\\nCompile the workflow\\nagent = workflow.compile()\\ndef analyze_code(code: str) -> str:\\n    \"\"\"Analyze the provided code using multiple perspectives.\"\"\"\\n    initial_state = State(\\n        messages=[SystemMessage(content=\"Starting code analysis...\")],\\n        current_step=\"style\",\\n        code=code,\\n        style_analysis={},\\n        security_analysis={},\\n        performance_analysis={},\\n        architecture_analysis={},\\n        final_recommendations={}\\n    )\\nfinal_state = agent.invoke(initial_state)\\nreturn format_output(final_state)\\n\\nCreate Gradio interface\\niface = gr.Interface(\\n    fn=analyze_code,\\n    inputs=gr.Code(\\n        label=\"Enter your code for analysis\",\\n        language=\"python\",\\n        lines=20\\n    ),\\n    outputs=gr.Textbox(\\n        label=\"Analysis Results\",\\n        lines=25\\n    ),\\n    title=\"üîç Code Architecture Critic\",\\n    description=\"Paste your code to get a comprehensive analysis of style, security, performance, and architecture.\",\\n    examples=[\\n        [\\'\\'\\'def process_data(data):\\n    result = []\\n    for i in range(len(data)):\\n        for j in range(len(data)):\\n            if data[i] + data[j] == 10:\\n                result.append((data[i], data[j]))\\n    return result\\ndef save_to_db(user_input):\\n    query = \"INSERT INTO users VALUES (\\'\" + user_input + \"\\')\"\\n    db.execute(query)\\nAPI_KEY = \"sk_test_123456789\"\\'\\'\\']\\n    ],\\n    theme=gr.themes.Soft()\\n)\\nif name == \"main\":\\n    iface.launch() \\n```\\nConclusion#\\nLangGraph makes it easier to build AI agents that need to manage complex workflows. The graph-based approach keeps things organised and flexible, especially when dealing with multi-step processes or memory.\\nEven though LangGraph doesn‚Äôt come with built-in server features, it works well with FastAPI and other frameworks to serve agents as APIs. Whether you‚Äôre building a chatbot, a code reviewer, or something else entirely, it gives you a solid foundation to work with.\\nI‚Äôm still experimenting and learning, so I‚Äôll keep updating this post as I find better ways to use LangGraph. If you‚Äôve built something cool with it or have any questions, let me know‚Äîhappy to chat!\\nResources#\\n\\nLangGraph Documentation\\nFastAPI Documentation\\nLangChain (LangGraph is part of the LangChain ecosystem)\\n\\nI hope you like this article, if you want to hear more follow me on X at @juanstoppa where I regularly post about AI\\n\\nLanggraph\\nAi-Agents\\nLangchain\\nPython\\n\\n¬´ Prev How to Create a Model Context Protocol (MCP) to give context to an LLM Next ¬ª Initial look at ChatGPT with Canvas\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n¬© 2025 Juan Stoppa ¬∑ Powered by Hugo & PaperMod\\n'},\n",
              " {'title': 'LangGraph Basics: Understanding State, Schema, Nodes, and Edges',\n",
              "  'url': 'https://medium.com/@vivekvjnk/langgraph-basics-understanding-state-schema-nodes-and-edges-77f2fd17cae5',\n",
              "  'content': 'Listen\\nShare\\nLangGraph is a message-passing framework for building modular, graph-based systems. At its core, it focuses on communication between nodes via structured states and logical edges, enabling a flexible and efficient workflow. Let‚Äôs break down the core concepts:\\n1. What is a State?\\nIn LangGraph, the state is the central mechanism for communication between nodes. It acts as a structured message that encapsulates the current snapshot of the system at any given moment. [...] The schema helps nodes interpret the state correctly, ensuring smooth execution across the graph.\\nLangGraph Basics: Understanding State, Schema, Nodes, and Edges\\nLangGraph is a message-passing framework for building modular, graph-based systems. At its core, it focuses on communication between nodes via structured states and logical edges, enabling a flexible and efficient workflow. Let‚Äôs break down the core concepts:\\n1. What is a State?',\n",
              "  'score': 0.9154545,\n",
              "  'raw_content': 'Published Time: 2024-12-15T15:58:51.867Z\\nLangGraph Basics: Understanding State, Schema, Nodes, and Edges | by Story_Teller | Medium\\nOpen in app\\nSign up\\nSign in\\n\\nWrite\\n\\nSign up\\nSign in\\n\\nLangGraph Basics: Understanding State, Schema, Nodes, and Edges\\n\\nStory_Teller\\n¬∑Follow\\n5 min read\\n¬∑\\nDec 15, 2024\\n\\n16\\n\\nListen\\nShare\\nLangGraph is a message-passing framework for building modular, graph-based systems. At its core, it focuses on communication between nodes via structured states and logical edges, enabling a flexible and efficient workflow. Let‚Äôs break down the core concepts:\\n1. What is a State?\\nIn LangGraph, the state is the central mechanism for communication between nodes. It acts as a structured message that encapsulates the current snapshot of the system at any given moment.\\nAccording to the LangGraph documentation:\\n\\n‚ÄúA state is a shared data structure that represents the current snapshot of your application.‚Äù\\n\\nStates are passed along edges between nodes, carrying the output of one node to the next as input. This makes the state the backbone of any message-passing graph.\\n2. What is a Schema in LangGraph?\\nA schema defines the structure of the state. It ensures the data being passed between nodes follows a consistent format.\\n\\nIn Python terms, a schema can be any data type.\\nHowever, it is typically represented using TypedDict or a Pydantic BaseModel.\\n\\nThe schema helps nodes interpret the state correctly, ensuring smooth execution across the graph.\\nLangGraph Basics: Understanding State, Schema, Nodes, and Edges\\nLangGraph is a message-passing framework for building modular, graph-based systems. At its core, it focuses on communication between nodes via structured states and logical edges, enabling a flexible and efficient workflow. Let‚Äôs break down the core concepts:\\n1. What is a State?\\nIn LangGraph, the state is the central mechanism for communication between nodes. It acts as a structured message that encapsulates the current snapshot of the system at any given moment.\\nAccording to the LangGraph documentation:\\n\\n‚ÄúA state is a shared data structure that represents the current snapshot of your application.‚Äù\\n\\nStates are passed along edges between nodes, carrying the output of one node to the next as input. This makes the state the backbone of any message-passing graph.\\n2. What is a Schema in LangGraph?\\nA schema defines the structure of the state. It ensures the data being passed between nodes follows a consistent format.\\n\\nIn Python terms, a schema can be any data type.\\nHowever, it is typically represented using TypedDict or a Pydantic BaseModel.\\n\\nThe schema helps nodes interpret the state correctly, ensuring smooth execution across the graph.\\n3. Nodes vs. Edges: What‚Äôs the Difference?\\nLangGraph can be visualized as a program of programs. It consists of:\\n\\nNodes: Perform the actual work. Nodes contain Python code that can execute any logic, from simple computations to LLM calls or integrations.\\nEdges: Define what happens next. Edges determine the flow of the state between nodes.\\n\\nNodes&Edges: A Messaging App Analogy\\nTo understand the role of edges in LangGraph, let‚Äôs use a relatable analogy: a messaging application on our smartphones.\\nIn this metaphor:\\n\\nWe (humans) represent the nodes.\\nThe edges are the connections or chat threads we create to communicate with others.\\n\\nHere‚Äôs how this analogy maps to LangGraph:\\n\\nDrawing the Edge:\\n    When we want to communicate with someone, we open the messaging app and select the correct chatbox. This action of choosing the chat creates an edge ‚Äî it establishes a connection between two nodes (you and the recipient).\\n\\nInteracting Through the App:\\n    Once the connection (edge) is established, we interact with the app in various ways:\\n\\n\\nHolding the mic button to send a voice message.\\n\\nTyping a text message of any length.\\nCapturing and sending a video using the camera feature.\\n\\nEach of these interactions follows a well-structured sequence of events specific to the messaging app. For example:\\n\\nA text message has a specific format (sender, recipient, message content).\\nA voice message includes data like audio duration and file size.\\nA video message involves capturing, compressing, and attaching a media file.\\n\\nThese predefined structures in the messaging app are synonymous with the schema of the state in LangGraph. Just as a messaging app ensures all interactions (messages) follow a consistent format, the schema in LangGraph ensures the state passed along edges is structured and interpretable.\\nLangGraph‚Äôs Simplicity:\\nThe key difference lies in complexity. In a messaging app, interactions are event-driven and dynamic (e.g., pressing buttons, recording audio, typing text). However, in LangGraph, the schema of the state is much simpler and defined at static time ‚Äî meaning it is established before execution rather than evolving during runtime.\\nThis static schema allows nodes to rely on a consistent state format, ensuring seamless communication along edges throughout the graph.\\nSimple Graph for Structured parsing with fallback\\nFollowing illustrations represents a simple and structured parser workflow with an integrated retry mechanism to handle errors during the parsing process.\\nThrough this illustration let‚Äôs try to understand modular nature of nodes and relevance of edges in the graph. Each node takes state input and yields updated state as output. Sometimes nodes do nothing to the input state and spits out the same state as output.\\nIf we provide proper input state to each individual nodes, they would provide the expected output. ie They are completely modular code sections on their own. Thus with sufficient interface engineering we can implement any graph built using LangGraph without any framework.\\n\\nGraph without edges connecting nodes\\nFollowing image shows the proper graph structure of the Structured Ouptut Parser with Fallback\\nMajor difference is the directed edges connecting different blocks in a logical fashion. These logical connections themselves become some sort of a program. LangGraph framework provides large verity of methods and mechanism to implement such such graphs while still maintaining the modularity.\\n\\nSame graph with directed edges\\nConclusion\\nIn this article, we explored the foundational concepts of graph-based systems, drawing parallels to familiar messaging applications to illustrate how edges, nodes, and state transitions function seamlessly in dynamic workflows. We then delved into a structured parser graph with an integrated retry mechanism, showcasing how LangGraph-like frameworks manage complex processes efficiently.\\nReference : https://langchain-ai.github.io/langgraph/concepts/low_level/\\n\\nSign up to discover human stories that deepen your understanding of the world.\\nFree\\nDistraction-free reading. No ads.\\nOrganize your knowledge with lists and highlights.\\nTell your story. Find your audience.\\nSign up for free\\nMembership\\nRead member-only stories\\nSupport writers you read most\\nEarn money for your writing\\nListen to audio narrations\\nRead offline with the Medium app\\nTry for $5/month\\nLanggraph\\nGraph Theory\\nAgentic\\nAgentic Ai\\nAgentic Workflow\\n\\n16\\n\\n16\\n\\n\\n\\nFollow\\n\\nWritten by Story_Teller ------------------------\\n24 Followers\\n¬∑5 Following\\nAlways a curious student\\nFollow\\n\\nNo responses yet\\n\\n\\nWrite a response\\nWhat are your thoughts?\\nCancel\\nRespond\\nMore from Story_Teller\\n\\n\\nStory_Teller\\nIntroduction to Tool Use with LangGraph‚Äôs ToolNode -------------------------------------------------- ### Modern AI applications often require seamless integration of external tools to enhance their capabilities. Tools are external utilities or‚Ä¶\\nDec 14, 2024\\n11 4\\n\\n\\n\\nStory_Teller\\nThe Command Object in Langgraph ------------------------------- ### What is the Command Object in Langgraph?\\nDec 24, 2024\\n9\\n\\n\\n\\nStory_Teller\\nUnderstanding Leiden vs Louvain Clustering: Hierarchy and Subset Properties --------------------------------------------------------------------------- ### 1. Hierarchical Nature of Clustering\\nJan 12\\n1\\n\\n\\n\\nStory_Teller\\nInterrupt Function: Overcoming BSP Limitations to Enable Human-in-the-Loop Workflows in LangGraph ------------------------------------------------------------------------------------------------- ### Why Is the Implementation of Human-In-The-Loop (HIL) Interactions So Difficult In Frameworks Like LangGraph?\\nDec 26, 2024\\n\\n\\nSee all from Story_Teller\\nRecommended from Medium\\n\\n\\nMinyang Chen\\nBuilding Code Agent from scratch using Langgraph ------------------------------------------------ ### Motivation\\nMar 5\\n8\\n\\n\\n\\nKamal Dhungana\\nGetting Started with Local and Remote MCP Servers in LangChain: A Hands-On Beginner‚Äôs Guide ------------------------------------------------------------------------------------------- ### Model Context Protocol (MCP) is an emerging standard designed to bridge the gap between Large Language Models (LLMs) and external tools or‚Ä¶\\nApr 9\\n138 1\\n\\n\\n\\nIn\\nAlgoMart\\nby\\nYash Jain\\nCreate Your First Multi-Agent Assistant Using LangChain & LangGraph ------------------------------------------------------------------- ### If you have recently been building AI applications using large language models (LLM), you are likely to have used LangChain ü¶ú. LangChain‚Ä¶\\nMar 31\\n37 1\\n\\n\\n\\nAreeba Ayub\\nUsing LangGraph Memory for Persistent Chat Conversations -------------------------------------------------------- ### I‚Äôm currently working on a chatbot and exploring memory systems in LangGraph. During my research, I found the information to be quite‚Ä¶\\nApr 1\\n5\\n\\n\\n\\nMinyang Chen\\nEmulate the investment strategies of today‚Äôs famous hedge fund managers with Agentic AI. ---------------------------------------------------------------------------------------- ### The stock market involves numerous statistics and patterns. Stock trading is grounded in research and data-driven decision-making. The use‚Ä¶\\nMar 25\\n50\\n\\n\\n\\nIn\\nAI Agents\\nby\\nSantosh Rout\\nLangGraph for Beginners, Part 3: Conditional Edges -------------------------------------------------- ### In this article, we will create a simple graph that explains conditional edges in LangGraph.\\nOct 24, 2024\\n41 1\\n\\nSee more recommendations\\nHelp\\nStatus\\nAbout\\nCareers\\nPress\\nBlog\\nPrivacy\\nRules\\nTerms\\nText to speech'},\n",
              " {'url': 'https://www.datacamp.com/tutorial/langgraph-tutorial',\n",
              "  'title': 'What Is LangGraph and How to Use It? - DataCamp',\n",
              "  'content': 'LangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner.\\nIt simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing agent runtimes. With LangGraph, we can easily build robust, scalable, and flexible multi-agent systems. [...] Home\\nTutorials\\nArtificial Intelligence\\n\\nLangGraph Tutorial: What Is LangGraph and How to Use It?\\nLangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.\\nContents\\nJun 26, 2024 \\xa0¬∑ 12 min read\\nContents\\n\\nWhat Is LangGraph?\\nGraph structure\\nState management\\n\\nCoordination\\n\\n\\nWhy LangGraph?\\n\\nSimplified development\\nFlexibility\\nScalability\\n\\nFault tolerance [...] If you want to learn more about the LangChain ecosystem, I recommend this introduction to LangChain.\\nWhat Is LangGraph?\\nLangGraph enables us to create stateful, multi-actor applications utilizing LLMs as easily as possible. It extends the capabilities of LangChain, introducing the ability to create and manage cyclical graphs, which are pivotal for developing sophisticated agent runtimes. The core concepts of LangGraph include: graph structure, state management, and coordination.\\nGraph structure',\n",
              "  'score': 0.914176,\n",
              "  'raw_content': 'Published Time: 2024-06-26T21:00:00.000Z\\nLangGraph Tutorial: What Is LangGraph and How to Use It? | DataCamp\\n ##### Get 50% off unlimited learning Buy Now\\nSkip to main content\\nWrite for us\\nEN\\nEnglishEspa√±olBetaPortugu√™sBetaDeutschBetaFran√ßaisBeta\\n\\nFound an Error?\\nLog InGet Started\\nTutorials\\nBlogs\\nTutorials\\ndocs\\nPodcasts\\nCheat Sheets\\ncode-alongs\\nCategory\\nCategory\\nTechnologies\\nDiscover content by tools and technology\\nArtificial IntelligenceAWSAzureBusiness IntelligenceChatGPTDatabricksdbtDockerExcelGenerative AIGitGoogle Cloud PlatformHugging FaceJavaJuliaKubernetesLarge Language ModelsOpenAIPostgreSQLPower BIPythonRScalaSnowflakeSpreadsheetsSQLSQLiteTableau\\nCategory\\nTopics\\nDiscover content by data science topics\\nAI for BusinessBig DataCareer ServicesCloudData AnalysisData EngineeringData LiteracyData ScienceData VisualizationDataLabDeep LearningMachine LearningMLOpsNatural Language Processing\\nRequest a Demo\\ncategory\\n\\nHome\\nTutorials\\nArtificial Intelligence\\n\\nLangGraph Tutorial: What Is LangGraph and How to Use It?\\nLangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.\\nContents\\nJun 26, 2024 \\xa0¬∑ 12 min read\\nContents\\n\\nWhat Is LangGraph?\\nGraph structure\\nState management\\n\\nCoordination\\n\\n\\nWhy LangGraph?\\n\\nSimplified development\\nFlexibility\\nScalability\\n\\nFault tolerance\\n\\n\\nGetting Started With LangGraph\\n\\nInstallation\\n\\nBasic Concepts\\n\\n\\nBuilding a Simple LangGraph Application\\n\\nStep 1: Define the StateGraph\\nStep 2: Initialize an LLM and add it as a Chatbot node\\nStep 3: Set edges\\n\\nStep 5: Run the chatbot\\n\\n\\nAdvanced LangGraph Features\\n\\nCustom node types\\nEdge types\\n\\nError handling\\n\\n\\nReal-World Applications of LangGraph\\n\\nChatbots\\nAutonomous agents\\nMulti-Agent systems\\nWorkflow automation tools\\nRecommendation systems\\n\\nPersonalized learning environments\\n\\n\\nConclusion\\n\\n\\nTraining more people?\\nGet your team access to the full DataCamp for business platform.\\nFor BusinessFor a bespoke solution book a demo.\\nImagine you\\'re building a complex, multi-agent large language model (LLM) application. It\\'s exciting, but it comes with challenges: managing the state of various agents, coordinating their interactions, and handling errors effectively. This is where LangGraph can help.\\nLangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner.\\nIt simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing agent runtimes. With LangGraph, we can easily build robust, scalable, and flexible multi-agent systems.\\nIf you want to learn more about the LangChain ecosystem, I recommend this introduction to LangChain.\\nWhat Is LangGraph?\\nLangGraph enables us to create stateful, multi-actor applications utilizing LLMs as easily as possible. It extends the capabilities of LangChain, introducing the ability to create and manage cyclical graphs, which are pivotal for developing sophisticated agent runtimes. The core concepts of LangGraph include: graph structure, state management, and coordination.\\nGraph structure\\nImagine your application as a directed graph. In LangGraph, each node represents an LLM agent, and the edges are the communication channels between these agents. This structure allows for clear and manageable workflows, where each agent performs specific tasks and passes information to other agents as needed.\\nState management\\nOne of LangGraph\\'s standout features is its automatic state management. This feature enables us to track and persist information across multiple interactions. As agents perform their tasks, the state is dynamically updated, ensuring the system maintains context and responds appropriately to new inputs.\\nCoordination\\nLangGraph ensures agents execute in the correct order and that necessary information is exchanged seamlessly. This coordination is vital for complex applications where multiple agents need to work together to achieve a common goal. By managing the flow of data and the sequence of operations, LangGraph allows developers to focus on the high-level logic of their applications rather than the intricacies of agent coordination.\\nWhy LangGraph?\\nAs I mentioned above, LangGraph offers several significant advantages for developers working with complex LLM applications. Here are some of the real-world benefits LangGraph offers.\\nSimplified development\\nLangGraph abstracts away the complexities associated with state management and agent coordination. This means developers can define their workflows and logic without worrying about the underlying mechanisms that ensure data consistency and proper execution order. This simplification accelerates the development process and reduces the likelihood of errors. It‚Äôs a game-changer!\\nFlexibility\\nWith LangGraph, developers have the flexibility to define their own agent logic and communication protocols. This allows for highly customized applications tailored to specific use cases. Whether you need a chatbot that can handle various types of user requests or a multi-agent system that performs complex tasks, LangGraph provides the tools to build exactly what you need. It‚Äôs all about giving you the power to create.\\nScalability\\nLangGraph is built to support the execution of large-scale multi-agent applications. Its robust architecture can handle a high volume of interactions and complex workflows, enabling the development of scalable systems that can grow with your needs. This makes it suitable for enterprise-level applications and scenarios where performance and reliability are critical.\\nFault tolerance\\nReliability is a core consideration in the design of LangGraph. The library includes mechanisms for gracefully handling errors, ensuring that your application can continue to operate even when individual agents encounter issues. This fault tolerance is essential for maintaining the stability and robustness of complex multi-agent systems. Peace of mind is just a feature away.\\nGetting Started With LangGraph\\nLet‚Äôs see how we can set up LangGraph and what the basic concepts are.\\nInstallation\\nTo install LangGraph, you can use pip:\\npip install -U langgraph\\nPowered By \\nWas this helpful? Yes No\\nBasic Concepts\\nNodes: Nodes represent units of work within your LangGraph. They are typically Python functions that perform a specific task, such as:\\n\\nInteracting with an LLM\\nCalling a tool or API\\nPerforming some data manipulation\\nReceiving user input\\nExecuting business logic\\n\\nIn LangGraph, you can add nodes using the graph.add_node(name, value) syntax.\\nEdges: Edges are communication channels between nodes. They define the flow of information and the order of execution. You can add edges using the graph.add_edge(node1, node2) syntax.\\nState: The state is a central object updated over time by the nodes in the graph. It manages the internal state of your application and can be overridden or added to, depending on the application\\'s requirements. This state can hold things such as:\\n\\nConversation history: A list of messages between the agent and the user.\\nContextual data: Information relevant to the current task or interaction.\\nInternal variables: Flags, counters, or other variables to track the agent\\'s progress and behavior.\\n\\nBuilding a Simple LangGraph Application\\nHere‚Äôs a step-by-step example of creating a basic chatbot application using LangGraph.\\nStep 1: Define the StateGraph\\nDefine a StateGraph object to structure the chatbot as a state machine. The State is a class object defined with a single key messages of type List and uses the add_messages() function to append new messages rather than overwrite them.\\nfrom typing import Annotated\\nfrom typing_extensions import TypedDict\\nfrom langgraph.graph import StateGraph\\nfrom langgraph.graph.message import add_messages\\nclass State(TypedDict):\\n    # messages have the type \"list\".\\n    # The add_messages function appends messages to the list, rather than overwriting them\\n    messages: Annotated[list, add_messages]\\ngraph_builder = StateGraph(State)\\nPowered By \\nWas this helpful? Yes No\\nStep 2: Initialize an LLM and add it as a Chatbot node\\nHere, we initialize the AzureChatOpenAI model and create a simple chatbot function that takes in the state messages as input and generates a message response (which is subsequently appended to the state).\\nThis chatbot function is added as a node named ‚Äúchatbot‚Äù to the graph.\\n```\\nfrom langchain_openai import AzureChatOpenAI\\nllm = AzureChatOpenAI(\\n    openai_api_version=os.environ[\"AZURE_OPENAI_API_VERSION\"],\\n    azure_deployment=os.environ[\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\"],\\n)\\ndef chatbot(state: State):\\n    return {\"messages\": [llm.invoke(state[\"messages\"])]}\\n‚Äò‚Äô‚ÄôThe first argument is the unique node name\\nThe second argument is the function or object that will be called whenever the node is used.‚Äô‚Äô‚Äô\\ngraph_builder.add_node(\"chatbot\", chatbot)\\n```\\nPowered By \\nStep 3: Set edges\\nSince we are building a simple chatbot, we set the chatbot node as both the entry and finish points of the graph to indicate where to start and end the process.\\n```\\nSet entry and finish points\\ngraph_builder.set_entry_point(\"chatbot\")\\ngraph_builder.set_finish_point(\"chatbot\")\\n```\\nPowered By \\nWas this helpful? Yes No\\nStep 4: Compile and Visualize the Graph\\nCompile the graph to create a CompiledGraph object, and optionally, we can visualize the graph structure using the code below:\\ngraph = graph_builder.compile()\\nfrom IPython.display import Image, display\\ntry:\\n    display(Image(graph.get_graph().draw_mermaid_png()))\\nexcept Exception:\\n    pass\\nPowered By \\nWas this helpful? Yes No\\n\\nStep 5: Run the chatbot\\nFinally, we implement a loop to continuously prompt the user for input, process it through the graph, and print the assistant\\'s response. The loop exits when the user types \"quit\", \"exit\", or \"q\".\\n```\\nRun the chatbot\\nwhile True:\\n    user_input = input(\"User: \")\\n    if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\\n        print(\"Goodbye!\")\\n        break\\n    for event in graph.stream({\"messages\": [(\"user\", user_input)]}):\\n        for value in event.values():\\n            print(\"Assistant:\", value[\"messages\"][-1].content)\\n```\\nPowered By \\nWas this helpful? Yes No\\nAdvanced LangGraph Features\\nNow that we covered the basics, let‚Äôs take a look at some advanced features.\\nCustom node types\\nLangGraph allows you to create custom node types to implement complex agent logic. This provides flexibility and control over your application\\'s behavior.\\nfrom typing import Annotated\\nfrom langchain_anthropic import ChatAnthropic\\nfrom langgraph.graph import StateGraph\\nfrom langgraph.graph.message import add_messages\\nclass MyCustomNode:\\n    def __init__(self, llm):\\n        self.llm = llm\\n    def __call__(self, state):\\n        # Implement your custom logic here\\n        # Access the state and perform actions\\n        messages = state[\"messages\"]\\n        response = self.llm.invoke(messages)\\n        return {\"messages\": [response]}\\ngraph_builder = StateGraph(State)\\nllm = ChatAnthropic(model=\"claude-3-haiku-20240307\")\\ncustom_node = MyCustomNode(llm)\\ngraph_builder.add_node(\"custom_node\", custom_node)\\nPowered By \\nWas this helpful? Yes No\\nHere, we define a class MyCustomNode that encapsulates custom logic and interacts with the LLM. This provides a more structured and maintainable way to implement complex node behaviors.\\nEdge types\\nLangGraph supports different edge types to handle various communication patterns between nodes. One useful type is the conditional edge, which allows for decision-making based on a node\\'s output.\\nTo create a conditional edge, you need three components:\\n\\nThe upstream node: The node\\'s output decides the next step.\\nA function: This function evaluates the upstream node\\'s output and determines the next node to execute, returning a string that represents the decision.\\nA mapping: This mapping links the possible outcomes of the function to the corresponding nodes to be executed.\\n\\nHere\\'s an example in pseudocode:\\ngraph.add_conditional_edge(\\n    \"model\",\\n    should_continue,\\n    {\\n        \"end\": END,\\n        \"continue\": \"tools\"\\n    }\\n)\\nPowered By \\nWas this helpful? Yes No\\nHere, after the ‚Äúmodel‚Äù node is called, we can either exit the graph (‚Äùend‚Äù) and return to the user, or we can continue (‚Äùcontinue‚Äù) and call a tool‚Äîdepending on what the user decides!\\nState management\\nLangGraph offers powerful state management techniques, which include using external databases like SQLite, PostgreSQL, and MongoDB, or cloud storage solutions like Amazon S3, Google Cloud Storage, and Azure Blob Storage to store and retrieve your agent\\'s state, enabling reliability and scalability.\\nHere\\'s an example of using a SQLite database for state management:\\n```\\nfrom langgraph.checkpoint.sqlite import SqliteSaver\\nConnect to the SQLite database\\nmemory = SqliteSaver.from_conn_string(\":memory:\")\\nCompile the graph with the checkpointer\\ngraph = graph_builder.compile(checkpointer=memory)\\n```\\nPowered By \\nWas this helpful? Yes No\\nError handling\\nLangGraph also provides mechanisms for error handling:\\n\\nExceptions: Node functions can raise exceptions to signal errors during execution. You can catch and handle these exceptions to prevent your graph from crashing.\\nRetry mechanisms: You can implement retry logic within your nodes to handle transient errors, such as network issues or API timeouts.\\nLogging: Use logging to record errors and track the execution of your graph.\\n\\nReal-World Applications of LangGraph\\nLangGraph can be used to build a wide range of applications.\\nChatbots\\nLangGraph is ideal for developing sophisticated chatbots that can handle a wide array of user requests. By leveraging multiple LLM agents, these chatbots can process natural language queries, provide accurate responses, and seamlessly switch between different conversation topics. The ability to manage state and coordinate interactions ensures that the chatbot maintains context and delivers a coherent user experience.\\nAutonomous agents\\nFor applications requiring autonomous decision-making, LangGraph enables the creation of agents that can perform tasks independently based on user inputs and predefined logic.\\nThese agents can execute complex workflows, interact with other systems, and adapt to new information dynamically. LangGraph\\'s structured framework ensures that each agent operates efficiently and effectively, making it suitable for tasks like automated customer support, data processing, and system monitoring.\\nMulti-Agent systems\\nLangGraph excels in building applications where multiple agents collaborate to achieve a common goal. For example, different agents can manage inventory, process orders, and coordinate deliveries in a supply chain management system. LangGraph\\'s coordination capabilities ensure that each agent communicates effectively, sharing information and making decisions in a synchronized manner. This leads to more efficient operations and better overall system performance.\\nWorkflow automation tools\\nWith LangGraph, automating business processes and workflows becomes straightforward. Intelligent agents can be designed to handle tasks such as document processing, approval workflows, and data analysis. By defining clear workflows and leveraging LangGraph\\'s state management, these tools can execute complex sequences of actions without human intervention, reducing errors and increasing productivity.\\nRecommendation systems\\nPersonalized recommendation systems can greatly benefit from LangGraph\\'s capabilities. By employing multiple agents to analyze user behavior, preferences, and contextual data, these systems can deliver tailored suggestions for products, content, or services. LangGraph\\'s flexibility allows for integrating various data sources and algorithms, enhancing the accuracy and relevance of recommendations.\\nPersonalized learning environments\\nIn educational platforms, LangGraph can be used to create adaptive learning environments that cater to individual learning styles and needs. Multiple agents can assess a student\\'s progress, provide customized exercises, and offer real-time feedback. The stateful nature of LangGraph ensures that the system retains information about each learner\\'s performance and preferences, enabling a more personalized and effective educational experience.\\nConclusion\\nLangGraph significantly simplifies the development of complex LLM applications by providing a structured framework for managing state and coordinating agent interactions.\\nPotential developments for LangGraph include integration with other LangChain components, support for new LLM models, and the introduction of more advanced agent runtimes from academia.\\nIf you want to learn more about developing applications within the LangChain ecosystem, I recommend this course on developing LLM applications with LangChain.\\n\\n\\nAuthor\\nRyan Ong\\n\\nRyan is a lead data scientist specialising in building AI applications using LLMs. He is a PhD candidate in Natural Language Processing and Knowledge Graphs at Imperial College London, where he also completed his Master‚Äôs degree in Computer Science. Outside of data science, he writes a weekly Substack newsletter,\\xa0The Limitless Playbook, where he shares one actionable idea from the world\\'s top thinkers and occasionally writes about core AI concepts.\\nTopics\\nArtificial IntelligencePython\\n\\n\\nRyan OngI write about AI research, entrepreneurship, and self-development.\\n\\nTopics\\nArtificial IntelligencePython\\n### LangGraph Studio Guide: Installation, Set Up, Use Cases\\n### Introduction to LangChain for Data Engineering & Data Applications\\n### How to Build LLM Applications with LangChain Tutorial\\n### Building LangChain Agents to Automate Tasks in Python\\n### Building Context-Aware Chatbots: Leveraging LangChain Framework for ChatGPT\\n### Building AI Applications with LangChain and GPT\\nLearn AI with these courses!\\nCourse\\nDeveloping LLM Applications with LangChain\\n3 hr\\n12.7K\\nDiscover how to build AI-powered applications using LLMs, prompts, chains, and agents in LangChain.\\nSee DetailsStart Course\\nCourse\\nDeveloping LLM Applications with LangChain\\n3 hr\\n12.7K\\nDiscover how to build AI-powered applications using LLMs, prompts, chains, and agents in LangChain.\\nSee DetailsStart Course\\nTrack\\nAI Business Fundamentals\\n11hrs hr\\nAccelerate your AI journey, conquer ChatGPT, and develop a comprehensive Artificial Intelligence strategy.\\nSee DetailsStart Course\\nSee More\\nRelated\\nTutorial ### LangGraph Studio Guide: Installation, Set Up, Use Cases\\nLangGraph Studio is a visual development environment for LangChain‚Äôs LangGraph framework, simplifying the development of complex agentic applications built with LangChain components.\\n\\nDr Ana Rojo-Echebur√∫a\\n8 min\\nTutorial ### Introduction to LangChain for Data Engineering & Data Applications\\nLangChain is a framework for including AI from large language models inside data pipelines and applications. This tutorial provides an overview of what you can do with LangChain, including the problems that LangChain solves and examples of data use cases.\\n\\nRichie Cotton\\n11 min\\nTutorial ### How to Build LLM Applications with LangChain Tutorial\\nExplore the untapped potential of Large Language Models with LangChain, an open-source Python framework for building advanced AI applications.\\n\\nMoez Ali\\n12 min\\nTutorial ### Building LangChain Agents to Automate Tasks in Python\\nA comprehensive tutorial on building multi-tool LangChain agents to automate tasks in Python using LLMs and chat models using OpenAI.\\n\\nBex Tuychiev\\n14 min\\nTutorial ### Building Context-Aware Chatbots: Leveraging LangChain Framework for ChatGPT\\nExplore how to build context-aware chatbots using the ChatGPT and LangChain framework.\\n\\nAndrea Valenzuela\\n15 min\\ncode-along ### Building AI Applications with LangChain and GPT\\nIn the live training, you\\'ll use LangChain to build a simple AI application, including preparing and indexing data, prompting the AI, and generating responses.\\n\\nEmmanuel Pire\\nSee MoreSee More\\nGrow your data skills with DataCamp for Mobile\\nMake progress on the go with our mobile courses and daily 5-minute coding challenges.\\nDownload on the App StoreGet it on Google Play\\nLearn\\nLearn PythonLearn AILearn Power BILearn Data EngineeringAssessmentsCareer TracksSkill TracksCoursesData Science Roadmap\\nData Courses\\nPython CoursesR CoursesSQL CoursesPower BI CoursesTableau CoursesAlteryx CoursesAzure CoursesAWS CoursesGoogle Sheets CoursesExcel CoursesAI CoursesData Analysis CoursesData Visualization CoursesMachine Learning CoursesData Engineering CoursesProbability & Statistics Courses\\nDataLab\\nGet StartedPricingSecurityDocumentation\\nCertification\\nCertificationsData ScientistData AnalystData EngineerSQL AssociatePower BI Data AnalystTableau Certified Data AnalystAzure FundamentalsAI Fundamentals\\nResources\\nResource CenterUpcoming EventsBlogCode-AlongsTutorialsDocsOpen SourceRDocumentationBook a Demo with DataCamp for BusinessData Portfolio\\nPlans\\nPricingFor StudentsFor BusinessFor UniversitiesDiscounts, Promos & SalesDataCamp Donates\\nFor Business\\nBusiness PricingTeams PlanData & AI Unlimited PlanCustomer StoriesPartner Program\\nAbout\\nAbout UsLearner StoriesCareersBecome an InstructorPressLeadershipContact UsDataCamp Espa√±olDataCamp Portugu√™sDataCamp DeutschDataCamp Fran√ßais\\nSupport\\nHelp CenterBecome an Affiliate\\nFacebookTwitterLinkedInYouTubeInstagram\\nPrivacy PolicyCookie NoticeDo Not Sell My Personal InformationAccessibilitySecurityTerms of Use\\n¬© 2025 DataCamp, Inc. All Rights Reserved.\\n\\n\\n\\nEnroll Enroll Learn the\\nfundamentals of AI Check Out All AI Courses ‚úï Perfect thank you! X \"\" has been copied to the clipboardShake To Reaveal Voucher [close] X Click me for great offers... Thanks... your code is: X'},\n",
              " {'url': 'https://langchain-ai.github.io/langgraph/',\n",
              "  'title': 'LangGraph - GitHub Pages',\n",
              "  'content': 'Note\\nLooking for the JS version? See the JS repo and the JS docs.\\nLangGraph ‚Äî used by Replit, Uber, LinkedIn, GitLab and more ‚Äî is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration ‚Äî offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.',\n",
              "  'score': 0.914176,\n",
              "  'raw_content': 'LangGraph\\nSkip to content\\nJoin us at Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!\\n \\nLangGraph\\n\\nInitializing search\\nGitHub\\n\\nHome\\nAPI reference\\n\\n \\nGitHub\\n\\n\\n[ ] \\nHome\\nHome\\n\\n\\n[ ]  Get started\\nGet started\\n\\nLearn the basics\\nDeployment\\n\\n\\n\\n[ ]  Guides\\nGuides\\n\\nHow-to Guides\\nConcepts\\nTutorials\\n\\n\\n\\n[ ]  Resources\\nResources\\n\\nPrebuilt Agents\\nCompanies using LangGraph\\nLLMS-txt\\nFAQ\\nTroubleshooting\\nLangGraph Academy Course\\n\\n\\n\\n\\n\\nAPI reference\\n\\n\\nTable of contents\\n\\nWhy use LangGraph?\\nLangGraph‚Äôs ecosystem\\nPairing with LangGraph Platform\\nAdditional resources\\nAcknowledgements\\n\\n\\nLangGraph\\n \\n\\n   \\nNote\\nLooking for the JS version? See the JS repo and the JS docs.\\nLangGraph ‚Äî used by Replit, Uber, LinkedIn, GitLab and more ‚Äî is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration ‚Äî offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-0-1)pipinstall-Ulanggraph\\nTo learn more about how to use LangGraph, check out the docs. We show a simple example below of how to create a ReAct agent.\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-1)# This code depends on pip install langchain[anthropic]\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-2)fromlanggraph.prebuiltimport create_react_agent\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-3)\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-4)defsearch(query: str):\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-5)\"\"\"Call to surf the web.\"\"\"\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-6)    if \"sf\" in query.lower() or \"san francisco\" in query.lower():\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-7)        return \"It\\'s 60 degrees and foggy.\"\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-8)    return \"It\\'s 90 degrees and sunny.\"\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-9)\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-10)agent = create_react_agent(\"anthropic:claude-3-7-sonnet-latest\", tools=[search])\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-11)agent.invoke(\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-12)    {\"messages\": [{\"role\": \"user\", \"content\": \"what is the weather in sf\"}]}\\n[](https://langchain-ai.github.io/langgraph/#__codelineno-1-13))\\nTip\\nCheck out this guide that walks through implementing common patterns (workflows and agents) in LangGraph.\\nWhy use LangGraph?¬∂\\nLangGraph is built for developers who want to build powerful, adaptable AI agents. Developers choose LangGraph for:\\n\\nReliability and controllability. Steer agent actions with moderation checks and human-in-the-loop approvals. LangGraph persists context for long-running workflows, keeping your agents on course.\\nLow-level and extensible. Build custom agents with fully descriptive, low-level primitives ‚Äì free from rigid abstractions that limit customization. Design scalable multi-agent systems, with each agent serving a specific role tailored to your use case.\\nFirst-class streaming support. With token-by-token streaming and streaming of intermediate steps, LangGraph gives users clear visibility into agent reasoning and actions as they unfold in real time.\\n\\nLangGraph is trusted in production and powering agents for companies like:\\n\\nKlarna: Customer support bot for 85 million active users\\nElastic: Security AI assistant for threat detection\\nUber: Automated unit test generation\\nReplit: Code generation\\nAnd many more (see list here)\\n\\nLangGraph‚Äôs ecosystem¬∂\\nWhile LangGraph can be used standalone, it also integrates seamlessly with any LangChain product, giving developers a full suite of tools for building agents. To improve your LLM application development, pair LangGraph with:\\n\\nLangSmith ‚Äî Helpful for agent evals and observability. Debug poor-performing LLM app runs, evaluate agent trajectories, gain visibility in production, and improve performance over time.\\nLangGraph Platform ‚Äî Deploy and scale agents effortlessly with a purpose-built deployment platform for long running, stateful workflows. Discover, reuse, configure, and share agents across teams ‚Äî and iterate quickly with visual prototyping in LangGraph Studio.\\n\\nPairing with LangGraph Platform¬∂\\nWhile LangGraph is our open-source agent orchestration framework, enterprises that need scalable agent deployment can benefit from LangGraph Platform.\\nLangGraph Platform can help engineering teams:\\n\\nAccelerate agent development: Quickly create agent UXs with configurable templates and LangGraph Studio for visualizing and debugging agent interactions.\\nDeploy seamlessly: We handle the complexity of deploying your agent. LangGraph Platform includes robust APIs for memory, threads, and cron jobs plus auto-scaling task queues & servers.\\nCentralize agent management & reusability: Discover, reuse, and manage agents across the organization. Business users can also modify agents without coding.\\n\\nAdditional resources¬∂\\n\\nLangChain Academy: Learn the basics of LangGraph in our free, structured course.\\nTutorials: Simple walkthroughs with guided examples on getting started with LangGraph.\\nTemplates: Pre-built reference apps for common agentic workflows (e.g. ReAct agent, memory, retrieval etc.) that can be cloned and adapted.\\nHow-to Guides: Quick, actionable code snippets for topics such as streaming, adding memory & persistence, and design patterns (e.g. branching, subgraphs, etc.).\\nAPI Reference: Detailed reference on core classes, methods, how to use the graph and checkpointing APIs, and higher-level prebuilt components.\\nBuilt with LangGraph: Hear how industry leaders use LangGraph to ship powerful, production-ready AI applications.\\n\\nAcknowledgements¬∂\\nLangGraph is inspired by Pregel and Apache Beam. The public interface draws inspiration from NetworkX. LangGraph is built by LangChain Inc, the creators of LangChain, but can be used without LangChain.\\nWas this page helpful?\\nThanks for your feedback!\\nThanks for your feedback! Please help us improve this page by adding to the discussion below.\\nBack to top\\nNext Learn the basics\\nCopyright ¬© 2025 LangChain, Inc | Consent Preferences\\nMade with Material for MkDocs Insiders\\n\\nCookie consent\\nWe use cookies to recognize your repeated visits and preferences, as well as to measure the effectiveness of our documentation and whether users find what they\\'re searching for. Clicking \"Accept\" makes our documentation better. Thank you! ‚ù§Ô∏è\\n\\nGoogle Analytics\\nGitHub\\n\\nAccept Reject'},\n",
              " {'title': 'LangGraph: Definition, Purpose & Benefits',\n",
              "  'url': 'https://zencoder.ai/glossary/lang-graph',\n",
              "  'content': 'LangGraph is an essential tool for developers working on language-intensive software projects. By offering visual insights into language resources and fostering effective management, LangGraph contributes to the quality and functionality of language-enabled applications.',\n",
              "  'score': 0.90791017,\n",
              "  'raw_content': None}]"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "docs[0]['results']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "naEyCquUxiFT",
      "metadata": {
        "id": "naEyCquUxiFT"
      },
      "outputs": [],
      "source": [
        "output = format_search_query_results(docs, max_tokens=500, include_raw_content=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qHJ7CU1ixoLI",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qHJ7CU1ixoLI",
        "outputId": "8535a4c1-bac0-425e-bd5b-c9d1a61f79c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Content from web search:\n",
            "\n",
            "Source What is LangGraph and How to Use It for Building AI Agents:\n",
            "===\n",
            "URL: https://jstoppa.com/posts/artificial-intelligence/fundamentals/what-is-langgraph-and-how-to-use-it-for-building-ai-agents/post/\n",
            "===\n",
            "Most relevant content from source: What is LangGraph?#\n",
            "LangGraph is a framework that brings state machines to Large Language Model (LLM) applications. It‚Äôs particularly useful when you need to build complex, stateful applications with LLMs. The framework allows you to structure your application as a graph, where each node represents a specific task or state, and edges represent transitions between states.\n",
            "Basic LangGraph Example#\n",
            "===\n",
            "Raw Content: Published Time: 2025-02-16T00:00:00Z\n",
            "What is LangGraph and How to Use It for Building AI Agents | Juan Stoppa\n",
            "Juan Stoppa\n",
            "\n",
            "Archives\n",
            "Search\n",
            "Tags\n",
            "\n",
            "What is LangGraph and How to Use It for Building AI Agents\n",
            "A practical guide to LangGraph and AI agents. This covers the basics, real examples, and deployment. I wrote it to simplify LangChain's complex docs and help people build stateful AI agents.\n",
            "February 16, 2025¬†¬∑¬†12 min¬†¬∑¬†Juan Stoppa\n",
            "I keep finding myself going back to the LangChain documentation to figure out how to use LangGraph. While the documentation is comprehensive, it can be overwhelming to navigate, especially when you‚Äôre trying to build advanced AI agents.\n",
            "This guide is my attempt to consolidate the key concepts and practical implementations of LangGraph in one place. Whether you‚Äôre building a conversational agent that needs to remember context, a multi-step reasoning agent, or a complex workflow that coordinates multiple AI components, LangGraph provides the framework to make it happen. I created this reference for myself but I hope it helps others who want a more straightforward explanation of how to use LangGraph effectively.\n",
            "What is LangGraph?#\n",
            "LangGraph is a framework that brings state machines to Large Language Model (LLM) applications. It‚Äôs particularly useful when you need to build complex, stateful applications with LLMs. The framework allows you to structure your application as a graph, where each node represents a specific task or state, and edges represent transitions between states.\n",
            "Basic LangGraph Example#\n",
            "Let‚Äôs start with a simple example to understand the core concepts: we are developing a simple agent that collects information and processes it, the actions of collecting and processing information are just fixed actions but they can be replaced with more complex actions.\n",
            "\n",
            "```python\n",
            "from langgraph.graph import StateGraph\n",
            "from typing import TypedDict, Annotated\n",
            "from langgraph.graph.message import add_messages\n",
            "from langchain_core.runnables.graph import MermaidDrawMethod\n",
            "class State(TypedDict):\n",
            "    messages: Annotated[list[str], add_messages]\n",
            "    current_step: str\n",
            "def collect_info(state: State) -> dict:\n",
            "    print(\"\\n--> In collect_info\")\n",
            "    print(f\"Messages before: {state['messages']}\")\n",
            "messages = state[\"messages\"] + [\"Information collected\"]\n",
            "print(f\"Messages after: {messages}\")\n",
            "\n",
            "return {\n",
            "    \"\n",
            "\n",
            "Source LangGraph Basics: Understanding State, Schema, Nodes, and Edges:\n",
            "===\n",
            "URL: https://medium.com/@vivekvjnk/langgraph-basics-understanding-state-schema-nodes-and-edges-77f2fd17cae5\n",
            "===\n",
            "Most relevant content from source: Listen\n",
            "Share\n",
            "LangGraph is a message-passing framework for building modular, graph-based systems. At its core, it focuses on communication between nodes via structured states and logical edges, enabling a flexible and efficient workflow. Let‚Äôs break down the core concepts:\n",
            "1. What is a State?\n",
            "In LangGraph, the state is the central mechanism for communication between nodes. It acts as a structured message that encapsulates the current snapshot of the system at any given moment. [...] The schema helps nodes interpret the state correctly, ensuring smooth execution across the graph.\n",
            "LangGraph Basics: Understanding State, Schema, Nodes, and Edges\n",
            "LangGraph is a message-passing framework for building modular, graph-based systems. At its core, it focuses on communication between nodes via structured states and logical edges, enabling a flexible and efficient workflow. Let‚Äôs break down the core concepts:\n",
            "1. What is a State?\n",
            "===\n",
            "Raw Content: Published Time: 2024-12-15T15:58:51.867Z\n",
            "LangGraph Basics: Understanding State, Schema, Nodes, and Edges | by Story_Teller | Medium\n",
            "Open in app\n",
            "Sign up\n",
            "Sign in\n",
            "\n",
            "Write\n",
            "\n",
            "Sign up\n",
            "Sign in\n",
            "\n",
            "LangGraph Basics: Understanding State, Schema, Nodes, and Edges\n",
            "\n",
            "Story_Teller\n",
            "¬∑Follow\n",
            "5 min read\n",
            "¬∑\n",
            "Dec 15, 2024\n",
            "\n",
            "16\n",
            "\n",
            "Listen\n",
            "Share\n",
            "LangGraph is a message-passing framework for building modular, graph-based systems. At its core, it focuses on communication between nodes via structured states and logical edges, enabling a flexible and efficient workflow. Let‚Äôs break down the core concepts:\n",
            "1. What is a State?\n",
            "In LangGraph, the state is the central mechanism for communication between nodes. It acts as a structured message that encapsulates the current snapshot of the system at any given moment.\n",
            "According to the LangGraph documentation:\n",
            "\n",
            "‚ÄúA state is a shared data structure that represents the current snapshot of your application.‚Äù\n",
            "\n",
            "States are passed along edges between nodes, carrying the output of one node to the next as input. This makes the state the backbone of any message-passing graph.\n",
            "2. What is a Schema in LangGraph?\n",
            "A schema defines the structure of the state. It ensures the data being passed between nodes follows a consistent format.\n",
            "\n",
            "In Python terms, a schema can be any data type.\n",
            "However, it is typically represented using TypedDict or a Pydantic BaseModel.\n",
            "\n",
            "The schema helps nodes interpret the state correctly, ensuring smooth execution across the graph.\n",
            "LangGraph Basics: Understanding State, Schema, Nodes, and Edges\n",
            "LangGraph is a message-passing framework for building modular, graph-based systems. At its core, it focuses on communication between nodes via structured states and logical edges, enabling a flexible and efficient workflow. Let‚Äôs break down the core concepts:\n",
            "1. What is a State?\n",
            "In LangGraph, the state is the central mechanism for communication between nodes. It acts as a structured message that encapsulates the current snapshot of the system at any given moment.\n",
            "According to the LangGraph documentation:\n",
            "\n",
            "‚ÄúA state is a shared data structure that represents the current snapshot of your application.‚Äù\n",
            "\n",
            "States are passed along edges between nodes, carrying the output of one node to the next as input. This makes the state the backbone of any message-passing graph.\n",
            "2. What is a Schema in LangGraph?\n",
            "A schema defines the structure\n",
            "\n",
            "Source What Is LangGraph and How to Use It? - DataCamp:\n",
            "===\n",
            "URL: https://www.datacamp.com/tutorial/langgraph-tutorial\n",
            "===\n",
            "Most relevant content from source: LangGraph is a library within the LangChain ecosystem designed to tackle these challenges head-on. LangGraph provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured manner.\n",
            "It simplifies the development process by enabling the creation of cyclical graphs, which are essential for developing agent runtimes. With LangGraph, we can easily build robust, scalable, and flexible multi-agent systems. [...] Home\n",
            "Tutorials\n",
            "Artificial Intelligence\n",
            "\n",
            "LangGraph Tutorial: What Is LangGraph and How to Use It?\n",
            "LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.\n",
            "Contents\n",
            "Jun 26, 2024 ¬†¬∑ 12 min read\n",
            "Contents\n",
            "\n",
            "What Is LangGraph?\n",
            "Graph structure\n",
            "State management\n",
            "\n",
            "Coordination\n",
            "\n",
            "\n",
            "Why LangGraph?\n",
            "\n",
            "Simplified development\n",
            "Flexibility\n",
            "Scalability\n",
            "\n",
            "Fault tolerance [...] If you want to learn more about the LangChain ecosystem, I recommend this introduction to LangChain.\n",
            "What Is LangGraph?\n",
            "LangGraph enables us to create stateful, multi-actor applications utilizing LLMs as easily as possible. It extends the capabilities of LangChain, introducing the ability to create and manage cyclical graphs, which are pivotal for developing sophisticated agent runtimes. The core concepts of LangGraph include: graph structure, state management, and coordination.\n",
            "Graph structure\n",
            "===\n",
            "Raw Content: Published Time: 2024-06-26T21:00:00.000Z\n",
            "LangGraph Tutorial: What Is LangGraph and How to Use It? | DataCamp\n",
            " ##### Get 50% off unlimited learning Buy Now\n",
            "Skip to main content\n",
            "Write for us\n",
            "EN\n",
            "EnglishEspa√±olBetaPortugu√™sBetaDeutschBetaFran√ßaisBeta\n",
            "\n",
            "Found an Error?\n",
            "Log InGet Started\n",
            "Tutorials\n",
            "Blogs\n",
            "Tutorials\n",
            "docs\n",
            "Podcasts\n",
            "Cheat Sheets\n",
            "code-alongs\n",
            "Category\n",
            "Category\n",
            "Technologies\n",
            "Discover content by tools and technology\n",
            "Artificial IntelligenceAWSAzureBusiness IntelligenceChatGPTDatabricksdbtDockerExcelGenerative AIGitGoogle Cloud PlatformHugging FaceJavaJuliaKubernetesLarge Language ModelsOpenAIPostgreSQLPower BIPythonRScalaSnowflakeSpreadsheetsSQLSQLiteTableau\n",
            "Category\n",
            "Topics\n",
            "Discover content by data science topics\n",
            "AI for BusinessBig DataCareer ServicesCloudData AnalysisData EngineeringData LiteracyData ScienceData VisualizationDataLabDeep LearningMachine LearningMLOpsNatural Language Processing\n",
            "Request a Demo\n",
            "category\n",
            "\n",
            "Home\n",
            "Tutorials\n",
            "Artificial Intelligence\n",
            "\n",
            "LangGraph Tutorial: What Is LangGraph and How to Use It?\n",
            "LangGraph is a library within the LangChain ecosystem that provides a framework for defining, coordinating, and executing multiple LLM agents (or chains) in a structured and efficient manner.\n",
            "Contents\n",
            "Jun 26, 2024 ¬†¬∑ 12 min read\n",
            "Contents\n",
            "\n",
            "What Is LangGraph?\n",
            "Graph structure\n",
            "State management\n",
            "\n",
            "Coordination\n",
            "\n",
            "\n",
            "Why LangGraph?\n",
            "\n",
            "Simplified development\n",
            "Flexibility\n",
            "Scalability\n",
            "\n",
            "Fault tolerance\n",
            "\n",
            "\n",
            "Getting Started With LangGraph\n",
            "\n",
            "Installation\n",
            "\n",
            "Basic Concepts\n",
            "\n",
            "\n",
            "Building a Simple LangGraph Application\n",
            "\n",
            "Step 1: Define the StateGraph\n",
            "Step 2: Initialize an LLM and add it as a Chatbot node\n",
            "Step 3: Set edges\n",
            "\n",
            "Step 5: Run the chatbot\n",
            "\n",
            "\n",
            "Advanced LangGraph Features\n",
            "\n",
            "Custom node types\n",
            "Edge types\n",
            "\n",
            "Error handling\n",
            "\n",
            "\n",
            "Real-World Applications of LangGraph\n",
            "\n",
            "Chatbots\n",
            "Autonomous agents\n",
            "Multi-Agent systems\n",
            "Workflow automation tools\n",
            "Recommendation systems\n",
            "\n",
            "Personalized learning environments\n",
            "\n",
            "\n",
            "Conclusion\n",
            "\n",
            "\n",
            "Training more people?\n",
            "Get your team access to the full DataCamp for business platform.\n",
            "For BusinessFor a bespoke solution book a demo.\n",
            "Imagine you're building a complex, multi-agent large language model (LLM) application. It's exciting, but it comes\n",
            "\n",
            "Source LangGraph - GitHub Pages:\n",
            "===\n",
            "URL: https://langchain-ai.github.io/langgraph/\n",
            "===\n",
            "Most relevant content from source: Note\n",
            "Looking for the JS version? See the JS repo and the JS docs.\n",
            "LangGraph ‚Äî used by Replit, Uber, LinkedIn, GitLab and more ‚Äî is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration ‚Äî offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.\n",
            "===\n",
            "Raw Content: LangGraph\n",
            "Skip to content\n",
            "Join us at Interrupt: The Agent AI Conference by LangChain on May 13 & 14 in San Francisco!\n",
            " \n",
            "LangGraph\n",
            "\n",
            "Initializing search\n",
            "GitHub\n",
            "\n",
            "Home\n",
            "API reference\n",
            "\n",
            " \n",
            "GitHub\n",
            "\n",
            "\n",
            "[ ] \n",
            "Home\n",
            "Home\n",
            "\n",
            "\n",
            "[ ]  Get started\n",
            "Get started\n",
            "\n",
            "Learn the basics\n",
            "Deployment\n",
            "\n",
            "\n",
            "\n",
            "[ ]  Guides\n",
            "Guides\n",
            "\n",
            "How-to Guides\n",
            "Concepts\n",
            "Tutorials\n",
            "\n",
            "\n",
            "\n",
            "[ ]  Resources\n",
            "Resources\n",
            "\n",
            "Prebuilt Agents\n",
            "Companies using LangGraph\n",
            "LLMS-txt\n",
            "FAQ\n",
            "Troubleshooting\n",
            "LangGraph Academy Course\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "API reference\n",
            "\n",
            "\n",
            "Table of contents\n",
            "\n",
            "Why use LangGraph?\n",
            "LangGraph‚Äôs ecosystem\n",
            "Pairing with LangGraph Platform\n",
            "Additional resources\n",
            "Acknowledgements\n",
            "\n",
            "\n",
            "LangGraph\n",
            " \n",
            "\n",
            "   \n",
            "Note\n",
            "Looking for the JS version? See the JS repo and the JS docs.\n",
            "LangGraph ‚Äî used by Replit, Uber, LinkedIn, GitLab and more ‚Äî is a low-level orchestration framework for building controllable agents. While langchain provides integrations and composable components to streamline LLM application development, the LangGraph library enables agent orchestration ‚Äî offering customizable architectures, long-term memory, and human-in-the-loop to reliably handle complex tasks.\n",
            "[](https://langchain-ai.github.io/langgraph/#__codelineno-0-1)pipinstall-Ulanggraph\n",
            "To learn more about how to use LangGraph, check out the docs. We show a simple example below of how to create a ReAct agent.\n",
            "[](https://langchain-ai.github.io/langgraph/#__codelineno-1-1)# This code depends on pip install langchain[anthropic]\n",
            "[](https://langchain-ai.github.io/langgraph/#__codelineno-1-2)fromlanggraph.prebuiltimport create_react_agent\n",
            "[](https://langchain-ai.github.io/langgraph/#__codelineno-1-3)\n",
            "[](https://langchain-ai.github.io/langgraph/#__codelineno-1-4)defsearch(query: str):\n",
            "[](https://langchain-ai.github.io/langgraph/#__codelineno-1-5)\"\"\"Call to surf the web.\"\"\"\n",
            "[](https://langchain-ai.github.io/langgraph/#__codelineno-1-6)    if \"sf\" in query.lower() or \"san francisco\" in query.lower():\n",
            "[](https://langchain-ai.github.io/lang\n",
            "\n",
            "Source LangGraph: Definition, Purpose & Benefits:\n",
            "===\n",
            "URL: https://zencoder.ai/glossary/lang-graph\n",
            "===\n",
            "Most relevant content from source: LangGraph is an essential tool for developers working on language-intensive software projects. By offering visual insights into language resources and fostering effective management, LangGraph contributes to the quality and functionality of language-enabled applications.\n",
            "===\n"
          ]
        }
      ],
      "source": [
        "print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "TVjGRN57M1Zp",
      "metadata": {
        "id": "TVjGRN57M1Zp"
      },
      "source": [
        "## Default Report Template\n",
        "\n",
        "This is the starting point for the LLM to get an idea of how to build a general report and it will use this to build a custom report structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_Mub1ld70yih",
      "metadata": {
        "id": "_Mub1ld70yih"
      },
      "outputs": [],
      "source": [
        "# Structure\n",
        "DEFAULT_REPORT_STRUCTURE = \"\"\"The report structure should focus on breaking-down the user-provided topic\n",
        "                              and building a comprehensive report in markdown using the following format:\n",
        "\n",
        "                              1. Introduction (no web search needed)\n",
        "                                    - Brief overview of the topic area\n",
        "\n",
        "                              2. Main Body Sections:\n",
        "                                    - Each section should focus on a sub-topic of the user-provided topic\n",
        "                                    - Include any key concepts and definitions\n",
        "                                    - Provide real-world examples or case studies where applicable\n",
        "\n",
        "                              3. Conclusion (no web search needed)\n",
        "                                    - Aim for 1 structural element (either a list of table) that distills the main body sections\n",
        "                                    - Provide a concise summary of the report\n",
        "\n",
        "                              When generating the final response in markdown, if there are special characters in the text,\n",
        "                              such as the dollar symbol, ensure they are escaped properly for correct rendering e.g $25.5 should become \\$25.5\n",
        "                          \"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "w-R-V_1SM-Rn",
      "metadata": {
        "id": "w-R-V_1SM-Rn"
      },
      "source": [
        "## Instruction Prompts for Report Planner\n",
        "\n",
        "There are two main instruction prompts:\n",
        "\n",
        "- __REPORT_PLAN_QUERY_GENERATOR_PROMPT:__ Helps the LLM to generate an initial list of questions based on the topic to get more information from the web about that topic so that it can plan the overall sections and structure of the report\n",
        "\n",
        "- __REPORT_PLAN_SECTION_GENERATOR_PROMPT:__ Here we feed the LLM with the default report template, the topic name and the search results from the intial queries generated to create a detailed structure for the report. The LLM will generate a structured response of the following fields for each major section which will be in the report (this is just the report structure - no content is created at this step):\n",
        "    - Name - Name for this section of the report.\n",
        "    - Description - Brief overview of the main topics and concepts to be covered in this section.\n",
        "    - Research - Whether to perform web search for this section of the report or not.\n",
        "    - Content - The content of the section, which you will leave blank for now."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "vjoRG-IP0zkx",
      "metadata": {
        "id": "vjoRG-IP0zkx"
      },
      "outputs": [],
      "source": [
        "REPORT_PLAN_QUERY_GENERATOR_PROMPT = \"\"\"You are an expert technical report writer, helping to plan a report.\n",
        "\n",
        "The report will be focused on the following topic:\n",
        "{topic}\n",
        "\n",
        "The report structure will follow these guidelines:\n",
        "{report_organization}\n",
        "\n",
        "Your goal is to generate {number_of_queries} search queries that will help gather comprehensive information for planning the report sections.\n",
        "\n",
        "The query should:\n",
        "1. Be related to the topic\n",
        "2. Help satisfy the requirements specified in the report organization\n",
        "\n",
        "Make the query specific enough to find high-quality, relevant sources while covering the depth and breadth needed for the report structure.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "qBjAzBjd2pYa",
      "metadata": {
        "id": "qBjAzBjd2pYa"
      },
      "outputs": [],
      "source": [
        "REPORT_PLAN_SECTION_GENERATOR_PROMPT = \"\"\"You are an expert technical report writer, helping to plan a report.\n",
        "\n",
        "Your goal is to generate the outline of the sections of the report.\n",
        "\n",
        "The overall topic of the report is:\n",
        "{topic}\n",
        "\n",
        "The report should follow this organizational structure:\n",
        "{report_organization}\n",
        "\n",
        "You should reflect on this additional context information from web searches to plan the main sections of the report:\n",
        "{search_context}\n",
        "\n",
        "Now, generate the sections of the report. Each section should have the following fields:\n",
        "- Name - Name for this section of the report.\n",
        "- Description - Brief overview of the main topics and concepts to be covered in this section.\n",
        "- Research - Whether to perform web search for this section of the report or not.\n",
        "- Content - The content of the section, which you will leave blank for now.\n",
        "\n",
        "Consider which sections require web search.\n",
        "For example, introduction and conclusion will not require research because they will distill information from other parts of the report.\n",
        "\"\"\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "BcGmRLcQOE-U",
      "metadata": {
        "id": "BcGmRLcQOE-U"
      },
      "source": [
        "## Node Function for Report Planner\n",
        "\n",
        "![](https://i.imgur.com/54Jyv71.png)\n",
        "\n",
        "This function uses the two prompts created above to:\n",
        " - First generate some queries based on the user topic\n",
        " - Search the web and get some information on these queries\n",
        " - Use this information to generate the overall structure of the report with the key sections necessary to be created"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "OH8ihSnZ0hHf",
      "metadata": {
        "id": "OH8ihSnZ0hHf"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI \n",
        "from langchain_core.messages import HumanMessage, SystemMessage\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash\", api_key= GEMINI_API_KEY,temperature=0)\n",
        "\n",
        "async def generate_report_plan(state: ReportState):\n",
        "    \"\"\"Generate the overall plan for building the report\"\"\"\n",
        "    topic = state[\"topic\"]\n",
        "    print('--- Generating Report Plan ---')\n",
        "\n",
        "    report_structure = DEFAULT_REPORT_STRUCTURE\n",
        "    number_of_queries = 8\n",
        "\n",
        "    structured_llm = llm.with_structured_output(Queries)\n",
        "\n",
        "    system_instructions_query = REPORT_PLAN_QUERY_GENERATOR_PROMPT.format(\n",
        "        topic=topic,\n",
        "        report_organization=report_structure,\n",
        "        number_of_queries=number_of_queries\n",
        "    )\n",
        "\n",
        "    try:\n",
        "        # Generate queries\n",
        "        results = structured_llm.invoke([\n",
        "            SystemMessage(content=system_instructions_query),\n",
        "            HumanMessage(content='Generate search queries that will help with planning the sections of the report.')\n",
        "        ])\n",
        "\n",
        "        # Convert SearchQuery objects to strings\n",
        "        query_list = [\n",
        "            query.search_query if isinstance(query, SearchQuery) else str(query)\n",
        "            for query in results.queries\n",
        "        ]\n",
        "\n",
        "        # Search web and ensure we wait for results\n",
        "        search_docs = await run_search_queries(\n",
        "            query_list,\n",
        "            num_results=5,\n",
        "            include_raw_content=False\n",
        "        )\n",
        "\n",
        "        if not search_docs:\n",
        "            print(\"Warning: No search results returned\")\n",
        "            search_context = \"No search results available.\"\n",
        "        else:\n",
        "            search_context = format_search_query_results(\n",
        "                search_docs,\n",
        "                include_raw_content=False\n",
        "            )\n",
        "\n",
        "        # Generate sections\n",
        "        system_instructions_sections = REPORT_PLAN_SECTION_GENERATOR_PROMPT.format(\n",
        "            topic=topic,\n",
        "            report_organization=report_structure,\n",
        "            search_context=search_context\n",
        "        )\n",
        "\n",
        "        structured_llm = llm.with_structured_output(Sections)\n",
        "        report_sections = structured_llm.invoke([\n",
        "            SystemMessage(content=system_instructions_sections),\n",
        "            HumanMessage(content=\"Generate the sections of the report. Your response must include a 'sections' field containing a list of sections. Each section must have: name, description, plan, research, and content fields.\")\n",
        "        ])\n",
        "\n",
        "        print('--- Generating Report Plan Completed ---')\n",
        "        return {\"sections\": report_sections.sections}\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error in generate_report_plan: {e}\")\n",
        "        return {\"sections\": []}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "j8zCsQwuQbeO",
      "metadata": {
        "id": "j8zCsQwuQbeO"
      },
      "source": [
        "## Instruction Prompts for Section Builder - Query Generator\n",
        "\n",
        "There is one main instruction prompt:\n",
        "\n",
        "- __REPORT_SECTION_QUERY_GENERATOR_PROMPT:__ Helps the LLM to generate a comprehensive list of questions for the topic of that specific section which needs to be built"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "uxLrzsyY5Mdl",
      "metadata": {
        "id": "uxLrzsyY5Mdl"
      },
      "outputs": [],
      "source": [
        "REPORT_SECTION_QUERY_GENERATOR_PROMPT = \"\"\"Your goal is to generate targeted web search queries that will gather comprehensive information for writing a technical report section.\n",
        "\n",
        "Topic for this section:\n",
        "{section_topic}\n",
        "\n",
        "When generating {number_of_queries} search queries, ensure that they:\n",
        "1. Cover different aspects of the topic (e.g., core features, real-world applications, technical architecture)\n",
        "2. Include specific technical terms related to the topic\n",
        "3. Target recent information by including year markers where relevant (e.g., \"2024\")\n",
        "4. Look for comparisons or differentiators from similar technologies/approaches\n",
        "5. Search for both official documentation and practical implementation examples\n",
        "\n",
        "Your queries should be:\n",
        "- Specific enough to avoid generic results\n",
        "- Technical enough to capture detailed implementation information\n",
        "- Diverse enough to cover all aspects of the section plan\n",
        "- Focused on authoritative sources (documentation, technical blogs, academic papers)\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JP6AVB1YRqpG",
      "metadata": {
        "id": "JP6AVB1YRqpG"
      },
      "source": [
        "## Node Function for Section Builder - Generate Queries (Query Generator)\n",
        "\n",
        "This uses the section topic and the instruction prompt above to generate some questions for researching on the web for getting useful information on the section topic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "1tdPfB6m3taO",
      "metadata": {
        "id": "1tdPfB6m3taO"
      },
      "outputs": [],
      "source": [
        "def generate_queries(state: SectionState):\n",
        "    \"\"\" Generate search queries for a specific report section \"\"\"\n",
        "\n",
        "\n",
        "\n",
        "    # Get state\n",
        "    section = state[\"section\"]\n",
        "    print('--- Generating Search Queries for Section: '+ section.name +' ---')\n",
        "\n",
        "    # Get configuration\n",
        "    number_of_queries = 5\n",
        "\n",
        "    # Generate queries\n",
        "    structured_llm = llm.with_structured_output(Queries)\n",
        "\n",
        "    # Format system instructions\n",
        "    system_instructions = REPORT_SECTION_QUERY_GENERATOR_PROMPT.format(section_topic=section.description,\n",
        "                                                                       number_of_queries=number_of_queries)\n",
        "\n",
        "    # Generate queries\n",
        "    user_instruction = \"Generate search queries on the provided topic.\"\n",
        "    search_queries = structured_llm.invoke([SystemMessage(content=system_instructions),\n",
        "                                     HumanMessage(content=user_instruction)])\n",
        "\n",
        "    print('--- Generating Search Queries for Section: '+ section.name +' Completed ---')\n",
        "\n",
        "    return {\"search_queries\": search_queries.queries}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6G_8doZxR8QC",
      "metadata": {
        "id": "6G_8doZxR8QC"
      },
      "source": [
        "## Node Function for Section Builder - Search Web\n",
        "\n",
        "Takes the queries generated by `generate_queries(...)`for a specific section, searches the web and formats the search results using the utility functions we defined earlier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "id": "Te1lHnkqRcBH",
      "metadata": {
        "id": "Te1lHnkqRcBH"
      },
      "outputs": [],
      "source": [
        "async def search_web(state: SectionState):\n",
        "    \"\"\" Search the web for each query, then return a list of raw sources and a formatted string of sources.\"\"\"\n",
        "\n",
        "    # Get state\n",
        "    search_queries = state[\"search_queries\"]\n",
        "\n",
        "    print('--- Searching Web for Queries ---')\n",
        "\n",
        "    # Web search\n",
        "    query_list = [query.search_query for query in search_queries]\n",
        "    search_docs = await run_search_queries(search_queries, num_results=6, include_raw_content=True)\n",
        "\n",
        "    # Deduplicate and format sources\n",
        "    search_context = format_search_query_results(search_docs, max_tokens=4000, include_raw_content=True)\n",
        "\n",
        "    print('--- Searching Web for Queries Completed ---')\n",
        "\n",
        "    return {\"source_str\": search_context}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5_ytIcDFUQMZ",
      "metadata": {
        "id": "5_ytIcDFUQMZ"
      },
      "source": [
        "## Instruction Prompts for Section Builder - Section Writer\n",
        "\n",
        "There is one main instruction prompt:\n",
        "\n",
        "- __SECTION_WRITER_PROMPT:__ Constrains the LLM to generate and write the content for a specific section using certain guidelines on style, structure, length, approach and the documents obtained from the web earlier using the `search_web(...)` function are also sent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "Fc8VGgaK-UkT",
      "metadata": {
        "id": "Fc8VGgaK-UkT"
      },
      "outputs": [],
      "source": [
        "SECTION_WRITER_PROMPT = \"\"\"You are an expert technical writer crafting one specific section of a technical report.\n",
        "\n",
        "Title for the section:\n",
        "{section_title}\n",
        "\n",
        "Topic for this section:\n",
        "{section_topic}\n",
        "\n",
        "Guidelines for writing:\n",
        "\n",
        "1. Technical Accuracy:\n",
        "- Include specific version numbers\n",
        "- Reference concrete metrics/benchmarks\n",
        "- Cite official documentation\n",
        "- Use technical terminology precisely\n",
        "\n",
        "2. Length and Style:\n",
        "- Strict 150-200 word limit\n",
        "- No marketing language\n",
        "- Technical focus\n",
        "- Write in simple, clear language do not use complex words unnecessarily\n",
        "- Start with your most important insight in **bold**\n",
        "- Use short paragraphs (2-3 sentences max)\n",
        "\n",
        "3. Structure:\n",
        "- Use ## for section title (Markdown format)\n",
        "- Only use ONE structural element IF it helps clarify your point:\n",
        "  * Either a focused table comparing 2-3 key items (using Markdown table syntax)\n",
        "  * Or a short list (3-5 items) using proper Markdown list syntax:\n",
        "    - Use `*` or `-` for unordered lists\n",
        "    - Use `1.` for ordered lists\n",
        "    - Ensure proper indentation and spacing\n",
        "- End with ### Sources that references the below source material formatted as:\n",
        "  * List each source with title, date, and URL\n",
        "  * Format: `- Title : URL`\n",
        "\n",
        "3. Writing Approach:\n",
        "- Include at least one specific example or case study if available\n",
        "- Use concrete details over general statements\n",
        "- Make every word count\n",
        "- No preamble prior to creating the section content\n",
        "- Focus on your single most important point\n",
        "\n",
        "4. Use this source material obtained from web searches to help write the section:\n",
        "{context}\n",
        "\n",
        "5. Quality Checks:\n",
        "- Format should be Markdown\n",
        "- Exactly 150-200 words (excluding title and sources)\n",
        "- Careful use of only ONE structural element (table or bullet list) and only if it helps clarify your point\n",
        "- One specific example / case study if available\n",
        "- Starts with bold insight\n",
        "- No preamble prior to creating the section content\n",
        "- Sources cited at end\n",
        "- If there are special characters in the text, such as the dollar symbol,\n",
        "  ensure they are escaped properly for correct rendering e.g $25.5 should become \\$25.5\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5Vg97bh3USLp",
      "metadata": {
        "id": "5Vg97bh3USLp"
      },
      "source": [
        "## Node Function for Section Builder - Write Section (Section Writer)\n",
        "\n",
        "Uses the SECTION_WRITER_PROMPT from above and feeds it with the section name, description and web search documents and passes it to an LLM to write the content for that section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "mSgrxeeJ8I-O",
      "metadata": {
        "id": "mSgrxeeJ8I-O"
      },
      "outputs": [],
      "source": [
        "def write_section(state: SectionState):\n",
        "    \"\"\" Write a section of the report \"\"\"\n",
        "\n",
        "    # Get state\n",
        "    section = state[\"section\"]\n",
        "    source_str = state[\"source_str\"]\n",
        "\n",
        "    print('--- Writing Section : '+ section.name +' ---')\n",
        "\n",
        "    # Format system instructions\n",
        "    system_instructions = SECTION_WRITER_PROMPT.format(section_title=section.name,\n",
        "                                                       section_topic=section.description,\n",
        "                                                       context=source_str)\n",
        "\n",
        "    # Generate section\n",
        "    user_instruction = \"Generate a report section based on the provided sources.\"\n",
        "    section_content = llm.invoke([SystemMessage(content=system_instructions),\n",
        "                                  HumanMessage(content=user_instruction)])\n",
        "\n",
        "    # Write content to the section object\n",
        "    section.content = section_content.content\n",
        "\n",
        "    print('--- Writing Section : '+ section.name +' Completed ---')\n",
        "\n",
        "    # Write the updated section to completed sections\n",
        "    return {\"completed_sections\": [section]}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "JIvVGOPwSNgQ",
      "metadata": {
        "id": "JIvVGOPwSNgQ"
      },
      "source": [
        "## Create the Section Builder Sub-Agent\n",
        "\n",
        "![](https://i.imgur.com/5VEYGrQ.png)\n",
        "\n",
        "This agent (or to be more specific, sub-agent) will be called several times in parallel, once for each section to search the web, get content and then write up that specific section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "UYB9crmZRcDD",
      "metadata": {
        "id": "UYB9crmZRcDD"
      },
      "outputs": [],
      "source": [
        "from langgraph.graph import StateGraph, START, END\n",
        "\n",
        "# Add nodes and edges\n",
        "section_builder = StateGraph(SectionState, output=SectionOutputState)\n",
        "section_builder.add_node(\"generate_queries\", generate_queries)\n",
        "section_builder.add_node(\"search_web\", search_web)\n",
        "section_builder.add_node(\"write_section\", write_section)\n",
        "\n",
        "section_builder.add_edge(START, \"generate_queries\")\n",
        "section_builder.add_edge(\"generate_queries\", \"search_web\")\n",
        "section_builder.add_edge(\"search_web\", \"write_section\")\n",
        "section_builder.add_edge(\"write_section\", END)\n",
        "section_builder_subagent = section_builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "kkGDMBRTRcFx",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "kkGDMBRTRcFx",
        "outputId": "c070cdba-dfef-40d5-cd45-00ab705662af"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Display the graph\n",
        "from IPython.display import display, Image\n",
        "Image(section_builder_subagent.get_graph().draw_mermaid_png())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "jrw1YPEHWD12",
      "metadata": {
        "id": "jrw1YPEHWD12"
      },
      "source": [
        "### Create Dynamic Parallelization Node Function - Parallelize Section Writing\n",
        "\n",
        "`Send(...)` is used to parallelize and call the `section_builder_subagent` once for each section to write up the content (in parallel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "id": "W7_5uWR2DkgN",
      "metadata": {
        "id": "W7_5uWR2DkgN"
      },
      "outputs": [],
      "source": [
        "from langgraph.constants import Send\n",
        "\n",
        "def parallelize_section_writing(state: ReportState):\n",
        "    \"\"\" This is the \"map\" step when we kick off web research for some sections of the report in parallel and then write the section\"\"\"\n",
        "\n",
        "    # Kick off section writing in parallel via Send() API for any sections that require research\n",
        "    return [\n",
        "        Send(\"section_builder_with_web_search\", # name of the subagent node\n",
        "             {\"section\": s})\n",
        "            for s in state[\"sections\"]\n",
        "              if s.research\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "YDquAhSNYz06",
      "metadata": {
        "id": "YDquAhSNYz06"
      },
      "source": [
        "## Create Format Sections Node Function\n",
        "\n",
        "This is basically the section where all the sections are formatted and combined together into one big document.\n",
        "\n",
        "![](https://i.imgur.com/6e5ZWK4.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "uNlTvupUCHI9",
      "metadata": {
        "id": "uNlTvupUCHI9"
      },
      "outputs": [],
      "source": [
        "def format_sections(sections: list[Section]) -> str:\n",
        "    \"\"\" Format a list of report sections into a single text string \"\"\"\n",
        "    formatted_str = \"\"\n",
        "    for idx, section in enumerate(sections, 1):\n",
        "        formatted_str += f\"\"\"\n",
        "{'='*60}\n",
        "Section {idx}: {section.name}\n",
        "{'='*60}\n",
        "Description:\n",
        "{section.description}\n",
        "Requires Research:\n",
        "{section.research}\n",
        "\n",
        "Content:\n",
        "{section.content if section.content else '[Not yet written]'}\n",
        "\n",
        "\"\"\"\n",
        "    return formatted_str\n",
        "\n",
        "\n",
        "def format_completed_sections(state: ReportState):\n",
        "    \"\"\" Gather completed sections from research and format them as context for writing the final sections \"\"\"\n",
        "\n",
        "    print('--- Formatting Completed Sections ---')\n",
        "\n",
        "    # List of completed sections\n",
        "    completed_sections = state[\"completed_sections\"]\n",
        "\n",
        "    # Format completed section to str to use as context for final sections\n",
        "    completed_report_sections = format_sections(completed_sections)\n",
        "\n",
        "    print('--- Formatting Completed Sections is Done ---')\n",
        "\n",
        "    return {\"report_sections_from_research\": completed_report_sections}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "l22EjIp1ZUTj",
      "metadata": {
        "id": "l22EjIp1ZUTj"
      },
      "source": [
        "## Instruction Prompts for Final Section\n",
        "\n",
        "There is one main instruction prompt:\n",
        "\n",
        "- __FINAL_SECTION_WRITER_PROMPT:__ Constrains the LLM to generate and write the content for either the introduction OR conclusion using certain guidelines on style, structure, length, approach and the content of the already written sections are also sent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "OEZqj7PFA2U_",
      "metadata": {
        "id": "OEZqj7PFA2U_"
      },
      "outputs": [],
      "source": [
        "FINAL_SECTION_WRITER_PROMPT = \"\"\"You are an expert technical writer crafting a section that synthesizes information from the rest of the report.\n",
        "\n",
        "Title for the section:\n",
        "{section_title}\n",
        "\n",
        "Topic for this section:\n",
        "{section_topic}\n",
        "\n",
        "Available report content of already completed sections:\n",
        "{context}\n",
        "\n",
        "1. Section-Specific Approach:\n",
        "\n",
        "For Introduction:\n",
        "- Use # for report title (Markdown format)\n",
        "- 50-100 word limit\n",
        "- Write in simple and clear language\n",
        "- Focus on the core motivation for the report in 1-2 paragraphs\n",
        "- Use a clear narrative arc to introduce the report\n",
        "- Include NO structural elements (no lists or tables)\n",
        "- No sources section needed\n",
        "\n",
        "For Conclusion/Summary:\n",
        "- Use ## for section title (Markdown format)\n",
        "- 100-150 word limit\n",
        "- For comparative reports:\n",
        "    * Must include a focused comparison table using Markdown table syntax\n",
        "    * Table should distill insights from the report\n",
        "    * Keep table entries clear and concise\n",
        "- For non-comparative reports:\n",
        "    * Only use ONE structural element IF it helps distill the points made in the report:\n",
        "    * Either a focused table comparing items present in the report (using Markdown table syntax)\n",
        "    * Or a short list using proper Markdown list syntax:\n",
        "      - Use `*` or `-` for unordered lists\n",
        "      - Use `1.` for ordered lists\n",
        "      - Ensure proper indentation and spacing\n",
        "- End with specific next steps or implications\n",
        "- No sources section needed\n",
        "\n",
        "3. Writing Approach:\n",
        "- Use concrete details over general statements\n",
        "- Make every word count\n",
        "- Focus on your single most important point\n",
        "\n",
        "4. Quality Checks:\n",
        "- For introduction: 50-100 word limit, # for report title, no structural elements, no sources section\n",
        "- For conclusion: 100-150 word limit, ## for section title, only ONE structural element at most, no sources section\n",
        "- Markdown format\n",
        "- Do not include word count or any preamble in your response\n",
        "- If there are special characters in the text, such as the dollar symbol,\n",
        "  ensure they are escaped properly for correct rendering e.g $25.5 should become \\$25.5\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Myztb9Eeb-88",
      "metadata": {
        "id": "Myztb9Eeb-88"
      },
      "source": [
        "## Create Write Final Sections Node Function\n",
        "\n",
        "This function uses the instruction prompot FINAL_SECTION_WRITER_PROMPT mentioned above to write up the introduction and conclusion. This function will be executed in parallel using `Send(...)` below\n",
        "\n",
        "![](https://i.imgur.com/pRv4PX8.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "id": "rRSoWr_MAIun",
      "metadata": {
        "id": "rRSoWr_MAIun"
      },
      "outputs": [],
      "source": [
        "def write_final_sections(state: SectionState):\n",
        "    \"\"\" Write the final sections of the report, which do not require web search and use the completed sections as context\"\"\"\n",
        "\n",
        "    # Get state\n",
        "    section = state[\"section\"]\n",
        "    completed_report_sections = state[\"report_sections_from_research\"]\n",
        "\n",
        "    print('--- Writing Final Section: '+ section.name + ' ---')\n",
        "\n",
        "    # Format system instructions\n",
        "    system_instructions = FINAL_SECTION_WRITER_PROMPT.format(section_title=section.name,\n",
        "                                                             section_topic=section.description,\n",
        "                                                             context=completed_report_sections)\n",
        "\n",
        "    # Generate section\n",
        "    user_instruction = \"Craft a report section based on the provided sources.\"\n",
        "    section_content = llm.invoke([SystemMessage(content=system_instructions),\n",
        "                                  HumanMessage(content=user_instruction)])\n",
        "\n",
        "    # Write content to section\n",
        "    section.content = section_content.content\n",
        "\n",
        "    print('--- Writing Final Section: '+ section.name + ' Completed ---')\n",
        "\n",
        "    # Write the updated section to completed sections\n",
        "    return {\"completed_sections\": [section]}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "XIHk7dkbdGdn",
      "metadata": {
        "id": "XIHk7dkbdGdn"
      },
      "source": [
        "### Create Dynamic Parallelization Node Function - Parallelize Final Section Writing\n",
        "\n",
        "`Send(...)` is used to parallelize and call the `write_final_sections` once for each of the introduction and conclusion to write up the content (in parallel)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "id": "gaXMkCuZDP9h",
      "metadata": {
        "id": "gaXMkCuZDP9h"
      },
      "outputs": [],
      "source": [
        "from langgraph.constants import Send\n",
        "\n",
        "def parallelize_final_section_writing(state: ReportState):\n",
        "    \"\"\" Write any final sections using the Send API to parallelize the process \"\"\"\n",
        "\n",
        "    # Kick off section writing in parallel via Send() API for any sections that do not require research\n",
        "    return [\n",
        "        Send(\"write_final_sections\",\n",
        "             {\"section\": s, \"report_sections_from_research\": state[\"report_sections_from_research\"]})\n",
        "                 for s in state[\"sections\"]\n",
        "                    if not s.research\n",
        "    ]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fCwKY0o_dWeM",
      "metadata": {
        "id": "fCwKY0o_dWeM"
      },
      "source": [
        "## Compile Final Report Node Function\n",
        "\n",
        "This function combines all the sections of the report together and compiles it into the final report document\n",
        "\n",
        "![](https://i.imgur.com/wLxCNZ5.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "id": "PPlIQZl2Ddrk",
      "metadata": {
        "id": "PPlIQZl2Ddrk"
      },
      "outputs": [],
      "source": [
        "def compile_final_report(state: ReportState):\n",
        "    \"\"\" Compile the final report \"\"\"\n",
        "\n",
        "    # Get sections\n",
        "    sections = state[\"sections\"]\n",
        "    completed_sections = {s.name: s.content for s in state[\"completed_sections\"]}\n",
        "\n",
        "    print('--- Compiling Final Report ---')\n",
        "\n",
        "    # Update sections with completed content while maintaining original order\n",
        "    for section in sections:\n",
        "        section.content = completed_sections[section.name]\n",
        "\n",
        "    # Compile final report\n",
        "    all_sections = \"\\n\\n\".join([s.content for s in sections])\n",
        "    # Escape unescaped $ symbols to display properly in Markdown\n",
        "    formatted_sections = all_sections.replace(\"\\\\$\", \"TEMP_PLACEHOLDER\")  # Temporarily mark already escaped $\n",
        "    formatted_sections = formatted_sections.replace(\"$\", \"\\\\$\")  # Escape all $\n",
        "    formatted_sections = formatted_sections.replace(\"TEMP_PLACEHOLDER\", \"\\\\$\")  # Restore originally escaped $\n",
        "\n",
        "# Now escaped_sections contains the properly escaped Markdown text\n",
        "\n",
        "\n",
        "    print('--- Compiling Final Report Done ---')\n",
        "\n",
        "    return {\"final_report\": formatted_sections}\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "i10VLrxKePMo",
      "metadata": {
        "id": "i10VLrxKePMo"
      },
      "source": [
        "## Build our Report Writer Planning Agent\n",
        "\n",
        "We now bring all the defined components and sub-agent together and build our planning agent\n",
        "\n",
        "![](https://i.imgur.com/STSC73k.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "id": "8WhUNRSJDLGX",
      "metadata": {
        "id": "8WhUNRSJDLGX"
      },
      "outputs": [],
      "source": [
        "builder = StateGraph(ReportState, input=ReportStateInput, output=ReportStateOutput)\n",
        "\n",
        "builder.add_node(\"generate_report_plan\", generate_report_plan)\n",
        "builder.add_node(\"section_builder_with_web_search\", section_builder_subagent)\n",
        "builder.add_node(\"format_completed_sections\", format_completed_sections)\n",
        "builder.add_node(\"write_final_sections\", write_final_sections)\n",
        "builder.add_node(\"compile_final_report\", compile_final_report)\n",
        "\n",
        "builder.add_edge(START, \"generate_report_plan\")\n",
        "builder.add_conditional_edges(\"generate_report_plan\",\n",
        "                              parallelize_section_writing,\n",
        "                              [\"section_builder_with_web_search\"])\n",
        "builder.add_edge(\"section_builder_with_web_search\", \"format_completed_sections\")\n",
        "builder.add_conditional_edges(\"format_completed_sections\",\n",
        "                              parallelize_final_section_writing,\n",
        "                              [\"write_final_sections\"])\n",
        "builder.add_edge(\"write_final_sections\", \"compile_final_report\")\n",
        "builder.add_edge(\"compile_final_report\", END)\n",
        "\n",
        "reporter_agent = builder.compile()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "id": "d0owAmm_j5I-",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 896
        },
        "id": "d0owAmm_j5I-",
        "outputId": "ab374eaf-b9bd-46ab-ff2a-b52e063af8dc"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "display(Image(reporter_agent.get_graph(xray=True).draw_mermaid_png()))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "LfIg-JDVearE",
      "metadata": {
        "id": "LfIg-JDVearE"
      },
      "source": [
        "## Run and Test our Agent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "id": "ddra7VuHbiwn",
      "metadata": {
        "id": "ddra7VuHbiwn"
      },
      "outputs": [],
      "source": [
        "from IPython.display import display\n",
        "from rich.console import Console\n",
        "from rich.markdown import Markdown as RichMarkdown\n",
        "\n",
        "async def call_planner_agent(agent, prompt, config={\"recursion_limit\": 50}, verbose=False):\n",
        "    events = agent.astream(\n",
        "        {'topic' : prompt},\n",
        "        config,\n",
        "        stream_mode=\"values\",\n",
        "    )\n",
        "\n",
        "    async for event in events:\n",
        "        for k, v in event.items():\n",
        "            if verbose:\n",
        "                if k != \"__end__\":\n",
        "                    display(RichMarkdown(repr(k) + ' -> ' + repr(v)))\n",
        "            if k == 'final_report':\n",
        "                print('='*50)\n",
        "                print('Final Report:')\n",
        "                md = RichMarkdown(v)\n",
        "                display(md)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "id": "WlDHdzLpFPSO",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WlDHdzLpFPSO",
        "outputId": "f6ea071c-3cac-4e8a-cece-8a94ecd8cb4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Generating Report Plan ---\n",
            "--- Generating Report Plan Completed ---\n",
            "--- Generating Search Queries for Section: Defining Agentic AI ---\n",
            "--- Generating Search Queries for Section: Core Components of Agentic AI Systems ---\n",
            "--- Generating Search Queries for Section: Agentic AI Architectures ---\n",
            "--- Generating Search Queries for Section: Design Patterns for Agentic AI Systems ---\n",
            "--- Generating Search Queries for Section: Frameworks for Building Agentic AI Systems ---\n",
            "--- Generating Search Queries for Section: Real-World Applications of Agentic AI ---\n",
            "--- Generating Search Queries for Section: Challenges and Ethical Considerations ---\n",
            "--- Generating Search Queries for Section: Core Components of Agentic AI Systems Completed ---\n",
            "--- Generating Search Queries for Section: Defining Agentic AI Completed ---\n",
            "--- Searching Web for Queries ---\n",
            "--- Searching Web for Queries ---\n",
            "--- Generating Search Queries for Section: Design Patterns for Agentic AI Systems Completed ---\n",
            "--- Searching Web for Queries ---\n",
            "--- Generating Search Queries for Section: Challenges and Ethical Considerations Completed ---\n",
            "--- Searching Web for Queries ---\n",
            "--- Generating Search Queries for Section: Frameworks for Building Agentic AI Systems Completed ---\n",
            "--- Generating Search Queries for Section: Real-World Applications of Agentic AI Completed ---\n",
            "--- Searching Web for Queries ---\n",
            "--- Searching Web for Queries ---\n",
            "--- Generating Search Queries for Section: Agentic AI Architectures Completed ---\n",
            "--- Searching Web for Queries ---\n",
            "--- Searching Web for Queries Completed ---\n",
            "--- Searching Web for Queries Completed ---\n",
            "--- Writing Section : Defining Agentic AI ---\n",
            "--- Writing Section : Core Components of Agentic AI Systems ---\n",
            "--- Searching Web for Queries Completed ---\n",
            "--- Writing Section : Design Patterns for Agentic AI Systems ---\n",
            "--- Searching Web for Queries Completed ---\n",
            "--- Searching Web for Queries Completed ---\n",
            "--- Writing Section : Challenges and Ethical Considerations ---\n",
            "--- Writing Section : Frameworks for Building Agentic AI Systems ---\n",
            "--- Searching Web for Queries Completed ---\n",
            "--- Writing Section : Real-World Applications of Agentic AI ---\n",
            "--- Searching Web for Queries Completed ---\n",
            "--- Writing Section : Agentic AI Architectures ---\n",
            "--- Writing Section : Defining Agentic AI Completed ---\n",
            "--- Writing Section : Core Components of Agentic AI Systems Completed ---\n",
            "--- Writing Section : Challenges and Ethical Considerations Completed ---\n",
            "--- Writing Section : Frameworks for Building Agentic AI Systems Completed ---\n",
            "--- Writing Section : Design Patterns for Agentic AI Systems Completed ---\n",
            "--- Writing Section : Agentic AI Architectures Completed ---\n",
            "--- Writing Section : Real-World Applications of Agentic AI Completed ---\n",
            "--- Formatting Completed Sections ---\n",
            "--- Formatting Completed Sections is Done ---\n",
            "--- Writing Final Section: Introduction ---\n",
            "--- Writing Final Section: Conclusion ---\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 48\n",
            "}\n",
            "].\n",
            "Retrying langchain_google_genai.chat_models._chat_with_retry.<locals>._chat_with_retry in 2.0 seconds as it raised ResourceExhausted: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n",
            "  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n",
            "  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n",
            "  quota_dimensions {\n",
            "    key: \"model\"\n",
            "    value: \"gemini-2.0-flash\"\n",
            "  }\n",
            "  quota_dimensions {\n",
            "    key: \"location\"\n",
            "    value: \"global\"\n",
            "  }\n",
            "  quota_value: 15\n",
            "}\n",
            ", links {\n",
            "  description: \"Learn more about Gemini API quotas\"\n",
            "  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n",
            "}\n",
            ", retry_delay {\n",
            "  seconds: 48\n",
            "}\n",
            "].\n"
          ]
        },
        {
          "ename": "ResourceExhausted",
          "evalue": "429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 15\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 45\n}\n]",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mResourceExhausted\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m topic = \u001b[33m\"\u001b[39m\u001b[33mDetailed report on how to build Agentic AI systems, design patterns and current frameworks\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m call_planner_agent(agent=reporter_agent,\n\u001b[32m      3\u001b[39m                          prompt=topic)\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[46]\u001b[39m\u001b[32m, line 12\u001b[39m, in \u001b[36mcall_planner_agent\u001b[39m\u001b[34m(agent, prompt, config, verbose)\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcall_planner_agent\u001b[39m(agent, prompt, config={\u001b[33m\"\u001b[39m\u001b[33mrecursion_limit\u001b[39m\u001b[33m\"\u001b[39m: \u001b[32m50\u001b[39m}, verbose=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m      6\u001b[39m     events = agent.astream(\n\u001b[32m      7\u001b[39m         {\u001b[33m'\u001b[39m\u001b[33mtopic\u001b[39m\u001b[33m'\u001b[39m : prompt},\n\u001b[32m      8\u001b[39m         config,\n\u001b[32m      9\u001b[39m         stream_mode=\u001b[33m\"\u001b[39m\u001b[33mvalues\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     10\u001b[39m     )\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m event \u001b[38;5;129;01min\u001b[39;00m events:\n\u001b[32m     13\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m event.items():\n\u001b[32m     14\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:1899\u001b[39m, in \u001b[36mPregel.astream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[39m\n\u001b[32m   1893\u001b[39m \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[32m   1894\u001b[39m \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates\u001b[39;00m\n\u001b[32m   1895\u001b[39m \u001b[38;5;66;03m# channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[32m   1896\u001b[39m \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[32m   1897\u001b[39m \u001b[38;5;66;03m# with channel updates applied only at the transition between steps\u001b[39;00m\n\u001b[32m   1898\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m loop.tick(input_keys=\u001b[38;5;28mself\u001b[39m.input_channels):\n\u001b[32m-> \u001b[39m\u001b[32m1899\u001b[39m     \u001b[38;5;28;01masync\u001b[39;00m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner.atick(\n\u001b[32m   1900\u001b[39m         loop.tasks.values(),\n\u001b[32m   1901\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.step_timeout,\n\u001b[32m   1902\u001b[39m         retry_policy=\u001b[38;5;28mself\u001b[39m.retry_policy,\n\u001b[32m   1903\u001b[39m         get_waiter=get_waiter,\n\u001b[32m   1904\u001b[39m     ):\n\u001b[32m   1905\u001b[39m         \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[32m   1906\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m o \u001b[38;5;129;01min\u001b[39;00m output():\n\u001b[32m   1907\u001b[39m             \u001b[38;5;28;01myield\u001b[39;00m o\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:454\u001b[39m, in \u001b[36mPregelRunner.atick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[39m\n\u001b[32m    452\u001b[39m     fut.cancel()\n\u001b[32m    453\u001b[39m \u001b[38;5;66;03m# panic on failure or timeout\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m454\u001b[39m \u001b[43m_panic_or_proceed\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    455\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdone_futures\u001b[49m\u001b[43m.\u001b[49m\u001b[43munion\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m.\u001b[49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout_exc_cls\u001b[49m\u001b[43m=\u001b[49m\u001b[43masyncio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mTimeoutError\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpanic\u001b[49m\u001b[43m=\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:549\u001b[39m, in \u001b[36m_panic_or_proceed\u001b[39m\u001b[34m(futs, timeout_exc_cls, panic)\u001b[39m\n\u001b[32m    547\u001b[39m         \u001b[38;5;66;03m# raise the exception\u001b[39;00m\n\u001b[32m    548\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m panic:\n\u001b[32m--> \u001b[39m\u001b[32m549\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m    550\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m inflight:\n\u001b[32m    551\u001b[39m     \u001b[38;5;66;03m# if we got here means we timed out\u001b[39;00m\n\u001b[32m    552\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m inflight:\n\u001b[32m    553\u001b[39m         \u001b[38;5;66;03m# cancel all pending tasks\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:128\u001b[39m, in \u001b[36marun_with_retry\u001b[39m\u001b[34m(task, retry_policy, stream, configurable)\u001b[39m\n\u001b[32m    126\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    127\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m128\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m task.proc.ainvoke(task.input, config)\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    130\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:485\u001b[39m, in \u001b[36mRunnableSeq.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    481\u001b[39m config = patch_config(\n\u001b[32m    482\u001b[39m     config, callbacks=run_manager.get_child(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m    483\u001b[39m )\n\u001b[32m    484\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m485\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m    486\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    487\u001b[39m     \u001b[38;5;28minput\u001b[39m = \u001b[38;5;28;01mawait\u001b[39;00m step.ainvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:275\u001b[39m, in \u001b[36mRunnableCallable.ainvoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    273\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ASYNCIO_ACCEPTS_CONTEXT:\n\u001b[32m    274\u001b[39m     coro = cast(Coroutine[\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, Any], \u001b[38;5;28mself\u001b[39m.afunc(\u001b[38;5;28minput\u001b[39m, **kwargs))\n\u001b[32m--> \u001b[39m\u001b[32m275\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m asyncio.create_task(coro, context=context)\n\u001b[32m    276\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    277\u001b[39m     ret = \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m.afunc(\u001b[38;5;28minput\u001b[39m, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:616\u001b[39m, in \u001b[36mrun_in_executor\u001b[39m\u001b[34m(executor_or_config, func, *args, **kwargs)\u001b[39m\n\u001b[32m    612\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m    614\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m executor_or_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(executor_or_config, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    615\u001b[39m     \u001b[38;5;66;03m# Use default executor with context copied from current context\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m616\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.get_running_loop().run_in_executor(\n\u001b[32m    617\u001b[39m         \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    618\u001b[39m         cast(\u001b[33m\"\u001b[39m\u001b[33mCallable[..., T]\u001b[39m\u001b[33m\"\u001b[39m, partial(copy_context().run, wrapper)),\n\u001b[32m    619\u001b[39m     )\n\u001b[32m    621\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mawait\u001b[39;00m asyncio.get_running_loop().run_in_executor(executor_or_config, wrapper)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     55\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     60\u001b[39m     \u001b[38;5;28mself\u001b[39m.future.set_exception(exc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langchain_core\\runnables\\config.py:607\u001b[39m, in \u001b[36mrun_in_executor.<locals>.wrapper\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m() -> T:\n\u001b[32m    606\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m607\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    608\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    609\u001b[39m         \u001b[38;5;66;03m# StopIteration can't be set on an asyncio.Future\u001b[39;00m\n\u001b[32m    610\u001b[39m         \u001b[38;5;66;03m# it raises a TypeError and leaves the Future pending forever\u001b[39;00m\n\u001b[32m    611\u001b[39m         \u001b[38;5;66;03m# so we need to convert it to a RuntimeError\u001b[39;00m\n\u001b[32m    612\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[41]\u001b[39m\u001b[32m, line 17\u001b[39m, in \u001b[36mwrite_final_sections\u001b[39m\u001b[34m(state)\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;66;03m# Generate section\u001b[39;00m\n\u001b[32m     16\u001b[39m user_instruction = \u001b[33m\"\u001b[39m\u001b[33mCraft a report section based on the provided sources.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m section_content = \u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mSystemMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43msystem_instructions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m                              \u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_instruction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[38;5;66;03m# Write content to section\u001b[39;00m\n\u001b[32m     21\u001b[39m section.content = section_content.content\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1175\u001b[39m, in \u001b[36mChatGoogleGenerativeAI.invoke\u001b[39m\u001b[34m(self, input, config, code_execution, stop, **kwargs)\u001b[39m\n\u001b[32m   1170\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1171\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1172\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mTools are already defined.\u001b[39m\u001b[33m\"\u001b[39m \u001b[33m\"\u001b[39m\u001b[33mcode_execution tool can\u001b[39m\u001b[33m'\u001b[39m\u001b[33mt be defined\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1173\u001b[39m         )\n\u001b[32m-> \u001b[39m\u001b[32m1175\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:368\u001b[39m, in \u001b[36mBaseChatModel.invoke\u001b[39m\u001b[34m(self, input, config, stop, **kwargs)\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    357\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    358\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    363\u001b[39m     **kwargs: Any,\n\u001b[32m    364\u001b[39m ) -> BaseMessage:\n\u001b[32m    365\u001b[39m     config = ensure_config(config)\n\u001b[32m    366\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[32m    367\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mChatGeneration\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m--> \u001b[39m\u001b[32m368\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    369\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    370\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    371\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcallbacks\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    372\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtags\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    373\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmetadata\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    374\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_name\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    375\u001b[39m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrun_id\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    376\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    377\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m.generations[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m],\n\u001b[32m    378\u001b[39m     ).message\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:937\u001b[39m, in \u001b[36mBaseChatModel.generate_prompt\u001b[39m\u001b[34m(self, prompts, stop, callbacks, **kwargs)\u001b[39m\n\u001b[32m    928\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    929\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_prompt\u001b[39m(\n\u001b[32m    930\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    934\u001b[39m     **kwargs: Any,\n\u001b[32m    935\u001b[39m ) -> LLMResult:\n\u001b[32m    936\u001b[39m     prompt_messages = [p.to_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[32m--> \u001b[39m\u001b[32m937\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:759\u001b[39m, in \u001b[36mBaseChatModel.generate\u001b[39m\u001b[34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[39m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[32m    757\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    758\u001b[39m         results.append(\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    760\u001b[39m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    761\u001b[39m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    762\u001b[39m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    763\u001b[39m \u001b[43m                \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    764\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    765\u001b[39m         )\n\u001b[32m    766\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    767\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langchain_core\\language_models\\chat_models.py:1002\u001b[39m, in \u001b[36mBaseChatModel._generate_with_cache\u001b[39m\u001b[34m(self, messages, stop, run_manager, **kwargs)\u001b[39m\n\u001b[32m   1000\u001b[39m     result = generate_from_stream(\u001b[38;5;28miter\u001b[39m(chunks))\n\u001b[32m   1001\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m inspect.signature(\u001b[38;5;28mself\u001b[39m._generate).parameters.get(\u001b[33m\"\u001b[39m\u001b[33mrun_manager\u001b[39m\u001b[33m\"\u001b[39m):\n\u001b[32m-> \u001b[39m\u001b[32m1002\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1003\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m   1004\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1005\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1006\u001b[39m     result = \u001b[38;5;28mself\u001b[39m._generate(messages, stop=stop, **kwargs)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:1242\u001b[39m, in \u001b[36mChatGoogleGenerativeAI._generate\u001b[39m\u001b[34m(self, messages, stop, run_manager, tools, functions, safety_settings, tool_config, generation_config, cached_content, tool_choice, **kwargs)\u001b[39m\n\u001b[32m   1216\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_generate\u001b[39m(\n\u001b[32m   1217\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1218\u001b[39m     messages: List[BaseMessage],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1229\u001b[39m     **kwargs: Any,\n\u001b[32m   1230\u001b[39m ) -> ChatResult:\n\u001b[32m   1231\u001b[39m     request = \u001b[38;5;28mself\u001b[39m._prepare_request(\n\u001b[32m   1232\u001b[39m         messages,\n\u001b[32m   1233\u001b[39m         stop=stop,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1240\u001b[39m         tool_choice=tool_choice,\n\u001b[32m   1241\u001b[39m     )\n\u001b[32m-> \u001b[39m\u001b[32m1242\u001b[39m     response: GenerateContentResponse = \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1243\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1244\u001b[39m \u001b[43m        \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1245\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgeneration_method\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1246\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdefault_metadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1247\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1248\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m _response_to_result(response)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:208\u001b[39m, in \u001b[36m_chat_with_retry\u001b[39m\u001b[34m(generation_method, **kwargs)\u001b[39m\n\u001b[32m    205\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    206\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[32m--> \u001b[39m\u001b[32m208\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_chat_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\tenacity\\__init__.py:338\u001b[39m, in \u001b[36mBaseRetrying.wraps.<locals>.wrapped_f\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    336\u001b[39m copy = \u001b[38;5;28mself\u001b[39m.copy()\n\u001b[32m    337\u001b[39m wrapped_f.statistics = copy.statistics  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\tenacity\\__init__.py:477\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    475\u001b[39m retry_state = RetryCallState(retry_object=\u001b[38;5;28mself\u001b[39m, fn=fn, args=args, kwargs=kwargs)\n\u001b[32m    476\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m477\u001b[39m     do = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43miter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    478\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\tenacity\\__init__.py:378\u001b[39m, in \u001b[36mBaseRetrying.iter\u001b[39m\u001b[34m(self, retry_state)\u001b[39m\n\u001b[32m    376\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    377\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.iter_state.actions:\n\u001b[32m--> \u001b[39m\u001b[32m378\u001b[39m     result = \u001b[43maction\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretry_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    379\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\tenacity\\__init__.py:420\u001b[39m, in \u001b[36mBaseRetrying._post_stop_check_actions.<locals>.exc_check\u001b[39m\u001b[34m(rs)\u001b[39m\n\u001b[32m    418\u001b[39m retry_exc = \u001b[38;5;28mself\u001b[39m.retry_error_cls(fut)\n\u001b[32m    419\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.reraise:\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mretry_exc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m retry_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mfut\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mexception\u001b[39;00m()\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\tenacity\\__init__.py:187\u001b[39m, in \u001b[36mRetryError.reraise\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    185\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mreraise\u001b[39m(\u001b[38;5;28mself\u001b[39m) -> t.NoReturn:\n\u001b[32m    186\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.last_attempt.failed:\n\u001b[32m--> \u001b[39m\u001b[32m187\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mlast_attempt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    188\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:449\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    447\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[32m    448\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m449\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    451\u001b[39m \u001b[38;5;28mself\u001b[39m._condition.wait(timeout)\n\u001b[32m    453\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\concurrent\\futures\\_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    399\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception:\n\u001b[32m    400\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m     \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m         \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n\u001b[32m    404\u001b[39m         \u001b[38;5;28mself\u001b[39m = \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\tenacity\\__init__.py:480\u001b[39m, in \u001b[36mRetrying.__call__\u001b[39m\u001b[34m(self, fn, *args, **kwargs)\u001b[39m\n\u001b[32m    478\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(do, DoAttempt):\n\u001b[32m    479\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m         result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m:  \u001b[38;5;66;03m# noqa: B902\u001b[39;00m\n\u001b[32m    482\u001b[39m         retry_state.set_exception(sys.exc_info())  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:206\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ChatGoogleGenerativeAIError(\n\u001b[32m    203\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid argument provided to Gemini: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    204\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m206\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m e\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\langchain_google_genai\\chat_models.py:190\u001b[39m, in \u001b[36m_chat_with_retry.<locals>._chat_with_retry\u001b[39m\u001b[34m(**kwargs)\u001b[39m\n\u001b[32m    187\u001b[39m \u001b[38;5;129m@retry_decorator\u001b[39m\n\u001b[32m    188\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_chat_with_retry\u001b[39m(**kwargs: Any) -> Any:\n\u001b[32m    189\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m190\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgeneration_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    191\u001b[39m     \u001b[38;5;66;03m# Do not retry for these errors.\u001b[39;00m\n\u001b[32m    192\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m google.api_core.exceptions.FailedPrecondition \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\google\\ai\\generativelanguage_v1beta\\services\\generative_service\\client.py:867\u001b[39m, in \u001b[36mGenerativeServiceClient.generate_content\u001b[39m\u001b[34m(self, request, model, contents, retry, timeout, metadata)\u001b[39m\n\u001b[32m    864\u001b[39m \u001b[38;5;28mself\u001b[39m._validate_universe_domain()\n\u001b[32m    866\u001b[39m \u001b[38;5;66;03m# Send the request.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m867\u001b[39m response = \u001b[43mrpc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    868\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    869\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    870\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    871\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    872\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[38;5;66;03m# Done; return the response.\u001b[39;00m\n\u001b[32m    875\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m response\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\google\\api_core\\gapic_v1\\method.py:131\u001b[39m, in \u001b[36m_GapicCallable.__call__\u001b[39m\u001b[34m(self, timeout, retry, compression, *args, **kwargs)\u001b[39m\n\u001b[32m    128\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compression \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    129\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mcompression\u001b[39m\u001b[33m\"\u001b[39m] = compression\n\u001b[32m--> \u001b[39m\u001b[32m131\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapped_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:293\u001b[39m, in \u001b[36mRetry.__call__.<locals>.retry_wrapped_func\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    289\u001b[39m target = functools.partial(func, *args, **kwargs)\n\u001b[32m    290\u001b[39m sleep_generator = exponential_sleep_generator(\n\u001b[32m    291\u001b[39m     \u001b[38;5;28mself\u001b[39m._initial, \u001b[38;5;28mself\u001b[39m._maximum, multiplier=\u001b[38;5;28mself\u001b[39m._multiplier\n\u001b[32m    292\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m293\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mretry_target\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    294\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    295\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_predicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    296\u001b[39m \u001b[43m    \u001b[49m\u001b[43msleep_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    297\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m    \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:153\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;66;03m# pylint: disable=broad-except\u001b[39;00m\n\u001b[32m    150\u001b[39m \u001b[38;5;66;03m# This function explicitly must deal with broad exceptions.\u001b[39;00m\n\u001b[32m    151\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    152\u001b[39m     \u001b[38;5;66;03m# defer to shared logic for handling errors\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m     \u001b[43m_retry_error_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    155\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdeadline\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    156\u001b[39m \u001b[43m        \u001b[49m\u001b[43msleep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    157\u001b[39m \u001b[43m        \u001b[49m\u001b[43merror_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    158\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpredicate\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mon_error\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexception_factory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# if exception not raised, sleep before next attempt\u001b[39;00m\n\u001b[32m    164\u001b[39m     time.sleep(sleep)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\google\\api_core\\retry\\retry_base.py:212\u001b[39m, in \u001b[36m_retry_error_helper\u001b[39m\u001b[34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[39m\n\u001b[32m    206\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m predicate_fn(exc):\n\u001b[32m    207\u001b[39m     final_exc, source_exc = exc_factory_fn(\n\u001b[32m    208\u001b[39m         error_list,\n\u001b[32m    209\u001b[39m         RetryFailureReason.NON_RETRYABLE_ERROR,\n\u001b[32m    210\u001b[39m         original_timeout,\n\u001b[32m    211\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m final_exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msource_exc\u001b[39;00m\n\u001b[32m    213\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m on_error_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    214\u001b[39m     on_error_fn(exc)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\google\\api_core\\retry\\retry_unary.py:144\u001b[39m, in \u001b[36mretry_target\u001b[39m\u001b[34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[39m\n\u001b[32m    142\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m sleep \u001b[38;5;129;01min\u001b[39;00m sleep_generator:\n\u001b[32m    143\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m144\u001b[39m         result = \u001b[43mtarget\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    145\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m inspect.isawaitable(result):\n\u001b[32m    146\u001b[39m             warnings.warn(_ASYNC_RETRY_WARNING)\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\google\\api_core\\timeout.py:130\u001b[39m, in \u001b[36mTimeToDeadlineTimeout.__call__.<locals>.func_with_timeout\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    126\u001b[39m         remaining_timeout = \u001b[38;5;28mself\u001b[39m._timeout\n\u001b[32m    128\u001b[39m     kwargs[\u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m] = remaining_timeout\n\u001b[32m--> \u001b[39m\u001b[32m130\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Shadab\\Downloads\\Kairon- Deep Research AI Agent\\deepvenv\\Lib\\site-packages\\google\\api_core\\grpc_helpers.py:78\u001b[39m, in \u001b[36m_wrap_unary_errors.<locals>.error_remapped_callable\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m callable_(*args, **kwargs)\n\u001b[32m     77\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m grpc.RpcError \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exceptions.from_grpc_error(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
            "\u001b[31mResourceExhausted\u001b[39m: 429 You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. [violations {\n  quota_metric: \"generativelanguage.googleapis.com/generate_content_free_tier_requests\"\n  quota_id: \"GenerateRequestsPerMinutePerProjectPerModel-FreeTier\"\n  quota_dimensions {\n    key: \"model\"\n    value: \"gemini-2.0-flash\"\n  }\n  quota_dimensions {\n    key: \"location\"\n    value: \"global\"\n  }\n  quota_value: 15\n}\n, links {\n  description: \"Learn more about Gemini API quotas\"\n  url: \"https://ai.google.dev/gemini-api/docs/rate-limits\"\n}\n, retry_delay {\n  seconds: 45\n}\n]",
            "During task with name 'write_final_sections' and id 'a6f83b34-c392-d9be-0a46-376a22bc7ee7'"
          ]
        }
      ],
      "source": [
        "topic = \"Detailed report on how to build Agentic AI systems, design patterns and current frameworks\"\n",
        "await call_planner_agent(agent=reporter_agent,\n",
        "                         prompt=topic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "SvT_7UGgGiQA",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "SvT_7UGgGiQA",
        "outputId": "47702d82-f92a-4991-faec-486b25f07f9a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Generating Report Plan ---\n",
            "--- Generating Report Plan Completed ---\n",
            "--- Generating Search Queries for Section: NVIDIA's Market Dominance in GPUs ------ Generating Search Queries for Section: Strategic Acquisitions and Partnerships ---\n",
            "--- Generating Search Queries for Section: Technological Innovations and AI Leadership ---\n",
            "\n",
            "--- Generating Search Queries for Section: Financial Performance and Growth Strategy ---\n",
            "--- Generating Search Queries for Section: NVIDIA's Market Dominance in GPUs Completed ---\n",
            "--- Searching Web for Queries ---\n",
            "--- Generating Search Queries for Section: Financial Performance and Growth Strategy Completed ---\n",
            "--- Searching Web for Queries ---\n",
            "--- Generating Search Queries for Section: Technological Innovations and AI Leadership Completed ---\n",
            "--- Searching Web for Queries ---\n",
            "--- Generating Search Queries for Section: Strategic Acquisitions and Partnerships Completed ---\n",
            "--- Searching Web for Queries ---\n",
            "--- Searching Web for Queries Completed ---\n",
            "--- Writing Section : Strategic Acquisitions and Partnerships ---\n",
            "--- Searching Web for Queries Completed ---\n",
            "--- Writing Section : Financial Performance and Growth Strategy ---\n",
            "--- Searching Web for Queries Completed ---\n",
            "--- Writing Section : NVIDIA's Market Dominance in GPUs ---\n",
            "--- Searching Web for Queries Completed ---\n",
            "--- Writing Section : Technological Innovations and AI Leadership ---\n",
            "--- Writing Section : Strategic Acquisitions and Partnerships Completed ---\n",
            "--- Writing Section : Financial Performance and Growth Strategy Completed ---\n",
            "--- Writing Section : NVIDIA's Market Dominance in GPUs Completed ---\n",
            "--- Writing Section : Technological Innovations and AI Leadership Completed ---\n",
            "--- Formatting Completed Sections ---\n",
            "--- Formatting Completed Sections is Done ---\n",
            "--- Writing Final Section: Introduction ------ Writing Final Section: Conclusion ---\n",
            "\n",
            "--- Writing Final Section: Introduction Completed ---\n",
            "--- Writing Final Section: Conclusion Completed ---\n",
            "--- Compiling Final Report ---\n",
            "--- Compiling Final Report Done ---\n",
            "==================================================\n",
            "Final Report:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ                                                  <span style=\"font-weight: bold\">Introduction</span>                                                   ‚îÉ\n",
              "‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ\n",
              "\n",
              "NVIDIA stands as a formidable leader in the technology market, particularly in the GPU and AI sectors. With an     \n",
              "impressive 90% market share in the discrete GPU market, NVIDIA has outpaced competitors like AMD and Intel through \n",
              "technological innovation and strategic positioning. The company's strategic acquisitions, such as Mellanox         \n",
              "Technologies and Arm Limited, have bolstered its capabilities in AI and data centers, further solidifying its      \n",
              "dominance. NVIDIA's advancements in AI and accelerated computing, coupled with robust financial performance,       \n",
              "underscore its pivotal role in shaping the future of technology. This report will delve into how NVIDIA continues  \n",
              "to outperform its competitors, setting new standards in the industry.                                              \n",
              "\n",
              "\n",
              "                                         <span style=\"font-weight: bold; text-decoration: underline\">NVIDIA's Market Dominance in GPUs</span>                                         \n",
              "\n",
              "<span style=\"font-weight: bold\">NVIDIA commands an unprecedented 90% of the global GPU market share as of Q3 2024, leaving competitors AMD and </span>    \n",
              "<span style=\"font-weight: bold\">Intel far behind.</span> This dominance is attributed to NVIDIA's strategic advancements and the anticipated release of   \n",
              "the RTX 50 series. According to Jon Peddie Research, NVIDIA's market share surged from 84% in early 2024 to 90% by \n",
              "Q3, while AMD's share dwindled to 10%, and Intel's presence nearly vanished.                                       \n",
              "\n",
              "Several factors contribute to NVIDIA's market leadership:                                                          \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Technological Innovation</span>: The RTX 50 series, featuring advanced AI capabilities and enhanced ray tracing, has   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>generated significant consumer interest.                                                                        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Strategic Positioning</span>: NVIDIA's focus on AI and data center solutions has expanded its market reach, with AI GPU\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>market shares estimated between 70% and 95%.                                                                    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Manufacturing Prowess</span>: NVIDIA's robust manufacturing capabilities have outpaced competitors, allowing for rapid \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>deployment of new technologies.                                                                                 \n",
              "\n",
              "Despite a 7.9% decline in overall GPU shipments year-over-year, NVIDIA's strategic initiatives have solidified its \n",
              "position as the leading force in the GPU sector, raising questions about innovation and pricing in a               \n",
              "near-monopolistic market.                                                                                          \n",
              "\n",
              "                                                      <span style=\"font-weight: bold\">Sources</span>                                                      \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>NVIDIA Crushes Rivals: Secures Unprecedented 90% of GPU Market in Q3 2024:                                      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://finance.yahoo.com/news/nvidia-crushes-rivals-secures-unprecedented-102235255.html                       \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>Nvidia's desktop GPU dominance grows to 88% as market returns to normal:                                        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://www.techspot.com/news/103293-nvidia-desktop-gpu-market-dominance-grows-88-sector.html                   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>Nvidia AI GPU Market Share 2024: Unrivaled Dominance and Market Trends:                                         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://deepai.tn/papers/nvidia-ai-gpu-market-share-2024/                                                       \n",
              "\n",
              "\n",
              "                                      <span style=\"font-weight: bold; text-decoration: underline\">Strategic Acquisitions and Partnerships</span>                                      \n",
              "\n",
              "<span style=\"font-weight: bold\">NVIDIA's acquisition of Mellanox Technologies and Arm Limited has significantly enhanced its AI and data center </span>   \n",
              "<span style=\"font-weight: bold\">capabilities.</span> The $7 billion acquisition of Mellanox in 2019 allowed NVIDIA to integrate high-performance          \n",
              "networking solutions, transforming it into a comprehensive data center service provider. This acquisition enabled  \n",
              "NVIDIA to offer end-to-end technologies from AI computing to networking, crucial for next-generation data centers  \n",
              "[1][2].                                                                                                            \n",
              "\n",
              "In a $40 billion deal, NVIDIA's acquisition of Arm Limited aimed to merge its AI computing platform with Arm's     \n",
              "ecosystem, enhancing energy-efficient AI hardware solutions. This strategic move is expected to redefine computing \n",
              "in the AI era, particularly in edge computing and IoT applications [3][4].                                         \n",
              "\n",
              "NVIDIA's partnership with AWS further accelerates AI innovation. The collaboration includes the integration of     \n",
              "NVIDIA's Blackwell GPU platform into AWS infrastructure, enabling faster and more secure deployment of AI models.  \n",
              "This partnership supports the development of multi-trillion parameter large language models, crucial for advancing \n",
              "generative AI capabilities [5][6].                                                                                 \n",
              "\n",
              "                                                      <span style=\"font-weight: bold\">Sources</span>                                                      \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>Nvidia finalizes Mellanox deal to boost AI products, 2020:                                                      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://www.techtarget.com/searchenterpriseai/news/252482488/Nvidia-finalizes-Mellanox-deal-to-boost-AI-products\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>With an Eye on Intelligent Next-Gen Data Centers, NVIDIA Acquires Mellanox, 2020:                               \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://www.allaboutcircuits.com/news/with-an-eye-on-intelligent-next-gen-data-centers-nvidia-acquires-mellanox-\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>for-7billion/                                                                                                   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>Mapping Nvidia's Expansion with 17 Strategic Acquisitions, 2024:                                                \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://cioinfluence.com/it-and-devops/mapping-nvidias-expansion-with-17-strategic-acquisitions/                \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>Nvidia's Acquisition of Arm: A Game-Changer for the AI Ecosystem, 2024:                                         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://medium.com/vanguard-industry-foresight/nvidias-acquisition-of-arm-a-game-changer-for-the-ai-ecosystem-35\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>1f49e7e0ce                                                                                                      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>AWS and NVIDIA Extend Collaboration to Advance Generative AI, 2024:                                             \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://press.aboutamazon.com/2024/3/aws-and-nvidia-extend-collaboration-to-advance-generative-ai-innovation    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>AWS and NVIDIA Form Game-Changing Strategic Alliance for Advanced Computing Solutions, 2024:                    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://www.aimlmag.com/aws-and-nvidia-form-game-changing-strategic-alliance-for-advanced-computing-solutions/  \n",
              "\n",
              "\n",
              "                                    <span style=\"font-weight: bold; text-decoration: underline\">Technological Innovations and AI Leadership</span>                                    \n",
              "\n",
              "<span style=\"font-weight: bold\">NVIDIA's advancements in AI and accelerated computing are reshaping the future of technology.</span> The introduction of  \n",
              "the Blackwell GPU platform, with its 208 billion transistors and 8 TB/s memory bandwidth, exemplifies NVIDIA's     \n",
              "commitment to high-performance AI computing. This platform supports AI models with up to 10 trillion parameters,   \n",
              "significantly enhancing training and inference capabilities. NVIDIA's edge computing solutions, such as the Jetson \n",
              "and EGX platforms, enable real-time AI processing at the data source, reducing latency and improving security.     \n",
              "\n",
              "NVIDIA's role in AI extends beyond hardware. The CUDA-X libraries, including the new cuPyNumeric, accelerate       \n",
              "scientific research by enabling GPU-accelerated data science and machine learning applications. At SC24, NVIDIA    \n",
              "showcased its Omniverse Blueprint for real-time digital twins, which accelerates simulations by up to 1,200x,      \n",
              "setting a new standard for interactivity.                                                                          \n",
              "\n",
              "A notable case study is NVIDIA's collaboration with Foxconn to scale production of AI systems like the Blackwell   \n",
              "supercomputer, highlighting the company's strategic partnerships to meet growing demand. These innovations         \n",
              "demonstrate NVIDIA's leadership in AI and computing, driving advancements across industries.                       \n",
              "\n",
              "                                                      <span style=\"font-weight: bold\">Sources</span>                                                      \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>NVIDIA Unveils AI &amp; Supercomputing Advances at SC 2024:                                                         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://www.techrepublic.com/article/nvidia-ai-supercomputing-2024/                                             \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>AI Will Drive Scientific Breakthroughs, NVIDIA CEO Says at SC24:                                                \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://blogs.nvidia.com/blog/supercomputing-24/                                                                \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>Nvidia's SC24 special address hints at a new era in computing and AI:                                           \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://siliconangle.com/2024/11/20/nvidias-sc24-special-address-hints-new-era-computing-ai/                    \n",
              "\n",
              "\n",
              "                                     <span style=\"font-weight: bold; text-decoration: underline\">Financial Performance and Growth Strategy</span>                                     \n",
              "\n",
              "<span style=\"font-weight: bold\">NVIDIA's financial performance in 2024 has been extraordinary, driven by AI demand and strategic innovation.</span> The   \n",
              "company reported a record revenue of $26 billion in Q1 2024, an 18% increase quarter-over-quarter and a 262%       \n",
              "year-over-year growth, primarily fueled by its data center segment, which contributed $22.6 billion. This segment's\n",
              "success is attributed to the widespread adoption of NVIDIA's technology in AI and high-performance computing       \n",
              "applications, with major customers like OpenAI and Meta. NVIDIA's market capitalization soared to over $3.28       \n",
              "trillion, making it the second-most valuable company globally.                                                     \n",
              "\n",
              "NVIDIA's growth strategy focuses on continuous innovation and substantial R&amp;D investments, which increased from    \n",
              "$2.38 billion in 2019 to $8.68 billion in 2024. This strategy includes the development of AI-specific hardware and \n",
              "expansion into data centers, positioning NVIDIA as a leader in the AI revolution. The company also announced a     \n",
              "10-for-1 stock split to make stock ownership more accessible. Despite challenges like supply chain constraints and \n",
              "emerging competition, NVIDIA's robust financial health and strategic initiatives suggest a positive outlook for    \n",
              "sustained growth.                                                                                                  \n",
              "\n",
              "                                                      <span style=\"font-weight: bold\">Sources</span>                                                      \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>NVIDIA Q1 2024 Earnings: AI Demand Fuels Growth Leading to Stock Split:                                         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://finance.yahoo.com/news/nvidia-q1-2024-earnings-ai-172819216.html                                        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>NVIDIA's AI Dominance in 2024: $28 Billion Revenue and What's Next?:                                            \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://medium.com/quarterscope/nvidias-ai-dominance-in-2024-28-billion-revenue-and-what-s-next-4e117875e141    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>Decoding NVIDIA Corp (NVDA): A Strategic SWOT Insight:                                                          \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://finance.yahoo.com/news/decoding-nvidia-corp-nvda-strategic-050218657.html                               \n",
              "\n",
              "\n",
              "                                                    <span style=\"font-weight: bold; text-decoration: underline\">Conclusion</span>                                                     \n",
              "\n",
              "NVIDIA's success is driven by its strategic focus on technological innovation, strategic acquisitions, and robust  \n",
              "financial performance. The company's dominance in the GPU market, with a 90% share, is bolstered by the advanced   \n",
              "RTX 50 series and a strong presence in AI and data centers. Strategic acquisitions like Mellanox and Arm have      \n",
              "expanded NVIDIA's capabilities, while partnerships with AWS enhance its AI offerings. Technological innovations,   \n",
              "such as the Blackwell GPU platform, position NVIDIA as a leader in AI and accelerated computing. Financially,      \n",
              "NVIDIA's record revenue and market capitalization underscore its growth strategy, emphasizing R&amp;D and market       \n",
              "expansion. These elements collectively ensure NVIDIA's competitive edge and sustained growth.                      \n",
              "\n",
              "                                                                                           \n",
              " <span style=\"font-weight: bold\"> Competitive Advantage     </span> <span style=\"font-weight: bold\"> Description                                                 </span> \n",
              " ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ \n",
              "  Market Dominance            90% GPU market share, leading AI and data center solutions   \n",
              "  Strategic Acquisitions      Enhanced capabilities through Mellanox and Arm acquisitions  \n",
              "  Technological Innovations   Advanced AI processors and edge computing solutions          \n",
              "  Financial Performance       Record revenue growth and strong market capitalization       \n",
              "                                                                                           \n",
              "\n",
              "NVIDIA's strategic initiatives suggest a promising future, with continued innovation and market leadership.        \n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ                                                  \u001b[1mIntroduction\u001b[0m                                                   ‚îÉ\n",
              "‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ\n",
              "\n",
              "NVIDIA stands as a formidable leader in the technology market, particularly in the GPU and AI sectors. With an     \n",
              "impressive 90% market share in the discrete GPU market, NVIDIA has outpaced competitors like AMD and Intel through \n",
              "technological innovation and strategic positioning. The company's strategic acquisitions, such as Mellanox         \n",
              "Technologies and Arm Limited, have bolstered its capabilities in AI and data centers, further solidifying its      \n",
              "dominance. NVIDIA's advancements in AI and accelerated computing, coupled with robust financial performance,       \n",
              "underscore its pivotal role in shaping the future of technology. This report will delve into how NVIDIA continues  \n",
              "to outperform its competitors, setting new standards in the industry.                                              \n",
              "\n",
              "\n",
              "                                         \u001b[1;4mNVIDIA's Market Dominance in GPUs\u001b[0m                                         \n",
              "\n",
              "\u001b[1mNVIDIA commands an unprecedented 90% of the global GPU market share as of Q3 2024, leaving competitors AMD and \u001b[0m    \n",
              "\u001b[1mIntel far behind.\u001b[0m This dominance is attributed to NVIDIA's strategic advancements and the anticipated release of   \n",
              "the RTX 50 series. According to Jon Peddie Research, NVIDIA's market share surged from 84% in early 2024 to 90% by \n",
              "Q3, while AMD's share dwindled to 10%, and Intel's presence nearly vanished.                                       \n",
              "\n",
              "Several factors contribute to NVIDIA's market leadership:                                                          \n",
              "\n",
              "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mTechnological Innovation\u001b[0m: The RTX 50 series, featuring advanced AI capabilities and enhanced ray tracing, has   \n",
              "\u001b[1;33m   \u001b[0mgenerated significant consumer interest.                                                                        \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mStrategic Positioning\u001b[0m: NVIDIA's focus on AI and data center solutions has expanded its market reach, with AI GPU\n",
              "\u001b[1;33m   \u001b[0mmarket shares estimated between 70% and 95%.                                                                    \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mManufacturing Prowess\u001b[0m: NVIDIA's robust manufacturing capabilities have outpaced competitors, allowing for rapid \n",
              "\u001b[1;33m   \u001b[0mdeployment of new technologies.                                                                                 \n",
              "\n",
              "Despite a 7.9% decline in overall GPU shipments year-over-year, NVIDIA's strategic initiatives have solidified its \n",
              "position as the leading force in the GPU sector, raising questions about innovation and pricing in a               \n",
              "near-monopolistic market.                                                                                          \n",
              "\n",
              "                                                      \u001b[1mSources\u001b[0m                                                      \n",
              "\n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mNVIDIA Crushes Rivals: Secures Unprecedented 90% of GPU Market in Q3 2024:                                      \n",
              "\u001b[1;33m   \u001b[0mhttps://finance.yahoo.com/news/nvidia-crushes-rivals-secures-unprecedented-102235255.html                       \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mNvidia's desktop GPU dominance grows to 88% as market returns to normal:                                        \n",
              "\u001b[1;33m   \u001b[0mhttps://www.techspot.com/news/103293-nvidia-desktop-gpu-market-dominance-grows-88-sector.html                   \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mNvidia AI GPU Market Share 2024: Unrivaled Dominance and Market Trends:                                         \n",
              "\u001b[1;33m   \u001b[0mhttps://deepai.tn/papers/nvidia-ai-gpu-market-share-2024/                                                       \n",
              "\n",
              "\n",
              "                                      \u001b[1;4mStrategic Acquisitions and Partnerships\u001b[0m                                      \n",
              "\n",
              "\u001b[1mNVIDIA's acquisition of Mellanox Technologies and Arm Limited has significantly enhanced its AI and data center \u001b[0m   \n",
              "\u001b[1mcapabilities.\u001b[0m The $7 billion acquisition of Mellanox in 2019 allowed NVIDIA to integrate high-performance          \n",
              "networking solutions, transforming it into a comprehensive data center service provider. This acquisition enabled  \n",
              "NVIDIA to offer end-to-end technologies from AI computing to networking, crucial for next-generation data centers  \n",
              "[1][2].                                                                                                            \n",
              "\n",
              "In a $40 billion deal, NVIDIA's acquisition of Arm Limited aimed to merge its AI computing platform with Arm's     \n",
              "ecosystem, enhancing energy-efficient AI hardware solutions. This strategic move is expected to redefine computing \n",
              "in the AI era, particularly in edge computing and IoT applications [3][4].                                         \n",
              "\n",
              "NVIDIA's partnership with AWS further accelerates AI innovation. The collaboration includes the integration of     \n",
              "NVIDIA's Blackwell GPU platform into AWS infrastructure, enabling faster and more secure deployment of AI models.  \n",
              "This partnership supports the development of multi-trillion parameter large language models, crucial for advancing \n",
              "generative AI capabilities [5][6].                                                                                 \n",
              "\n",
              "                                                      \u001b[1mSources\u001b[0m                                                      \n",
              "\n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mNvidia finalizes Mellanox deal to boost AI products, 2020:                                                      \n",
              "\u001b[1;33m   \u001b[0mhttps://www.techtarget.com/searchenterpriseai/news/252482488/Nvidia-finalizes-Mellanox-deal-to-boost-AI-products\n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mWith an Eye on Intelligent Next-Gen Data Centers, NVIDIA Acquires Mellanox, 2020:                               \n",
              "\u001b[1;33m   \u001b[0mhttps://www.allaboutcircuits.com/news/with-an-eye-on-intelligent-next-gen-data-centers-nvidia-acquires-mellanox-\n",
              "\u001b[1;33m   \u001b[0mfor-7billion/                                                                                                   \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mMapping Nvidia's Expansion with 17 Strategic Acquisitions, 2024:                                                \n",
              "\u001b[1;33m   \u001b[0mhttps://cioinfluence.com/it-and-devops/mapping-nvidias-expansion-with-17-strategic-acquisitions/                \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mNvidia's Acquisition of Arm: A Game-Changer for the AI Ecosystem, 2024:                                         \n",
              "\u001b[1;33m   \u001b[0mhttps://medium.com/vanguard-industry-foresight/nvidias-acquisition-of-arm-a-game-changer-for-the-ai-ecosystem-35\n",
              "\u001b[1;33m   \u001b[0m1f49e7e0ce                                                                                                      \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mAWS and NVIDIA Extend Collaboration to Advance Generative AI, 2024:                                             \n",
              "\u001b[1;33m   \u001b[0mhttps://press.aboutamazon.com/2024/3/aws-and-nvidia-extend-collaboration-to-advance-generative-ai-innovation    \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mAWS and NVIDIA Form Game-Changing Strategic Alliance for Advanced Computing Solutions, 2024:                    \n",
              "\u001b[1;33m   \u001b[0mhttps://www.aimlmag.com/aws-and-nvidia-form-game-changing-strategic-alliance-for-advanced-computing-solutions/  \n",
              "\n",
              "\n",
              "                                    \u001b[1;4mTechnological Innovations and AI Leadership\u001b[0m                                    \n",
              "\n",
              "\u001b[1mNVIDIA's advancements in AI and accelerated computing are reshaping the future of technology.\u001b[0m The introduction of  \n",
              "the Blackwell GPU platform, with its 208 billion transistors and 8 TB/s memory bandwidth, exemplifies NVIDIA's     \n",
              "commitment to high-performance AI computing. This platform supports AI models with up to 10 trillion parameters,   \n",
              "significantly enhancing training and inference capabilities. NVIDIA's edge computing solutions, such as the Jetson \n",
              "and EGX platforms, enable real-time AI processing at the data source, reducing latency and improving security.     \n",
              "\n",
              "NVIDIA's role in AI extends beyond hardware. The CUDA-X libraries, including the new cuPyNumeric, accelerate       \n",
              "scientific research by enabling GPU-accelerated data science and machine learning applications. At SC24, NVIDIA    \n",
              "showcased its Omniverse Blueprint for real-time digital twins, which accelerates simulations by up to 1,200x,      \n",
              "setting a new standard for interactivity.                                                                          \n",
              "\n",
              "A notable case study is NVIDIA's collaboration with Foxconn to scale production of AI systems like the Blackwell   \n",
              "supercomputer, highlighting the company's strategic partnerships to meet growing demand. These innovations         \n",
              "demonstrate NVIDIA's leadership in AI and computing, driving advancements across industries.                       \n",
              "\n",
              "                                                      \u001b[1mSources\u001b[0m                                                      \n",
              "\n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mNVIDIA Unveils AI & Supercomputing Advances at SC 2024:                                                         \n",
              "\u001b[1;33m   \u001b[0mhttps://www.techrepublic.com/article/nvidia-ai-supercomputing-2024/                                             \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mAI Will Drive Scientific Breakthroughs, NVIDIA CEO Says at SC24:                                                \n",
              "\u001b[1;33m   \u001b[0mhttps://blogs.nvidia.com/blog/supercomputing-24/                                                                \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mNvidia's SC24 special address hints at a new era in computing and AI:                                           \n",
              "\u001b[1;33m   \u001b[0mhttps://siliconangle.com/2024/11/20/nvidias-sc24-special-address-hints-new-era-computing-ai/                    \n",
              "\n",
              "\n",
              "                                     \u001b[1;4mFinancial Performance and Growth Strategy\u001b[0m                                     \n",
              "\n",
              "\u001b[1mNVIDIA's financial performance in 2024 has been extraordinary, driven by AI demand and strategic innovation.\u001b[0m The   \n",
              "company reported a record revenue of $26 billion in Q1 2024, an 18% increase quarter-over-quarter and a 262%       \n",
              "year-over-year growth, primarily fueled by its data center segment, which contributed $22.6 billion. This segment's\n",
              "success is attributed to the widespread adoption of NVIDIA's technology in AI and high-performance computing       \n",
              "applications, with major customers like OpenAI and Meta. NVIDIA's market capitalization soared to over $3.28       \n",
              "trillion, making it the second-most valuable company globally.                                                     \n",
              "\n",
              "NVIDIA's growth strategy focuses on continuous innovation and substantial R&D investments, which increased from    \n",
              "$2.38 billion in 2019 to $8.68 billion in 2024. This strategy includes the development of AI-specific hardware and \n",
              "expansion into data centers, positioning NVIDIA as a leader in the AI revolution. The company also announced a     \n",
              "10-for-1 stock split to make stock ownership more accessible. Despite challenges like supply chain constraints and \n",
              "emerging competition, NVIDIA's robust financial health and strategic initiatives suggest a positive outlook for    \n",
              "sustained growth.                                                                                                  \n",
              "\n",
              "                                                      \u001b[1mSources\u001b[0m                                                      \n",
              "\n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mNVIDIA Q1 2024 Earnings: AI Demand Fuels Growth Leading to Stock Split:                                         \n",
              "\u001b[1;33m   \u001b[0mhttps://finance.yahoo.com/news/nvidia-q1-2024-earnings-ai-172819216.html                                        \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mNVIDIA's AI Dominance in 2024: $28 Billion Revenue and What's Next?:                                            \n",
              "\u001b[1;33m   \u001b[0mhttps://medium.com/quarterscope/nvidias-ai-dominance-in-2024-28-billion-revenue-and-what-s-next-4e117875e141    \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mDecoding NVIDIA Corp (NVDA): A Strategic SWOT Insight:                                                          \n",
              "\u001b[1;33m   \u001b[0mhttps://finance.yahoo.com/news/decoding-nvidia-corp-nvda-strategic-050218657.html                               \n",
              "\n",
              "\n",
              "                                                    \u001b[1;4mConclusion\u001b[0m                                                     \n",
              "\n",
              "NVIDIA's success is driven by its strategic focus on technological innovation, strategic acquisitions, and robust  \n",
              "financial performance. The company's dominance in the GPU market, with a 90% share, is bolstered by the advanced   \n",
              "RTX 50 series and a strong presence in AI and data centers. Strategic acquisitions like Mellanox and Arm have      \n",
              "expanded NVIDIA's capabilities, while partnerships with AWS enhance its AI offerings. Technological innovations,   \n",
              "such as the Blackwell GPU platform, position NVIDIA as a leader in AI and accelerated computing. Financially,      \n",
              "NVIDIA's record revenue and market capitalization underscore its growth strategy, emphasizing R&D and market       \n",
              "expansion. These elements collectively ensure NVIDIA's competitive edge and sustained growth.                      \n",
              "\n",
              "                                                                                           \n",
              " \u001b[1m \u001b[0m\u001b[1mCompetitive Advantage\u001b[0m\u001b[1m    \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDescription\u001b[0m\u001b[1m                                                \u001b[0m\u001b[1m \u001b[0m \n",
              " ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ \n",
              "  Market Dominance            90% GPU market share, leading AI and data center solutions   \n",
              "  Strategic Acquisitions      Enhanced capabilities through Mellanox and Arm acquisitions  \n",
              "  Technological Innovations   Advanced AI processors and edge computing solutions          \n",
              "  Financial Performance       Record revenue growth and strong market capitalization       \n",
              "                                                                                           \n",
              "\n",
              "NVIDIA's strategic initiatives suggest a promising future, with continued innovation and market leadership.        \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "topic = \"Detailed report on how is NVIDIA winning the game against its competitors\"\n",
        "await call_planner_agent(agent=reporter_agent,\n",
        "                         prompt=topic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "W1ng0JUSKai8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "W1ng0JUSKai8",
        "outputId": "0e8d76c0-0f1e-48ba-e194-8670209be93a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--- Generating Report Plan ---\n",
            "--- Generating Report Plan Completed ---\n",
            "--- Generating Search Queries for Section: DeepSeek's Technological Innovations ---\n",
            "--- Generating Search Queries for Section: Market Disruption and Economic Impact ---\n",
            "--- Generating Search Queries for Section: Comparison with Established AI Models ---\n",
            "--- Generating Search Queries for Section: Challenges and Criticisms ---\n",
            "--- Generating Search Queries for Section: Comparison with Established AI Models Completed ---\n",
            "--- Searching Web for Queries ---\n",
            "--- Generating Search Queries for Section: Challenges and Criticisms Completed ---\n",
            "--- Searching Web for Queries ---\n",
            "--- Generating Search Queries for Section: Market Disruption and Economic Impact Completed ---\n",
            "--- Searching Web for Queries ---\n",
            "--- Generating Search Queries for Section: DeepSeek's Technological Innovations Completed ---\n",
            "--- Searching Web for Queries ---\n",
            "--- Searching Web for Queries Completed ---\n",
            "--- Writing Section : DeepSeek's Technological Innovations ---\n",
            "--- Searching Web for Queries Completed ---\n",
            "--- Writing Section : Comparison with Established AI Models ---\n",
            "--- Searching Web for Queries Completed ---\n",
            "--- Writing Section : Market Disruption and Economic Impact ---\n",
            "--- Searching Web for Queries Completed ---\n",
            "--- Writing Section : Challenges and Criticisms ---\n",
            "--- Writing Section : DeepSeek's Technological Innovations Completed ---\n",
            "--- Writing Section : Comparison with Established AI Models Completed ---\n",
            "--- Writing Section : Market Disruption and Economic Impact Completed ---\n",
            "--- Writing Section : Challenges and Criticisms Completed ---\n",
            "--- Formatting Completed Sections ---\n",
            "--- Formatting Completed Sections is Done ---\n",
            "--- Writing Final Section: Introduction ------ Writing Final Section: Conclusion ---\n",
            "\n",
            "--- Writing Final Section: Introduction Completed ---\n",
            "--- Writing Final Section: Conclusion Completed ---\n",
            "--- Compiling Final Report ---\n",
            "--- Compiling Final Report Done ---\n",
            "==================================================\n",
            "Final Report:\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ                                                  <span style=\"font-weight: bold\">Introduction</span>                                                   ‚îÉ\n",
              "‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ\n",
              "\n",
              "DeepSeek is a groundbreaking player in the AI market, known for its innovative technological advancements and      \n",
              "disruptive economic strategies. By leveraging open-source models and efficient AI development techniques, DeepSeek \n",
              "has redefined the landscape of AI model efficiency and accessibility. Its introduction of cost-effective models has\n",
              "sparked significant price wars, challenging established tech giants like Nvidia and OpenAI. This report delves into\n",
              "DeepSeek's technological innovations, market impact, and the challenges it faces, offering a comprehensive analysis\n",
              "of its role in reshaping the AI industry.                                                                          \n",
              "\n",
              "\n",
              "                                       <span style=\"font-weight: bold; text-decoration: underline\">DeepSeek's Technological Innovations</span>                                        \n",
              "\n",
              "<span style=\"font-weight: bold\">DeepSeek's innovative use of the Mixture-of-Experts (MoE) architecture and efficient AI development techniques has </span>\n",
              "<span style=\"font-weight: bold\">redefined AI model efficiency.</span> The DeepSeek-V3 model, launched in December 2024, exemplifies this with its 671     \n",
              "billion parameters, yet only 37 billion are activated per task, significantly reducing computational costs. This   \n",
              "model was trained using just 2,048 Nvidia H800 GPUs over two months, costing approximately $5.6 million, a fraction\n",
              "of the cost for similar models from major tech companies.                                                          \n",
              "\n",
              "DeepSeek's approach includes several key innovations:                                                              \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Multi-Head Latent Attention (MLA):</span> Enhances the model's ability to process complex inputs by focusing on        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>different data aspects simultaneously.                                                                          \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">FP8 Mixed Precision Training:</span> Reduces memory usage and accelerates training without sacrificing accuracy.       \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Auxiliary-Loss-Free Load Balancing:</span> Ensures efficient distribution of computational tasks across the model's    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>parameters.                                                                                                     \n",
              "\n",
              "These advancements allow DeepSeek to deliver high performance on benchmarks like MMLU-Pro and MATH 500, often      \n",
              "surpassing models like GPT-4o. DeepSeek's commitment to open-source models democratizes access to advanced AI,     \n",
              "challenging the dominance of established players and reshaping the AI landscape.                                   \n",
              "\n",
              "                                                      <span style=\"font-weight: bold\">Sources</span>                                                      \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>All About DeepSeek ‚Äî The Chinese AI Startup Challenging US Big Tech:                                            \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://www.forbes.com/sites/janakirammsv/2025/01/26/all-about-deepseekthe-chinese-ai-startup-challenging-the-us\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>-big-tech/                                                                                                      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>Exploring DeepSeek-V3: A Technical Overview:                                                                    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://medium.com/@lmpo/exploring-deepseek-version-3-a-technical-deep-dive-0b3d2c78b777                        \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>DeepSeek: What you need to know about the AI that dethroned ChatGPT:                                            \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://www.digitaltrends.com/computing/what-is-deepseek-everything-you-need-to-know/                           \n",
              "\n",
              "\n",
              "                                       <span style=\"font-weight: bold; text-decoration: underline\">Market Disruption and Economic Impact</span>                                       \n",
              "\n",
              "<span style=\"font-weight: bold\">DeepSeek's aggressive pricing strategy has triggered a significant price war in the AI market, challenging major </span>  \n",
              "<span style=\"font-weight: bold\">players like Nvidia and OpenAI.</span> The introduction of DeepSeek-V2 in May 2024, with its high performance at a low    \n",
              "cost, has forced companies such as ByteDance, Tencent, and Alibaba to lower their prices. This disruption has      \n",
              "extended beyond China, affecting global tech giants. For instance, Nvidia's stock plummeted by 12.5% following     \n",
              "DeepSeek's market entry, highlighting the financial impact on established companies reliant on high-cost AI        \n",
              "infrastructure.                                                                                                    \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span><span style=\"font-weight: bold\">Key Impacts:</span>                                                                                                    \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    ‚Ä¢ </span><span style=\"font-weight: bold\">Nvidia:</span> Experienced a record $593 billion market cap loss, with shares dropping 17%.                         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    ‚Ä¢ </span><span style=\"font-weight: bold\">OpenAI:</span> Faces pressure to reduce prices as DeepSeek's models rival their offerings at a fraction of the cost.\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">    ‚Ä¢ </span><span style=\"font-weight: bold\">Global AI Market:</span> The emergence of cost-efficient models like DeepSeek-V3 has sparked discussions on the     \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">      </span>sustainability of current AI investments.                                                                    \n",
              "\n",
              "DeepSeek's rise underscores a shift towards more accessible AI technologies, challenging the traditional balance   \n",
              "between innovation and profitability. This shift is prompting a reevaluation of investment strategies in AI        \n",
              "infrastructure, as companies seek to remain competitive in a rapidly evolving market landscape.                    \n",
              "\n",
              "                                                      <span style=\"font-weight: bold\">Sources</span>                                                      \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>DeepSeek price is challenges Nvidia, ChatGPT, and Silicon Valley - Quartz:                                      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://qz.com/deepseeks-aggressive-pricing-is-challenging-silicon-val-1851748345                               \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>DeepSeek's cheap price is challenging Nvidia, ChatGPT, and Silicon ...:                                         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://finance.yahoo.com/news/deepseeks-cheap-price-challenging-nvidia-180341018.html                          \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>DeepSeek And The Looming AI Price War Will Affect Us All - Forbes:                                              \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://www.forbes.com/sites/craigsmith/2025/01/28/the-looming-ai-price-war-will-affect-us-all/                 \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>What is DeepSeek, and why is it causing Nvidia and other stocks to ...:                                         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://www.cbsnews.com/news/what-is-deepseek-ai-china-stock-nvidia-nvda-asml/                                  \n",
              "\n",
              "\n",
              "                                       <span style=\"font-weight: bold; text-decoration: underline\">Comparison with Established AI Models</span>                                       \n",
              "\n",
              "<span style=\"font-weight: bold\">DeepSeek V3 offers a cost-effective alternative to proprietary models like OpenAI's GPT-4o, with competitive </span>      \n",
              "<span style=\"font-weight: bold\">performance across key benchmarks.</span> DeepSeek V3, an open-source model, features 671 billion parameters and utilizes \n",
              "a Mixture-of-Experts (MoE) architecture, activating only 37 billion parameters per task. This design enhances      \n",
              "computational efficiency, allowing DeepSeek V3 to achieve high performance in math and coding tasks, such as       \n",
              "scoring 90.2 on the Math-500 benchmark, surpassing GPT-4o's 74.6.                                                  \n",
              "\n",
              "In terms of cost, DeepSeek V3 is significantly cheaper, with input and output token costs at $0.14 and $0.28 per   \n",
              "million tokens, respectively, compared to GPT-4o's $2.50 and $10.00. This makes DeepSeek V3 approximately 29.8     \n",
              "times more cost-effective. Additionally, DeepSeek V3's open-source nature under the MIT license provides broad     \n",
              "accessibility for research and commercial use, contrasting with GPT-4o's proprietary restrictions.                 \n",
              "\n",
              "                                                      <span style=\"font-weight: bold\">Sources</span>                                                      \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>DeepSeek V3: New Open AI Model Surpasses Rivals and Challenges GPT-4o:                                          \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://winbuzzer.com/2024/12/27/deepseek-v3-new-open-ai-model-surpasses-rivals-and-challenges-gpt-4o-xcxwbn/   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>DeepSeek-V3 vs GPT-4o - Detailed Performance &amp; Feature Comparison:                                              \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://docsbot.ai/models/compare/deepseek-v3/gpt-4o                                                            \n",
              "\n",
              "\n",
              "                                             <span style=\"font-weight: bold; text-decoration: underline\">Challenges and Criticisms</span>                                             \n",
              "\n",
              "<span style=\"font-weight: bold\">DeepSeek faces significant challenges and criticisms, particularly regarding privacy, geopolitical implications, </span>  \n",
              "<span style=\"font-weight: bold\">and business sustainability.</span> Privacy concerns are paramount, as DeepSeek's privacy policy indicates that user data,\n",
              "including keystrokes and IP addresses, is stored on servers in China, raising alarms about potential government    \n",
              "access (TechRadar, 2025). This has led to comparisons with TikTok, highlighting fears of surveillance and data     \n",
              "misuse (Wired, 2025).                                                                                              \n",
              "\n",
              "Geopolitically, DeepSeek's rapid rise has sparked debates about U.S. export controls' effectiveness, as the        \n",
              "platform's success suggests Chinese AI can thrive despite restrictions (Observer, 2025). This has implications for \n",
              "global AI leadership and security, with concerns that DeepSeek could be used for misinformation or cyber-espionage \n",
              "(Axios, 2025).                                                                                                     \n",
              "\n",
              "Sustainability of DeepSeek's business model is also questioned. While its open-source approach and low costs       \n",
              "disrupt the market, reliance on Chinese infrastructure and potential censorship issues may hinder global adoption  \n",
              "(Forbes, 2025). The platform's ability to maintain competitive pricing while ensuring data security and ethical use\n",
              "remains a critical challenge.                                                                                      \n",
              "\n",
              "                                                      <span style=\"font-weight: bold\">Sources</span>                                                      \n",
              "\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>TechRadar:                                                                                                      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://www.techradar.com/computing/cyber-security/is-deepseek-ai-safe-or-is-it-just-a-data-minefield-waiting-to\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>-blow-up?t                                                                                                      \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>Wired: https://www.wired.com/story/deepseek-ai-china-privacy-data/                                              \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>Observer: https://observer.com/2025/01/china-deepseek-ai-shocks-markets-sparks-national-security-fears/         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>Axios: https://www.axios.com/2025/01/28/deepseek-ai-model-energy-power-demand                                   \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\"> ‚Ä¢ </span>Forbes:                                                                                                         \n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>https://www.forbes.com/sites/janakirammsv/2025/01/26/all-about-deepseekthe-chinese-ai-startup-challenging-the-us\n",
              "<span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">   </span>-big-tech/                                                                                                      \n",
              "\n",
              "\n",
              "                                                    <span style=\"font-weight: bold; text-decoration: underline\">Conclusion</span>                                                     \n",
              "\n",
              "DeepSeek has emerged as a formidable player in the AI landscape, introducing technological innovations that        \n",
              "challenge established norms. Its Mixture-of-Experts architecture and efficient AI development techniques have set  \n",
              "new standards for model efficiency and cost-effectiveness. The market disruption caused by DeepSeek's aggressive   \n",
              "pricing strategy has pressured major players like Nvidia and OpenAI to reconsider their pricing models,            \n",
              "highlighting a shift towards more accessible AI technologies. However, DeepSeek faces challenges, including privacy\n",
              "concerns and geopolitical implications, which may impact its global adoption and business sustainability.          \n",
              "\n",
              "                                  <span style=\"font-weight: bold\">Key Disruptive Elements Introduced by DeepSeek</span>                                   \n",
              "\n",
              "                                                                                                                \n",
              " <span style=\"font-weight: bold\"> Element                           </span> <span style=\"font-weight: bold\"> Description                                                              </span> \n",
              " ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ \n",
              "  Mixture-of-Experts Architecture     Enhances efficiency by activating only necessary parameters per task.     \n",
              "  Aggressive Pricing Strategy         Triggers price wars, challenging major AI companies to lower costs.       \n",
              "  Open-Source Accessibility           Democratizes AI access, contrasting with proprietary models like GPT-4o.  \n",
              "  Privacy and Geopolitical Concerns   Raises issues about data security and global AI leadership dynamics.      \n",
              "                                                                                                                \n",
              "\n",
              "DeepSeek's innovations and market impact suggest a need for ongoing evaluation of AI investment strategies and     \n",
              "regulatory frameworks to address emerging challenges.                                                              \n",
              "</pre>\n"
            ],
            "text/plain": [
              "‚îè‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îì\n",
              "‚îÉ                                                  \u001b[1mIntroduction\u001b[0m                                                   ‚îÉ\n",
              "‚îó‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îõ\n",
              "\n",
              "DeepSeek is a groundbreaking player in the AI market, known for its innovative technological advancements and      \n",
              "disruptive economic strategies. By leveraging open-source models and efficient AI development techniques, DeepSeek \n",
              "has redefined the landscape of AI model efficiency and accessibility. Its introduction of cost-effective models has\n",
              "sparked significant price wars, challenging established tech giants like Nvidia and OpenAI. This report delves into\n",
              "DeepSeek's technological innovations, market impact, and the challenges it faces, offering a comprehensive analysis\n",
              "of its role in reshaping the AI industry.                                                                          \n",
              "\n",
              "\n",
              "                                       \u001b[1;4mDeepSeek's Technological Innovations\u001b[0m                                        \n",
              "\n",
              "\u001b[1mDeepSeek's innovative use of the Mixture-of-Experts (MoE) architecture and efficient AI development techniques has \u001b[0m\n",
              "\u001b[1mredefined AI model efficiency.\u001b[0m The DeepSeek-V3 model, launched in December 2024, exemplifies this with its 671     \n",
              "billion parameters, yet only 37 billion are activated per task, significantly reducing computational costs. This   \n",
              "model was trained using just 2,048 Nvidia H800 GPUs over two months, costing approximately $5.6 million, a fraction\n",
              "of the cost for similar models from major tech companies.                                                          \n",
              "\n",
              "DeepSeek's approach includes several key innovations:                                                              \n",
              "\n",
              "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mMulti-Head Latent Attention (MLA):\u001b[0m Enhances the model's ability to process complex inputs by focusing on        \n",
              "\u001b[1;33m   \u001b[0mdifferent data aspects simultaneously.                                                                          \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mFP8 Mixed Precision Training:\u001b[0m Reduces memory usage and accelerates training without sacrificing accuracy.       \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mAuxiliary-Loss-Free Load Balancing:\u001b[0m Ensures efficient distribution of computational tasks across the model's    \n",
              "\u001b[1;33m   \u001b[0mparameters.                                                                                                     \n",
              "\n",
              "These advancements allow DeepSeek to deliver high performance on benchmarks like MMLU-Pro and MATH 500, often      \n",
              "surpassing models like GPT-4o. DeepSeek's commitment to open-source models democratizes access to advanced AI,     \n",
              "challenging the dominance of established players and reshaping the AI landscape.                                   \n",
              "\n",
              "                                                      \u001b[1mSources\u001b[0m                                                      \n",
              "\n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mAll About DeepSeek ‚Äî The Chinese AI Startup Challenging US Big Tech:                                            \n",
              "\u001b[1;33m   \u001b[0mhttps://www.forbes.com/sites/janakirammsv/2025/01/26/all-about-deepseekthe-chinese-ai-startup-challenging-the-us\n",
              "\u001b[1;33m   \u001b[0m-big-tech/                                                                                                      \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mExploring DeepSeek-V3: A Technical Overview:                                                                    \n",
              "\u001b[1;33m   \u001b[0mhttps://medium.com/@lmpo/exploring-deepseek-version-3-a-technical-deep-dive-0b3d2c78b777                        \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mDeepSeek: What you need to know about the AI that dethroned ChatGPT:                                            \n",
              "\u001b[1;33m   \u001b[0mhttps://www.digitaltrends.com/computing/what-is-deepseek-everything-you-need-to-know/                           \n",
              "\n",
              "\n",
              "                                       \u001b[1;4mMarket Disruption and Economic Impact\u001b[0m                                       \n",
              "\n",
              "\u001b[1mDeepSeek's aggressive pricing strategy has triggered a significant price war in the AI market, challenging major \u001b[0m  \n",
              "\u001b[1mplayers like Nvidia and OpenAI.\u001b[0m The introduction of DeepSeek-V2 in May 2024, with its high performance at a low    \n",
              "cost, has forced companies such as ByteDance, Tencent, and Alibaba to lower their prices. This disruption has      \n",
              "extended beyond China, affecting global tech giants. For instance, Nvidia's stock plummeted by 12.5% following     \n",
              "DeepSeek's market entry, highlighting the financial impact on established companies reliant on high-cost AI        \n",
              "infrastructure.                                                                                                    \n",
              "\n",
              "\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mKey Impacts:\u001b[0m                                                                                                    \n",
              "\u001b[1;33m   \u001b[0m\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mNvidia:\u001b[0m Experienced a record $593 billion market cap loss, with shares dropping 17%.                         \n",
              "\u001b[1;33m   \u001b[0m\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mOpenAI:\u001b[0m Faces pressure to reduce prices as DeepSeek's models rival their offerings at a fraction of the cost.\n",
              "\u001b[1;33m   \u001b[0m\u001b[1;33m ‚Ä¢ \u001b[0m\u001b[1mGlobal AI Market:\u001b[0m The emergence of cost-efficient models like DeepSeek-V3 has sparked discussions on the     \n",
              "\u001b[1;33m   \u001b[0m\u001b[1;33m   \u001b[0msustainability of current AI investments.                                                                    \n",
              "\n",
              "DeepSeek's rise underscores a shift towards more accessible AI technologies, challenging the traditional balance   \n",
              "between innovation and profitability. This shift is prompting a reevaluation of investment strategies in AI        \n",
              "infrastructure, as companies seek to remain competitive in a rapidly evolving market landscape.                    \n",
              "\n",
              "                                                      \u001b[1mSources\u001b[0m                                                      \n",
              "\n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mDeepSeek price is challenges Nvidia, ChatGPT, and Silicon Valley - Quartz:                                      \n",
              "\u001b[1;33m   \u001b[0mhttps://qz.com/deepseeks-aggressive-pricing-is-challenging-silicon-val-1851748345                               \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mDeepSeek's cheap price is challenging Nvidia, ChatGPT, and Silicon ...:                                         \n",
              "\u001b[1;33m   \u001b[0mhttps://finance.yahoo.com/news/deepseeks-cheap-price-challenging-nvidia-180341018.html                          \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mDeepSeek And The Looming AI Price War Will Affect Us All - Forbes:                                              \n",
              "\u001b[1;33m   \u001b[0mhttps://www.forbes.com/sites/craigsmith/2025/01/28/the-looming-ai-price-war-will-affect-us-all/                 \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mWhat is DeepSeek, and why is it causing Nvidia and other stocks to ...:                                         \n",
              "\u001b[1;33m   \u001b[0mhttps://www.cbsnews.com/news/what-is-deepseek-ai-china-stock-nvidia-nvda-asml/                                  \n",
              "\n",
              "\n",
              "                                       \u001b[1;4mComparison with Established AI Models\u001b[0m                                       \n",
              "\n",
              "\u001b[1mDeepSeek V3 offers a cost-effective alternative to proprietary models like OpenAI's GPT-4o, with competitive \u001b[0m      \n",
              "\u001b[1mperformance across key benchmarks.\u001b[0m DeepSeek V3, an open-source model, features 671 billion parameters and utilizes \n",
              "a Mixture-of-Experts (MoE) architecture, activating only 37 billion parameters per task. This design enhances      \n",
              "computational efficiency, allowing DeepSeek V3 to achieve high performance in math and coding tasks, such as       \n",
              "scoring 90.2 on the Math-500 benchmark, surpassing GPT-4o's 74.6.                                                  \n",
              "\n",
              "In terms of cost, DeepSeek V3 is significantly cheaper, with input and output token costs at $0.14 and $0.28 per   \n",
              "million tokens, respectively, compared to GPT-4o's $2.50 and $10.00. This makes DeepSeek V3 approximately 29.8     \n",
              "times more cost-effective. Additionally, DeepSeek V3's open-source nature under the MIT license provides broad     \n",
              "accessibility for research and commercial use, contrasting with GPT-4o's proprietary restrictions.                 \n",
              "\n",
              "                                                      \u001b[1mSources\u001b[0m                                                      \n",
              "\n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mDeepSeek V3: New Open AI Model Surpasses Rivals and Challenges GPT-4o:                                          \n",
              "\u001b[1;33m   \u001b[0mhttps://winbuzzer.com/2024/12/27/deepseek-v3-new-open-ai-model-surpasses-rivals-and-challenges-gpt-4o-xcxwbn/   \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mDeepSeek-V3 vs GPT-4o - Detailed Performance & Feature Comparison:                                              \n",
              "\u001b[1;33m   \u001b[0mhttps://docsbot.ai/models/compare/deepseek-v3/gpt-4o                                                            \n",
              "\n",
              "\n",
              "                                             \u001b[1;4mChallenges and Criticisms\u001b[0m                                             \n",
              "\n",
              "\u001b[1mDeepSeek faces significant challenges and criticisms, particularly regarding privacy, geopolitical implications, \u001b[0m  \n",
              "\u001b[1mand business sustainability.\u001b[0m Privacy concerns are paramount, as DeepSeek's privacy policy indicates that user data,\n",
              "including keystrokes and IP addresses, is stored on servers in China, raising alarms about potential government    \n",
              "access (TechRadar, 2025). This has led to comparisons with TikTok, highlighting fears of surveillance and data     \n",
              "misuse (Wired, 2025).                                                                                              \n",
              "\n",
              "Geopolitically, DeepSeek's rapid rise has sparked debates about U.S. export controls' effectiveness, as the        \n",
              "platform's success suggests Chinese AI can thrive despite restrictions (Observer, 2025). This has implications for \n",
              "global AI leadership and security, with concerns that DeepSeek could be used for misinformation or cyber-espionage \n",
              "(Axios, 2025).                                                                                                     \n",
              "\n",
              "Sustainability of DeepSeek's business model is also questioned. While its open-source approach and low costs       \n",
              "disrupt the market, reliance on Chinese infrastructure and potential censorship issues may hinder global adoption  \n",
              "(Forbes, 2025). The platform's ability to maintain competitive pricing while ensuring data security and ethical use\n",
              "remains a critical challenge.                                                                                      \n",
              "\n",
              "                                                      \u001b[1mSources\u001b[0m                                                      \n",
              "\n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mTechRadar:                                                                                                      \n",
              "\u001b[1;33m   \u001b[0mhttps://www.techradar.com/computing/cyber-security/is-deepseek-ai-safe-or-is-it-just-a-data-minefield-waiting-to\n",
              "\u001b[1;33m   \u001b[0m-blow-up?t                                                                                                      \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mWired: https://www.wired.com/story/deepseek-ai-china-privacy-data/                                              \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mObserver: https://observer.com/2025/01/china-deepseek-ai-shocks-markets-sparks-national-security-fears/         \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mAxios: https://www.axios.com/2025/01/28/deepseek-ai-model-energy-power-demand                                   \n",
              "\u001b[1;33m ‚Ä¢ \u001b[0mForbes:                                                                                                         \n",
              "\u001b[1;33m   \u001b[0mhttps://www.forbes.com/sites/janakirammsv/2025/01/26/all-about-deepseekthe-chinese-ai-startup-challenging-the-us\n",
              "\u001b[1;33m   \u001b[0m-big-tech/                                                                                                      \n",
              "\n",
              "\n",
              "                                                    \u001b[1;4mConclusion\u001b[0m                                                     \n",
              "\n",
              "DeepSeek has emerged as a formidable player in the AI landscape, introducing technological innovations that        \n",
              "challenge established norms. Its Mixture-of-Experts architecture and efficient AI development techniques have set  \n",
              "new standards for model efficiency and cost-effectiveness. The market disruption caused by DeepSeek's aggressive   \n",
              "pricing strategy has pressured major players like Nvidia and OpenAI to reconsider their pricing models,            \n",
              "highlighting a shift towards more accessible AI technologies. However, DeepSeek faces challenges, including privacy\n",
              "concerns and geopolitical implications, which may impact its global adoption and business sustainability.          \n",
              "\n",
              "                                  \u001b[1mKey Disruptive Elements Introduced by DeepSeek\u001b[0m                                   \n",
              "\n",
              "                                                                                                                \n",
              " \u001b[1m \u001b[0m\u001b[1mElement\u001b[0m\u001b[1m                          \u001b[0m\u001b[1m \u001b[0m \u001b[1m \u001b[0m\u001b[1mDescription\u001b[0m\u001b[1m                                                             \u001b[0m\u001b[1m \u001b[0m \n",
              " ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ \n",
              "  Mixture-of-Experts Architecture     Enhances efficiency by activating only necessary parameters per task.     \n",
              "  Aggressive Pricing Strategy         Triggers price wars, challenging major AI companies to lower costs.       \n",
              "  Open-Source Accessibility           Democratizes AI access, contrasting with proprietary models like GPT-4o.  \n",
              "  Privacy and Geopolitical Concerns   Raises issues about data security and global AI leadership dynamics.      \n",
              "                                                                                                                \n",
              "\n",
              "DeepSeek's innovations and market impact suggest a need for ongoing evaluation of AI investment strategies and     \n",
              "regulatory frameworks to address emerging challenges.                                                              \n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "topic = \"Detailed report on how DeepSeek has disrupted the AI Market\"\n",
        "await call_planner_agent(agent=reporter_agent,\n",
        "                         prompt=topic)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f365ab75",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "deepvenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
